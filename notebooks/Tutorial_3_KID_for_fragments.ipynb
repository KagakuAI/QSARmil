{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae70e79-b15d-4ea1-85e4-19590aca7273",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Each bag contains a collection of molecular fragments. The label is the sum of some property calculated for each fragment. These properties are chosen to be preferably additive (can be calculated as a linear contribution of each fragment). The predicted weights should correspond to the contribution of each fragment. The higher the contribution, the higher the weight should be.\n",
    "\n",
    "**Instance:** One molecular fragment (e.g. C(=O)O - Carboxy group).\n",
    "\n",
    "**Bag**: A collection of fragments (e.g., a list of 5 fragments).\n",
    "\n",
    "**Label:** A sum of fragment property value (e.g. LogP) in the bag.\n",
    "\n",
    "**Key instance:** All fragments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603ccad-b191-45e8-9987-0c0494f2d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "from rdkit import RDLogger\n",
    "# Suppress all RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from milearn.preprocessing import BagMinMaxScaler\n",
    "\n",
    "# Network hparams\n",
    "from milearn.network.module.hopt import DEFAULT_PARAM_GRID\n",
    "\n",
    "# MIL wrappers\n",
    "from milearn.network.regressor import BagWrapperMLPNetworkRegressor, InstanceWrapperMLPNetworkRegressor\n",
    "from milearn.network.classifier import BagWrapperMLPNetworkClassifier, InstanceWrapperMLPNetworkClassifier\n",
    "\n",
    "# MIL networks\n",
    "from milearn.network.regressor import (InstanceNetworkRegressor,\n",
    "                                       BagNetworkRegressor,\n",
    "                                       AdditiveAttentionNetworkRegressor,\n",
    "                                       SelfAttentionNetworkRegressor,\n",
    "                                       HopfieldAttentionNetworkRegressor,\n",
    "                                       DynamicPoolingNetworkRegressor)\n",
    "\n",
    "# Utils\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Molecular utils\n",
    "from qsarmil.fragment.rdkit import FragmentGenerator\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Prediction visualisation\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fb753-5dea-4160-af2c-5dac4d3b4f22",
   "metadata": {},
   "source": [
    "### Key Instance Detection Ranking Accuracy for Regression\n",
    "\n",
    "This function evaluates how well a model's predicted attention weights rank the important instances in a bag, by computing the Spearman rank correlation between:\n",
    "\n",
    "* The true importance ranking (represented here by the fragment property values)\n",
    "\n",
    "* The predicted importance scores (predicted weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296404f-5204-4200-9a35-2ca10b0d5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kid_ranking_accuracy(instance_digits, attn_weights):\n",
    "\n",
    "    per_bag_corrs = []\n",
    "    for w, digits in zip(attn_weights, instance_digits):\n",
    "        if len(set(digits)) == 1:\n",
    "            # Avoid undefined correlation when all digits are identical\n",
    "            per_bag_corrs.append(0.0)\n",
    "            continue\n",
    "\n",
    "        corr, _ = spearmanr(w, digits)\n",
    "        if np.isnan(corr):\n",
    "            corr = 0.0\n",
    "        per_bag_corrs.append(corr)\n",
    "\n",
    "    mean_corr = np.mean(per_bag_corrs)\n",
    "    return mean_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eaf42-a36a-4499-8dd0-f21addcf1e85",
   "metadata": {},
   "source": [
    "### Fragment properties\n",
    "\n",
    "In Multiple Instance Learning (MIL), each bag is a collection of instances (here, molecular fragments), and the task often involves predicting a label for the entire bag. In this specific setup:\n",
    "\n",
    "* Each molecule is broken into BRICS fragments.\n",
    "\n",
    "* A fixed number of these fragments are randomly sampled to form a bag.\n",
    "\n",
    "* A chemical property is calculated for each fragment.\n",
    "\n",
    "* The sum of fragment properties becomes the bag's label.\n",
    "\n",
    "* The function returns: The fragment bags (as RDKit Mol objects), The bag labels (total property), The individual fragment properties (per bag)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3d188-e74c-46a7-b62f-6985141d7198",
   "metadata": {},
   "source": [
    "**The list of properties that can be calculated for fragments:**\n",
    "\n",
    "* ``LogP`` – Lipophilicity\n",
    "\n",
    "* ``MolWt`` – Molecular weight\n",
    "\n",
    "* ``TPSA`` – Topological polar surface area\n",
    "\n",
    "* ``NumHDonors`` – Number of hydrogen bond donors\n",
    "\n",
    "* ``NumHAcceptors`` – Number of hydrogen bond acceptors\n",
    "\n",
    "* ``MolMR`` – Molar refractivity\n",
    "\n",
    "* ``NumRotatableBonds`` – Flexibility\n",
    "\n",
    "* ``RingCount`` – Number of rings\n",
    "\n",
    "* ``FractionCSP3`` – Fraction of sp³-hybridized carbon atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311c507-cd6d-45c9-b1e2-7d195c53550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fragments_with_weights(fragments, props, pred_weights, sort=True, max_fragments=16, title=None):\n",
    "\n",
    "    props = np.array(props)\n",
    "    pred_weights = np.array(pred_weights)\n",
    "\n",
    "    if sort:\n",
    "        sorted_idx = np.argsort(props)[::-1]\n",
    "        fragments = [fragments[i] for i in sorted_idx]\n",
    "        props = props[sorted_idx]\n",
    "        pred_weights = pred_weights[sorted_idx]\n",
    "\n",
    "    fragments = fragments[:max_fragments]\n",
    "    props = props[:max_fragments]\n",
    "    pred_weights = pred_weights[:max_fragments]\n",
    "\n",
    "    cols = 4\n",
    "    rows = (len(fragments) + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax in axes[len(fragments):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, (frag, prop, weight) in enumerate(zip(fragments, props, pred_weights)):\n",
    "        ax = axes[i]\n",
    "        img = Draw.MolToImage(frag, size=(150, 150))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True prop: {prop:.3f}\\nWeight: {weight:.2f}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # leave space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca51ed-6500-42f0-b107-a14d19327c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported RDKit molecular property functions\n",
    "PROPERTY_FUNCTIONS = {\n",
    "    \"LogP\": Descriptors.MolLogP,\n",
    "    \"MolWt\": Descriptors.MolWt,\n",
    "    \"TPSA\": rdMolDescriptors.CalcTPSA,\n",
    "    \"NumHDonors\": Descriptors.NumHDonors,\n",
    "    \"NumHAcceptors\": Descriptors.NumHAcceptors,\n",
    "    \"MolMR\": Descriptors.MolMR,\n",
    "    \"NumRotatableBonds\": Descriptors.NumRotatableBonds,\n",
    "    \"RingCount\": Descriptors.RingCount,\n",
    "    \"FractionCSP3\": Descriptors.FractionCSP3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8d3d7-689c-4166-b076-aa42f3ba0564",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d71a4d-5062-4b8e-87d6-5f94ccbcd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ID = \"KagakuData/notebooks\"\n",
    "\n",
    "csv_path = hf_hub_download(REPO_ID, filename=\"chembl/CHEMBL279.csv\", repo_type=\"dataset\")\n",
    "data = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "smiles = list(data[0])\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961bc140-7794-4bb4-9daa-cd15eaa418b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fragments\n",
    "frag_gen = FragmentGenerator(num_cpu=40, verbose=True)\n",
    "frags = frag_gen.run(mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd64de-964b-4504-9b91-af930e408024",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_size = 5\n",
    "rng = np.random.RandomState(42)\n",
    "frags = [mol for mol in frags if len(mol) > bag_size]\n",
    "frags = [rng.choice(mol, size=bag_size, replace=False).tolist() for mol in frags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad36408-5e19-445f-9986-414e34843dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_name = \"LogP\"\n",
    "get_property = PROPERTY_FUNCTIONS[property_name]\n",
    "\n",
    "contribs = [[get_property(f) for f in mol] for mol in frags]\n",
    "props = [sum(m) for m in contribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fba210-124e-4252-a8dd-fe4e42ffa49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total number of molecules: {len(mols)}\")\n",
    "print(f\"Total number of bags (successfully generated fragments): {len(frags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d90a9-b66b-48c4-aaba-2dd1d5f47fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f624dd0d-75c1-4845-ad98-c39180b4889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contribs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b764b6-5de3-48d2-958d-9de8726fbaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "props[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121edf28-caeb-4a1a-a7bb-487feeaa72b9",
   "metadata": {},
   "source": [
    "### 2. Calculate fragment descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a1707-5126-4fb6-bc07-6bf784da8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_fragment_descriptors(frags, n_bits=1024, radius=2):\n",
    "#     bags_descriptors = []\n",
    "#     for frag in frags:\n",
    "#         descs = [np.array(AllChem.GetMorganFingerprintAsBitVect(f, radius, nBits=n_bits)) for f in frag]\n",
    "#         bags_descriptors.append(descs)\n",
    "#     return bags_descriptors\n",
    "\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "\n",
    "desc_list = [desc[1] for desc in Descriptors.descList]\n",
    "\n",
    "def compute_fragment_descriptors(frags):\n",
    "    bags_descriptors = []\n",
    "\n",
    "    for frag in frags:\n",
    "        descs = []\n",
    "        for f in frag:\n",
    "            vals = np.array([desc(f) if desc(f) is not None else np.nan for desc in desc_list], dtype=float)\n",
    "            descs.append(vals)\n",
    "\n",
    "        descs = np.array(descs)  # shape: (num_fragments_in_bag, num_descriptors)\n",
    "\n",
    "        # replace NaNs by mean of each descriptor in the bag\n",
    "        col_mean = np.nanmean(descs, axis=0)\n",
    "\n",
    "        # if entire column is NaN, replace with 0\n",
    "        col_mean = np.where(np.isnan(col_mean), 0.0, col_mean)\n",
    "\n",
    "        inds = np.where(np.isnan(descs))\n",
    "        descs[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "        bags_descriptors.append(descs)\n",
    "\n",
    "    return bags_descriptors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9882c183-11aa-4964-8e1a-7e457c354f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc = compute_fragment_descriptors(frags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed31db-d1a4-4de7-b875-ea56f70147a5",
   "metadata": {},
   "source": [
    "### 3. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d4308-c4dc-4a35-8a34-31ba1c11df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, key_train, key_test, frg_train, frg_test = train_test_split(desc, props, contribs, frags, random_state=42)\n",
    "#\n",
    "scaler = BagMinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b8325-a377-4e10-b0c8-ed70e2542629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DynamicPoolingNetworkRegressor()\n",
    "model.hopt(x_train_scaled, y_train, param_grid=DEFAULT_PARAM_GRID, verbose=True)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9e45e-76b5-4fcd-a6fb-81a164bbdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_scaled)\n",
    "w_pred = model.get_instance_weights(x_test_scaled)\n",
    "w_pred = [w.flatten() for w in w_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71657a5d-fc8a-4ee0-a027-989392a00f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Regression R2: {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"KID ranking accuracy: {kid_ranking_accuracy(key_test, w_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820883d-a563-4cca-81b3-42bb4bcd444f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "display_fragments_with_weights(frg_test[N], key_test[N], w_pred[N], sort=True, max_fragments=10,\n",
    "                               title=f\"Bag {N}\\nPredicted label:{y_pred[N].item():.2f}\\nTrue label: {y_test[N]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1b3a0-5393-4d86-a595-1d7c9d4833ee",
   "metadata": {},
   "source": [
    "### 4. Mini-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9603049-4c2f-423a-b9e5-05437aac445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_list = [\n",
    "    \n",
    "        # attention mil networks\n",
    "        (\"AdditiveAttentionNetworkRegressor\", AdditiveAttentionNetworkRegressor()),\n",
    "        (\"SelfAttentionNetworkRegressor\", SelfAttentionNetworkRegressor()),\n",
    "        (\"HopfieldAttentionNetworkRegressor\", HopfieldAttentionNetworkRegressor()),\n",
    "\n",
    "        # other mil networks\n",
    "        (\"DynamicPoolingNetworkRegressor\", DynamicPoolingNetworkRegressor()),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523bd06-47da-427f-85ac-9a3492778dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_size = 5\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "tasks = [\"LogP\", \"MolWt\", \"TPSA\", \"NumHDonors\", \"NumHAcceptors\", \n",
    "         \"MolMR\", \"NumRotatableBonds\", \"RingCount\", \"FractionCSP3\"]\n",
    "\n",
    "for task_idx, task in enumerate(tasks, 1):\n",
    "    print(f\"\\n[Task {task_idx}/{len(tasks)}] Starting task: '{task}'\")\n",
    "\n",
    "    # load data\n",
    "    REPO_ID = \"KagakuData/notebooks\"\n",
    "    csv_path = hf_hub_download(REPO_ID, filename=\"chembl/CHEMBL279.csv\", repo_type=\"dataset\")\n",
    "    data = pd.read_csv(csv_path, header=None)\n",
    "    smiles = list(data[0])\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "    # compute bag desc\n",
    "    frag_gen = FragmentGenerator(num_cpu=40, verbose=True)\n",
    "    frags = frag_gen.run(mols)\n",
    "    #\n",
    "    bag_size = 5\n",
    "    rng = np.random.RandomState(42)\n",
    "    frags = [mol for mol in frags if len(mol) > bag_size]\n",
    "    frags = [rng.choice(mol, size=bag_size, replace=False).tolist() for mol in frags]\n",
    "    #\n",
    "    desc = compute_fragment_descriptors(frags)\n",
    "    #\n",
    "    x_train, x_test, y_train, y_test, key_train, key_test, frg_train, frg_test = train_test_split(\n",
    "        desc, labels, contribs, bags, random_state=42)\n",
    "    \n",
    "    # scale features\n",
    "    scaler = BagMinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train_scaled, x_test_scaled = scaler.transform(x_train), scaler.transform(x_test)\n",
    "    \n",
    "    # build models\n",
    "    for model_idx, (name, model) in enumerate(regressor_list, 1):\n",
    "        print(f\"  [Model {model_idx}/{len(regressor_list)}] Training model: '{name}'\")\n",
    "\n",
    "        # train model\n",
    "        model.hopt(x_train_scaled, y_train, param_grid=DEFAULT_PARAM_GRID, verbose=True)\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        \n",
    "        # predict\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "        w_pred = model.get_instance_weights(x_test_scaled)\n",
    "        w_pred = [w.flatten() for w in w_pred]\n",
    "        #\n",
    "        res_df.loc[name, f\"PRED_{task}\"] = r2_score(y_test, y_pred)\n",
    "        res_df.loc[name, f\"KID_{task}\"] = kid_ranking_accuracy(key_test, w_pred)\n",
    "\n",
    "print(\"\\nAll tasks and models completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0ed6f6-21c1-4087-96fd-51efdc662085",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98beab-6d0d-4e77-931b-ff51e7c10abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
