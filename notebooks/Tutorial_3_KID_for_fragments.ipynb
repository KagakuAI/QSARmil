{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae70e79-b15d-4ea1-85e4-19590aca7273",
   "metadata": {},
   "source": [
    "### MIL with Molecular Fragments (Additive Properties)\n",
    "\n",
    "In this tutorial, we focus on a **Multiple Instance Learning (MIL)** setup where each **bag** represents a collection of molecular fragments, and the **bag-level label** is computed as the sum of some **additive property** across the fragments.  \n",
    "\n",
    "This setup is useful for tasks where molecular properties can be approximated as a **linear combination of fragment contributions**, such as LogP or other physicochemical properties.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Instance:** A single molecular fragment, e.g., `C(=O)O` (carboxy group).  \n",
    "- **Bag:** A collection of fragments, e.g., a list of 5 fragments forming a small molecule.  \n",
    "- **Label:** Sum of the property values of all fragments in the bag. For example, the sum of LogP contributions.  \n",
    "- **Key Instance:** In this tutorial, **all fragments are considered key instances**, since every fragment contributes to the bag-level label.  \n",
    "\n",
    "---\n",
    "\n",
    "### Goals of this Notebook\n",
    "\n",
    "1. Represent molecules as **bags of fragments**.  \n",
    "2. Compute fragment-level properties that contribute additively to the bag label.  \n",
    "3. Train MIL models to predict **bag-level properties** while recovering **fragment contributions**.  \n",
    "4. Analyze predicted weights to identify **key fragments** and evaluate model interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d603ccad-b191-45e8-9987-0c0494f2d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "from rdkit import RDLogger\n",
    "# Suppress all RDKit warnings\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from milearn.preprocessing import BagMinMaxScaler\n",
    "\n",
    "# Network hparams\n",
    "from milearn.network.module.hopt import DEFAULT_PARAM_GRID\n",
    "\n",
    "# MIL wrappers\n",
    "from milearn.network.regressor import BagWrapperMLPNetworkRegressor, InstanceWrapperMLPNetworkRegressor\n",
    "from milearn.network.classifier import BagWrapperMLPNetworkClassifier, InstanceWrapperMLPNetworkClassifier\n",
    "\n",
    "# MIL networks\n",
    "from milearn.network.regressor import (InstanceNetworkRegressor,\n",
    "                                       BagNetworkRegressor,\n",
    "                                       AdditiveAttentionNetworkRegressor,\n",
    "                                       SelfAttentionNetworkRegressor,\n",
    "                                       HopfieldAttentionNetworkRegressor,\n",
    "                                       DynamicPoolingNetworkRegressor)\n",
    "\n",
    "# Utils\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Molecular utils\n",
    "from qsarmil.fragment.rdkit import FragmentGenerator\n",
    "from rdkit.Chem import Descriptors, rdMolDescriptors\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Prediction visualisation\n",
    "from rdkit.Chem import Draw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fb753-5dea-4160-af2c-5dac4d3b4f22",
   "metadata": {},
   "source": [
    "### Key Instance Ranking Accuracy (`kid_ranking_accuracy`)\n",
    "\n",
    "In MIL tasks where **instance-level contributions** are predicted (e.g., via attention weights), it is useful to measure **how well the predicted weights rank the true contributions**.  \n",
    "\n",
    "The function `kid_ranking_accuracy` computes a **ranking-based accuracy metric** using **Spearman correlation** between predicted weights and true instance contributions:\n",
    "\n",
    "---\n",
    "\n",
    "### How It Works\n",
    "\n",
    "1. **Inputs:**\n",
    "   - `instance_digits` – true property values or contributions for each instance in a bag (e.g., fragment property values).  \n",
    "   - `attn_weights` – predicted weights from the MIL model (e.g., attention scores).\n",
    "\n",
    "2. **Per-bag correlation:**\n",
    "   - For each bag, compute the **Spearman rank correlation** between predicted weights and true instance contributions.  \n",
    "   - If all true contributions are identical (no variance), correlation is undefined → assign `0.0`.  \n",
    "   - Any `NaN` correlation is also replaced with `0.0`.\n",
    "\n",
    "3. **Output:**\n",
    "   - Returns the **mean Spearman correlation** across all bags.  \n",
    "   - This metric reflects how well the model **ranks instances by their true importance**, not just whether it identifies the top instance.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "- `1.0` → Perfect ranking: predicted weights exactly match the true contributions.  \n",
    "- `0.0` → No correlation between predicted weights and true contributions.  \n",
    "- `-1.0` → Completely inverted ranking.  \n",
    "\n",
    "This metric is particularly useful for **evaluating interpretability** of MIL models at the instance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c296404f-5204-4200-9a35-2ca10b0d5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kid_ranking_accuracy(instance_digits, attn_weights):\n",
    "\n",
    "    per_bag_corrs = []\n",
    "    for w, digits in zip(attn_weights, instance_digits):\n",
    "        if len(set(digits)) == 1:\n",
    "            # Avoid undefined correlation when all digits are identical\n",
    "            per_bag_corrs.append(0.0)\n",
    "            continue\n",
    "\n",
    "        corr, _ = spearmanr(w, digits)\n",
    "        if np.isnan(corr):\n",
    "            corr = 0.0\n",
    "        per_bag_corrs.append(corr)\n",
    "\n",
    "    mean_corr = np.mean(per_bag_corrs)\n",
    "    return mean_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112eaf42-a36a-4499-8dd0-f21addcf1e85",
   "metadata": {},
   "source": [
    "### Fragment Properties in MIL\n",
    "\n",
    "In this MIL setup, each bag represents a collection of **molecular fragments**, and the bag-level label is derived from the **sum of fragment properties**.\n",
    "\n",
    "- Molecules are broken into **BRICS fragments**.  \n",
    "- A fixed number of fragments are randomly sampled to form a bag.  \n",
    "- A chemical property is calculated for each fragment.\n",
    "\n",
    "**Fragment properties used:**\n",
    "\n",
    "- `LogP` – Lipophilicity  \n",
    "- `MolWt` – Molecular weight  \n",
    "- `TPSA` – Topological polar surface area  \n",
    "- `NumHDonors` – Hydrogen bond donors  \n",
    "- `NumHAcceptors` – Hydrogen bond acceptors  \n",
    "- `MolMR` – Molar refractivity  \n",
    "- `NumRotatableBonds` – Flexibility  \n",
    "- `RingCount` – Number of rings  \n",
    "- `FractionCSP3` – Fraction of sp³-hybridized carbons\n",
    "\n",
    "The **bag label** is the sum of the selected fragment properties.  \n",
    "\n",
    "**Function output:**\n",
    "1. Fragment bags (RDKit Mol objects)  \n",
    "2. Bag labels (sum of properties)  \n",
    "3. Individual fragment properties per bag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1311c507-cd6d-45c9-b1e2-7d195c53550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fragments_with_weights(fragments, props, pred_weights, sort=True, max_fragments=16, title=None):\n",
    "\n",
    "    props = np.array(props)\n",
    "    pred_weights = np.array(pred_weights)\n",
    "\n",
    "    if sort:\n",
    "        sorted_idx = np.argsort(props)[::-1]\n",
    "        fragments = [fragments[i] for i in sorted_idx]\n",
    "        props = props[sorted_idx]\n",
    "        pred_weights = pred_weights[sorted_idx]\n",
    "\n",
    "    fragments = fragments[:max_fragments]\n",
    "    props = props[:max_fragments]\n",
    "    pred_weights = pred_weights[:max_fragments]\n",
    "\n",
    "    cols = 4\n",
    "    rows = (len(fragments) + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax in axes[len(fragments):]:\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, (frag, prop, weight) in enumerate(zip(fragments, props, pred_weights)):\n",
    "        ax = axes[i]\n",
    "        img = Draw.MolToImage(frag, size=(150, 150))\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"True prop: {prop:.3f}\\nWeight: {weight:.2f}\", fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # leave space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68ca51ed-6500-42f0-b107-a14d19327c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported RDKit molecular property functions\n",
    "PROPERTY_FUNCTIONS = {\n",
    "    \"LogP\": Descriptors.MolLogP,\n",
    "    \"MolWt\": Descriptors.MolWt,\n",
    "    \"TPSA\": rdMolDescriptors.CalcTPSA,\n",
    "    \"NumHDonors\": Descriptors.NumHDonors,\n",
    "    \"NumHAcceptors\": Descriptors.NumHAcceptors,\n",
    "    \"MolMR\": Descriptors.MolMR,\n",
    "    \"NumRotatableBonds\": Descriptors.NumRotatableBonds,\n",
    "    \"RingCount\": Descriptors.RingCount,\n",
    "    \"FractionCSP3\": Descriptors.FractionCSP3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8d3d7-689c-4166-b076-aa42f3ba0564",
   "metadata": {},
   "source": [
    "### 1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d71a4d-5062-4b8e-87d6-5f94ccbcd094",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_ID = \"KagakuData/notebooks\"\n",
    "\n",
    "csv_path = hf_hub_download(REPO_ID, filename=\"chembl/CHEMBL217.csv\", repo_type=\"dataset\")\n",
    "data = pd.read_csv(csv_path, header=None)\n",
    "\n",
    "smiles = list(data[0])\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d93f8c-815d-426f-a40c-1ab9cae73d6a",
   "metadata": {},
   "source": [
    "### 2. Generate molecular fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961bc140-7794-4bb4-9daa-cd15eaa418b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|█████████████████████████████████████████████████████████| 5012/5012 [08:46<00:00,  9.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# generate fragments\n",
    "frag_gen = FragmentGenerator(num_cpu=40, verbose=True)\n",
    "frags = frag_gen.run(mols)\n",
    "\n",
    "# sample bags with multiple fragments\n",
    "bag_size = 5\n",
    "rng = np.random.RandomState(42)\n",
    "frags = [mol for mol in frags if len(mol) > bag_size]\n",
    "frags = [rng.choice(mol, size=bag_size, replace=False).tolist() for mol in frags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ad36408-5e19-445f-9986-414e34843dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_name = \"LogP\"\n",
    "get_property = PROPERTY_FUNCTIONS[property_name]\n",
    "\n",
    "contribs = [[get_property(f) for f in mol] for mol in frags]\n",
    "props = [sum(m) for m in contribs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76fba210-124e-4252-a8dd-fe4e42ffa49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of molecules: 5012\n",
      "Total number of bags (successfully generated fragments): 2582\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of molecules: {len(mols)}\")\n",
    "print(f\"Total number of bags (successfully generated fragments): {len(frags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315d90a9-b66b-48c4-aaba-2dd1d5f47fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<rdkit.Chem.rdchem.Mol at 0x7fa3981dfc30>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7fa3981dfca0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7fa398b52ff0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7fa3981dc2e0>,\n",
       " <rdkit.Chem.rdchem.Mol at 0x7fa398b53a70>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f624dd0d-75c1-4845-ad98-c39180b4889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.11459999999999992,\n",
       " -0.46740000000000004,\n",
       " -0.12270000000000003,\n",
       " -0.4954,\n",
       " 0.03579999999999994]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contribs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84b764b6-5de3-48d2-958d-9de8726fbaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.1643"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "props[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121edf28-caeb-4a1a-a7bb-487feeaa72b9",
   "metadata": {},
   "source": [
    "### 3. Calculate fragment descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "692a1707-5126-4fb6-bc07-6bf784da8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fragment_descriptors(frags, n_bits=128, radius=2):\n",
    "    bags_descriptors = []\n",
    "    for frag in frags:\n",
    "        descs = [np.array(AllChem.GetMorganFingerprintAsBitVect(f, radius, nBits=n_bits)) for f in frag]\n",
    "        bags_descriptors.append(descs)\n",
    "    return bags_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9882c183-11aa-4964-8e1a-7e457c354f78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "desc = compute_fragment_descriptors(frags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ed31db-d1a4-4de7-b875-ea56f70147a5",
   "metadata": {},
   "source": [
    "### 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050d4308-c4dc-4a35-8a34-31ba1c11df64",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, key_train, key_test, frg_train, frg_test = train_test_split(desc, props, contribs, frags, random_state=42)\n",
    "#\n",
    "scaler = BagMinMaxScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016b8325-a377-4e10-b0c8-ed70e2542629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% | 18.1 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 35, Loss: 0.0033\n",
      "[2/28 |  7.1% | 17.3 min] Value: (256, 128, 64), Epochs: 58, Loss: 0.0027\n",
      "[3/28 | 10.7% | 10.9 min] Value: (128,), Epochs: 64, Loss: 0.0045\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0027\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% | 21.9 min] Value: relu, Epochs: 46, Loss: 0.0039\n",
      "[5/28 | 17.9% | 23.7 min] Value: leakyrelu, Epochs: 52, Loss: 0.0039\n",
      "[6/28 | 21.4% | 23.7 min] Value: gelu, Epochs: 51, Loss: 0.0028\n",
      "[7/28 | 25.0% | 17.1 min] Value: elu, Epochs: 33, Loss: 0.0054\n",
      "[8/28 | 28.6% | 23.7 min] Value: silu, Epochs: 67, Loss: 0.0032\n",
      "Best activation = gelu, val_loss = 0.0028\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% | 76.1 min] Value: 0.0001, Epochs: 180, Loss: 0.0030\n",
      "[10/28 | 35.7% | 33.3 min] Value: 0.001, Epochs: 42, Loss: 0.0028\n",
      "Best learning_rate = 0.001, val_loss = 0.0028\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% | 19.4 min] Value: 32, Epochs: 24, Loss: 0.0030\n",
      "[12/28 | 42.9% | 18.1 min] Value: 512, Epochs: 119, Loss: 0.0027\n",
      "[13/28 | 46.4% | 19.8 min] Value: 1024, Epochs: 177, Loss: 0.0027\n",
      "Best batch_size = 512, val_loss = 0.0027\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  9.0 min] Value: 0.0, Epochs: 112, Loss: 0.0029\n",
      "[15/28 | 53.6% |  8.6 min] Value: 1e-05, Epochs: 74, Loss: 0.0035\n",
      "[16/28 | 57.1% |  8.9 min] Value: 0.0001, Epochs: 101, Loss: 0.0028\n",
      "[17/28 | 60.7% |  7.5 min] Value: 0.001, Epochs: 60, Loss: 0.0040\n",
      "[18/28 | 64.3% |  8.5 min] Value: 0.01, Epochs: 70, Loss: 0.0040\n",
      "Best weight_decay = 0.0001, val_loss = 0.0028\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  4.3 min] Value: 0.0, Epochs: 58, Loss: 0.0044\n",
      "[20/28 | 71.4% |  4.2 min] Value: 0.2, Epochs: 45, Loss: 0.0109\n",
      "[21/28 | 75.0% |  2.9 min] Value: 0.4, Epochs: 27, Loss: 0.0200\n",
      "[22/28 | 78.6% |  4.3 min] Value: 0.6, Epochs: 59, Loss: 0.0220\n",
      "[23/28 | 82.1% |  4.1 min] Value: 0.8, Epochs: 42, Loss: 0.0348\n",
      "Best instance_dropout = 0.0, val_loss = 0.0044\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  5.9 min] Value: 1, Epochs: 56, Loss: 0.0046\n",
      "[25/28 | 89.3% |  7.5 min] Value: 2, Epochs: 106, Loss: 0.0036\n",
      "[26/28 | 92.9% |  6.6 min] Value: 3, Epochs: 66, Loss: 0.0040\n",
      "[27/28 | 96.4% |  7.4 min] Value: 4, Epochs: 96, Loss: 0.0033\n",
      "[28/28 | 100.0% |  7.4 min] Value: 5, Epochs: 91, Loss: 0.0034\n",
      "Best random_seed = 4, val_loss = 0.0033\n",
      "Stepwise optimization completed in 158.5 min\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DynamicPoolingNetworkRegressor(\n",
       "  (instance_transformer): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): GELU(approximate='none')\n",
       "  )\n",
       "  (bag_estimator): Norm()\n",
       "  (dynamic_pooling): DynamicPooling()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DynamicPoolingNetworkRegressor()\n",
    "model.hopt(x_train_scaled, y_train, param_grid=DEFAULT_PARAM_GRID, verbose=True)\n",
    "model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b9e45e-76b5-4fcd-a6fb-81a164bbdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_scaled)\n",
    "w_pred = model.get_instance_weights(x_test_scaled)\n",
    "w_pred = [w.flatten() for w in w_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71657a5d-fc8a-4ee0-a027-989392a00f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression R2: 0.71\n",
      "KID ranking accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(f\"Regression R2: {r2_score(y_test, y_pred):.2f}\")\n",
    "print(f\"KID ranking accuracy: {kid_ranking_accuracy(key_test, w_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b820883d-a563-4cca-81b3-42bb4bcd444f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 4\n",
    "display_fragments_with_weights(frg_test[N], key_test[N], w_pred[N], sort=True, max_fragments=10,\n",
    "                               title=f\"Bag {N}\\nPredicted label:{y_pred[N].item():.2f}\\nTrue label: {y_test[N]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d1b3a0-5393-4d86-a595-1d7c9d4833ee",
   "metadata": {},
   "source": [
    "### 4. Mini-benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9603049-4c2f-423a-b9e5-05437aac445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_list = [\n",
    "    \n",
    "        # attention mil networks\n",
    "        (\"AdditiveAttentionNetworkRegressor\", AdditiveAttentionNetworkRegressor()),\n",
    "        (\"SelfAttentionNetworkRegressor\", SelfAttentionNetworkRegressor()),\n",
    "        (\"HopfieldAttentionNetworkRegressor\", HopfieldAttentionNetworkRegressor()),\n",
    "\n",
    "        # other mil networks\n",
    "        (\"DynamicPoolingNetworkRegressor\", DynamicPoolingNetworkRegressor()),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4523bd06-47da-427f-85ac-9a3492778dd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Task 1/9] Starting task: 'LogP'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:25<00:00, 25.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.9 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 34, Loss: 0.4843\n",
      "[2/31 |  6.5% |  0.5 min] Value: (256, 128, 64), Epochs: 45, Loss: 0.6243\n",
      "[3/31 |  9.7% |  0.6 min] Value: (128,), Epochs: 64, Loss: 1.2810\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.4843\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.4 min] Value: relu, Epochs: 60, Loss: 0.6040\n",
      "[5/31 | 16.1% |  2.2 min] Value: leakyrelu, Epochs: 104, Loss: 0.4800\n",
      "[6/31 | 19.4% |  1.1 min] Value: gelu, Epochs: 47, Loss: 0.4927\n",
      "[7/31 | 22.6% |  1.7 min] Value: elu, Epochs: 73, Loss: 0.6336\n",
      "[8/31 | 25.8% |  1.8 min] Value: silu, Epochs: 76, Loss: 0.4185\n",
      "Best activation = silu, val_loss = 0.4185\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.5 min] Value: 0.0001, Epochs: 52, Loss: 0.5392\n",
      "[10/31 | 32.3% |  1.0 min] Value: 0.001, Epochs: 34, Loss: 0.4780\n",
      "Best learning_rate = 0.001, val_loss = 0.4780\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  1.6 min] Value: 32, Epochs: 21, Loss: 0.4656\n",
      "[12/31 | 38.7% |  1.7 min] Value: 512, Epochs: 93, Loss: 0.4350\n",
      "[13/31 | 41.9% |  1.7 min] Value: 1024, Epochs: 93, Loss: 0.4350\n",
      "Best batch_size = 512, val_loss = 0.4350\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.6 min] Value: 0.0, Epochs: 93, Loss: 0.4350\n",
      "[15/31 | 48.4% |  1.6 min] Value: 1e-05, Epochs: 93, Loss: 0.4350\n",
      "[16/31 | 51.6% |  1.6 min] Value: 0.0001, Epochs: 93, Loss: 0.4350\n",
      "[17/31 | 54.8% |  1.0 min] Value: 0.001, Epochs: 56, Loss: 0.5580\n",
      "[18/31 | 58.1% |  1.3 min] Value: 0.01, Epochs: 74, Loss: 0.5461\n",
      "Best weight_decay = 1e-05, val_loss = 0.4350\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.9 min] Value: 0.01, Epochs: 38, Loss: 2.1229\n",
      "[20/31 | 64.5% |  1.1 min] Value: 0.5, Epochs: 58, Loss: 0.6470\n",
      "[21/31 | 67.7% |  1.6 min] Value: 1.0, Epochs: 93, Loss: 0.4350\n",
      "Best tau = 1.0, val_loss = 0.4350\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.4 min] Value: 0.0, Epochs: 21, Loss: 1.2121\n",
      "[23/31 | 74.2% |  0.8 min] Value: 0.2, Epochs: 45, Loss: 0.7933\n",
      "[24/31 | 77.4% |  0.8 min] Value: 0.4, Epochs: 43, Loss: 1.0653\n",
      "[25/31 | 80.6% |  1.0 min] Value: 0.6, Epochs: 61, Loss: 1.0337\n",
      "[26/31 | 83.9% |  0.9 min] Value: 0.8, Epochs: 49, Loss: 1.2030\n",
      "Best instance_dropout = 0.2, val_loss = 0.7933\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.8 min] Value: 1, Epochs: 46, Loss: 0.7977\n",
      "[28/31 | 90.3% |  0.8 min] Value: 2, Epochs: 46, Loss: 0.7532\n",
      "[29/31 | 93.5% |  0.8 min] Value: 3, Epochs: 42, Loss: 0.8441\n",
      "[30/31 | 96.8% |  0.8 min] Value: 4, Epochs: 44, Loss: 0.7468\n",
      "[31/31 | 100.0% |  0.7 min] Value: 5, Epochs: 37, Loss: 0.7886\n",
      "Best random_seed = 4, val_loss = 0.7468\n",
      "Stepwise optimization completed in 11.4 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  1.1 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 39, Loss: 0.5205\n",
      "[2/31 |  6.5% |  0.7 min] Value: (256, 128, 64), Epochs: 53, Loss: 0.4186\n",
      "[3/31 |  9.7% |  0.8 min] Value: (128,), Epochs: 68, Loss: 0.5461\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.4186\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.0 min] Value: relu, Epochs: 131, Loss: 0.5705\n",
      "[5/31 | 16.1% |  0.5 min] Value: leakyrelu, Epochs: 49, Loss: 0.6608\n",
      "[6/31 | 19.4% |  0.7 min] Value: gelu, Epochs: 64, Loss: 0.4349\n",
      "[7/31 | 22.6% |  0.5 min] Value: elu, Epochs: 52, Loss: 0.3654\n",
      "[8/31 | 25.8% |  0.7 min] Value: silu, Epochs: 70, Loss: 0.3687\n",
      "Best activation = elu, val_loss = 0.3654\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  2.6 min] Value: 0.0001, Epochs: 203, Loss: 0.5040\n",
      "[10/31 | 32.3% |  1.3 min] Value: 0.001, Epochs: 89, Loss: 0.3288\n",
      "Best learning_rate = 0.001, val_loss = 0.3288\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.7 min] Value: 32, Epochs: 28, Loss: 0.4609\n",
      "[12/31 | 38.7% |  0.9 min] Value: 512, Epochs: 86, Loss: 0.3840\n",
      "[13/31 | 41.9% |  0.9 min] Value: 1024, Epochs: 86, Loss: 0.3840\n",
      "Best batch_size = 1024, val_loss = 0.3840\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.7 min] Value: 0.0, Epochs: 86, Loss: 0.3840\n",
      "[15/31 | 48.4% |  0.7 min] Value: 1e-05, Epochs: 86, Loss: 0.3840\n",
      "[16/31 | 51.6% |  0.7 min] Value: 0.0001, Epochs: 86, Loss: 0.3840\n",
      "[17/31 | 54.8% |  0.7 min] Value: 0.001, Epochs: 86, Loss: 0.3840\n",
      "[18/31 | 58.1% |  0.6 min] Value: 0.01, Epochs: 86, Loss: 0.3842\n",
      "Best weight_decay = 0.0, val_loss = 0.3840\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.8 min] Value: 0.01, Epochs: 76, Loss: 0.3596\n",
      "[20/31 | 64.5% |  0.6 min] Value: 0.5, Epochs: 58, Loss: 0.4158\n",
      "[21/31 | 67.7% |  0.8 min] Value: 1.0, Epochs: 86, Loss: 0.3840\n",
      "Best tau = 0.01, val_loss = 0.3596\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.0 min] Value: 0.0, Epochs: 203, Loss: 0.1665\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 31, Loss: 1.0887\n",
      "[24/31 | 77.4% |  0.3 min] Value: 0.4, Epochs: 46, Loss: 1.3093\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 40, Loss: 1.5602\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 42, Loss: 1.6420\n",
      "Best instance_dropout = 0.0, val_loss = 0.1665\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.5 min] Value: 1, Epochs: 58, Loss: 0.6912\n",
      "[28/31 | 90.3% |  0.6 min] Value: 2, Epochs: 74, Loss: 0.4559\n",
      "[29/31 | 93.5% |  0.5 min] Value: 3, Epochs: 71, Loss: 0.4221\n",
      "[30/31 | 96.8% |  0.5 min] Value: 4, Epochs: 61, Loss: 0.5086\n",
      "[31/31 | 100.0% |  0.6 min] Value: 5, Epochs: 84, Loss: 0.3481\n",
      "Best random_seed = 5, val_loss = 0.3481\n",
      "Stepwise optimization completed in 8.8 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.5 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 23, Loss: 2.4072\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 26, Loss: 2.0084\n",
      "[3/31 |  9.7% |  0.4 min] Value: (128,), Epochs: 66, Loss: 1.4873\n",
      "Best hidden_layer_sizes = (128,), val_loss = 1.4873\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.3 min] Value: relu, Epochs: 61, Loss: 1.6095\n",
      "[5/31 | 16.1% |  0.3 min] Value: leakyrelu, Epochs: 43, Loss: 1.6522\n",
      "[6/31 | 19.4% |  0.3 min] Value: gelu, Epochs: 42, Loss: 1.9236\n",
      "[7/31 | 22.6% |  0.3 min] Value: elu, Epochs: 57, Loss: 1.7169\n",
      "[8/31 | 25.8% |  0.5 min] Value: silu, Epochs: 101, Loss: 1.3133\n",
      "Best activation = silu, val_loss = 1.3133\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.8 min] Value: 0.0001, Epochs: 285, Loss: 1.5340\n",
      "[10/31 | 32.3% |  0.7 min] Value: 0.001, Epochs: 100, Loss: 1.2938\n",
      "Best learning_rate = 0.001, val_loss = 1.2938\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.5 min] Value: 32, Epochs: 37, Loss: 1.8280\n",
      "[12/31 | 38.7% |  0.5 min] Value: 512, Epochs: 141, Loss: 1.3298\n",
      "[13/31 | 41.9% |  0.2 min] Value: 1024, Epochs: 46, Loss: 1.9700\n",
      "Best batch_size = 512, val_loss = 1.3298\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.6 min] Value: 0.0, Epochs: 141, Loss: 1.3298\n",
      "[15/31 | 48.4% |  0.6 min] Value: 1e-05, Epochs: 141, Loss: 1.3298\n",
      "[16/31 | 51.6% |  0.6 min] Value: 0.0001, Epochs: 141, Loss: 1.3298\n",
      "[17/31 | 54.8% |  0.6 min] Value: 0.001, Epochs: 141, Loss: 1.3298\n",
      "[18/31 | 58.1% |  0.6 min] Value: 0.01, Epochs: 141, Loss: 1.3293\n",
      "Best weight_decay = 0.01, val_loss = 1.3293\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  1.5 min] Value: 0.01, Epochs: 404, Loss: 0.4216\n",
      "[20/31 | 64.5% |  0.9 min] Value: 0.5, Epochs: 209, Loss: 1.1575\n",
      "[21/31 | 67.7% |  0.6 min] Value: 1.0, Epochs: 141, Loss: 1.3293\n",
      "Best tau = 0.01, val_loss = 0.4216\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  2.5 min] Value: 0.0, Epochs: 1001, Loss: 0.3499\n",
      "[23/31 | 74.2% |  1.1 min] Value: 0.2, Epochs: 250, Loss: 0.7566\n",
      "[24/31 | 77.4% |  1.0 min] Value: 0.4, Epochs: 223, Loss: 1.1248\n",
      "[25/31 | 80.6% |  0.9 min] Value: 0.6, Epochs: 192, Loss: 1.4253\n",
      "[26/31 | 83.9% |  1.0 min] Value: 0.8, Epochs: 204, Loss: 1.6318\n",
      "Best instance_dropout = 0.0, val_loss = 0.3499\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  3.6 min] Value: 1, Epochs: 1001, Loss: 0.2882\n",
      "[28/31 | 90.3% |  3.6 min] Value: 2, Epochs: 1001, Loss: 0.2898\n",
      "[29/31 | 93.5% |  1.5 min] Value: 3, Epochs: 318, Loss: 0.4210\n",
      "[30/31 | 96.8% |  3.6 min] Value: 4, Epochs: 1001, Loss: 0.2901\n",
      "[31/31 | 100.0% |  1.6 min] Value: 5, Epochs: 368, Loss: 0.4488\n",
      "Best random_seed = 1, val_loss = 0.2882\n",
      "Stepwise optimization completed in 11.6 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.8 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 39, Loss: 0.0159\n",
      "[2/28 |  7.1% |  0.4 min] Value: (256, 128, 64), Epochs: 44, Loss: 0.0232\n",
      "[3/28 | 10.7% |  0.4 min] Value: (128,), Epochs: 51, Loss: 0.0320\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0159\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.8 min] Value: relu, Epochs: 42, Loss: 0.0203\n",
      "[5/28 | 17.9% |  0.7 min] Value: leakyrelu, Epochs: 32, Loss: 0.0196\n",
      "[6/28 | 21.4% |  1.3 min] Value: gelu, Epochs: 70, Loss: 0.0149\n",
      "[7/28 | 25.0% |  1.0 min] Value: elu, Epochs: 52, Loss: 0.0467\n",
      "[8/28 | 28.6% |  1.0 min] Value: silu, Epochs: 54, Loss: 0.0137\n",
      "Best activation = silu, val_loss = 0.0137\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  1.5 min] Value: 0.0001, Epochs: 72, Loss: 0.0187\n",
      "[10/28 | 35.7% |  0.7 min] Value: 0.001, Epochs: 29, Loss: 0.0178\n",
      "Best learning_rate = 0.001, val_loss = 0.0178\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  1.9 min] Value: 32, Epochs: 35, Loss: 0.0138\n",
      "[12/28 | 42.9% |  0.8 min] Value: 512, Epochs: 44, Loss: 0.0130\n",
      "[13/28 | 46.4% |  1.1 min] Value: 1024, Epochs: 66, Loss: 0.0180\n",
      "Best batch_size = 512, val_loss = 0.0130\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.9 min] Value: 0.0, Epochs: 54, Loss: 0.0126\n",
      "[15/28 | 53.6% |  0.8 min] Value: 1e-05, Epochs: 51, Loss: 0.0190\n",
      "[16/28 | 57.1% |  1.1 min] Value: 0.0001, Epochs: 66, Loss: 0.0180\n",
      "[17/28 | 60.7% |  1.1 min] Value: 0.001, Epochs: 66, Loss: 0.0179\n",
      "[18/28 | 64.3% |  1.1 min] Value: 0.01, Epochs: 66, Loss: 0.0174\n",
      "Best weight_decay = 0.0, val_loss = 0.0126\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.6 min] Value: 0.0, Epochs: 44, Loss: 0.0123\n",
      "[20/28 | 71.4% |  0.4 min] Value: 0.2, Epochs: 26, Loss: 0.0416\n",
      "[21/28 | 75.0% |  0.5 min] Value: 0.4, Epochs: 36, Loss: 0.0452\n",
      "[22/28 | 78.6% |  0.2 min] Value: 0.6, Epochs: 14, Loss: 0.1022\n",
      "[23/28 | 82.1% |  0.3 min] Value: 0.8, Epochs: 17, Loss: 0.1554\n",
      "Best instance_dropout = 0.0, val_loss = 0.0123\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.9 min] Value: 1, Epochs: 59, Loss: 0.0101\n",
      "[25/28 | 89.3% |  0.9 min] Value: 2, Epochs: 55, Loss: 0.0165\n",
      "[26/28 | 92.9% |  0.7 min] Value: 3, Epochs: 41, Loss: 0.0128\n",
      "[27/28 | 96.4% |  0.9 min] Value: 4, Epochs: 54, Loss: 0.0170\n",
      "[28/28 | 100.0% |  0.7 min] Value: 5, Epochs: 41, Loss: 0.0126\n",
      "Best random_seed = 1, val_loss = 0.0101\n",
      "Stepwise optimization completed in 8.1 min\n",
      "\n",
      "\n",
      "[Task 2/9] Starting task: 'MolWt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:21<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.8 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 44, Loss: 1275.9178\n",
      "[2/31 |  6.5% |  0.9 min] Value: (256, 128, 64), Epochs: 119, Loss: 1064.6215\n",
      "[3/31 |  9.7% |  2.0 min] Value: (128,), Epochs: 435, Loss: 4480.3716\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 1064.6215\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.8 min] Value: relu, Epochs: 122, Loss: 830.3524\n",
      "[5/31 | 16.1% |  0.8 min] Value: leakyrelu, Epochs: 126, Loss: 847.7144\n",
      "[6/31 | 19.4% |  0.7 min] Value: gelu, Epochs: 113, Loss: 896.3862\n",
      "[7/31 | 22.6% |  0.6 min] Value: elu, Epochs: 93, Loss: 1019.2482\n",
      "[8/31 | 25.8% |  0.8 min] Value: silu, Epochs: 118, Loss: 922.1566\n",
      "Best activation = relu, val_loss = 830.3524\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  2.4 min] Value: 0.0001, Epochs: 381, Loss: 3454.3811\n",
      "[10/31 | 32.3% |  0.5 min] Value: 0.001, Epochs: 70, Loss: 1024.5491\n",
      "Best learning_rate = 0.001, val_loss = 1024.5491\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.8 min] Value: 32, Epochs: 41, Loss: 873.6127\n",
      "[12/31 | 38.7% |  0.5 min] Value: 512, Epochs: 70, Loss: 1052.9829\n",
      "[13/31 | 41.9% |  0.6 min] Value: 1024, Epochs: 73, Loss: 922.4321\n",
      "Best batch_size = 32, val_loss = 873.6127\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.8 min] Value: 0.0, Epochs: 33, Loss: 960.8127\n",
      "[15/31 | 48.4% |  0.9 min] Value: 1e-05, Epochs: 39, Loss: 1019.2060\n",
      "[16/31 | 51.6% |  0.8 min] Value: 0.0001, Epochs: 33, Loss: 944.6947\n",
      "[17/31 | 54.8% |  0.8 min] Value: 0.001, Epochs: 33, Loss: 999.0504\n",
      "[18/31 | 58.1% |  0.9 min] Value: 0.01, Epochs: 41, Loss: 943.4150\n",
      "Best weight_decay = 0.01, val_loss = 943.4150\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  1.6 min] Value: 0.01, Epochs: 79, Loss: 920.6747\n",
      "[20/31 | 64.5% |  0.7 min] Value: 0.5, Epochs: 31, Loss: 873.4232\n",
      "[21/31 | 67.7% |  0.7 min] Value: 1.0, Epochs: 30, Loss: 888.0048\n",
      "Best tau = 0.5, val_loss = 873.4232\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.7 min] Value: 0.0, Epochs: 115, Loss: 301.3957\n",
      "[23/31 | 74.2% |  1.0 min] Value: 0.2, Epochs: 49, Loss: 993.9995\n",
      "[24/31 | 77.4% |  0.5 min] Value: 0.4, Epochs: 22, Loss: 1438.2603\n",
      "[25/31 | 80.6% |  0.5 min] Value: 0.6, Epochs: 19, Loss: 2127.2698\n",
      "[26/31 | 83.9% |  0.5 min] Value: 0.8, Epochs: 19, Loss: 2501.3396\n",
      "Best instance_dropout = 0.0, val_loss = 301.3957\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  2.5 min] Value: 1, Epochs: 102, Loss: 352.1408\n",
      "[28/31 | 90.3% |  2.7 min] Value: 2, Epochs: 110, Loss: 383.5530\n",
      "[29/31 | 93.5% |  3.9 min] Value: 3, Epochs: 174, Loss: 298.7798\n",
      "[30/31 | 96.8% |  3.9 min] Value: 4, Epochs: 176, Loss: 252.1052\n",
      "[31/31 | 100.0% |  4.6 min] Value: 5, Epochs: 238, Loss: 216.3497\n",
      "Best random_seed = 5, val_loss = 216.3497\n",
      "Stepwise optimization completed in 14.8 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  1.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 54, Loss: 2169.1594\n",
      "[2/31 |  6.5% |  0.6 min] Value: (256, 128, 64), Epochs: 55, Loss: 4553.4565\n",
      "[3/31 |  9.7% |  0.8 min] Value: (128,), Epochs: 103, Loss: 3539.0476\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 2169.1594\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.0 min] Value: relu, Epochs: 58, Loss: 2548.4373\n",
      "[5/31 | 16.1% |  1.0 min] Value: leakyrelu, Epochs: 54, Loss: 2543.6707\n",
      "[6/31 | 19.4% |  0.8 min] Value: gelu, Epochs: 41, Loss: 2258.6685\n",
      "[7/31 | 22.6% |  1.0 min] Value: elu, Epochs: 58, Loss: 2026.1672\n",
      "[8/31 | 25.8% |  0.7 min] Value: silu, Epochs: 38, Loss: 2137.7144\n",
      "Best activation = elu, val_loss = 2026.1672\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.1 min] Value: 0.0001, Epochs: 53, Loss: 5662.0610\n",
      "[10/31 | 32.3% |  1.2 min] Value: 0.001, Epochs: 58, Loss: 2026.7074\n",
      "Best learning_rate = 0.001, val_loss = 2026.7074\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  1.3 min] Value: 32, Epochs: 19, Loss: 2284.6912\n",
      "[12/31 | 38.7% |  1.3 min] Value: 512, Epochs: 69, Loss: 2034.6619\n",
      "[13/31 | 41.9% |  1.2 min] Value: 1024, Epochs: 58, Loss: 2028.2407\n",
      "Best batch_size = 1024, val_loss = 2028.2407\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.1 min] Value: 0.0, Epochs: 58, Loss: 2026.0957\n",
      "[15/31 | 48.4% |  1.1 min] Value: 1e-05, Epochs: 58, Loss: 2028.4741\n",
      "[16/31 | 51.6% |  1.1 min] Value: 0.0001, Epochs: 58, Loss: 2027.9958\n",
      "[17/31 | 54.8% |  1.1 min] Value: 0.001, Epochs: 58, Loss: 2028.7141\n",
      "[18/31 | 58.1% |  1.1 min] Value: 0.01, Epochs: 58, Loss: 2028.7241\n",
      "Best weight_decay = 0.0, val_loss = 2026.0957\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  1.2 min] Value: 0.01, Epochs: 58, Loss: 2028.5994\n",
      "[20/31 | 64.5% |  1.2 min] Value: 0.5, Epochs: 58, Loss: 2026.1757\n",
      "[21/31 | 67.7% |  1.2 min] Value: 1.0, Epochs: 58, Loss: 2009.6130\n",
      "Best tau = 1.0, val_loss = 2009.6130\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.1 min] Value: 0.0, Epochs: 70, Loss: 2019.6849\n",
      "[23/31 | 74.2% |  1.0 min] Value: 0.2, Epochs: 64, Loss: 2294.0447\n",
      "[24/31 | 77.4% |  0.4 min] Value: 0.4, Epochs: 21, Loss: 13680.6338\n",
      "[25/31 | 80.6% |  0.4 min] Value: 0.6, Epochs: 22, Loss: 14755.0508\n",
      "[26/31 | 83.9% |  0.4 min] Value: 0.8, Epochs: 22, Loss: 14856.3955\n",
      "Best instance_dropout = 0.0, val_loss = 2019.6849\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.4 min] Value: 1, Epochs: 16, Loss: 4967.7563\n",
      "[28/31 | 90.3% |  0.5 min] Value: 2, Epochs: 20, Loss: 6831.1797\n",
      "[29/31 | 93.5% |  1.1 min] Value: 3, Epochs: 58, Loss: 2100.5300\n",
      "[30/31 | 96.8% |  0.4 min] Value: 4, Epochs: 15, Loss: 3641.0876\n",
      "[31/31 | 100.0% |  1.0 min] Value: 5, Epochs: 58, Loss: 2009.5944\n",
      "Best random_seed = 5, val_loss = 2009.5944\n",
      "Stepwise optimization completed in 9.2 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.9 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 51, Loss: 2717.3938\n",
      "[2/31 |  6.5% |  2.7 min] Value: (256, 128, 64), Epochs: 444, Loss: 407.9911\n",
      "[3/31 |  9.7% |  3.5 min] Value: (128,), Epochs: 1001, Loss: 3652.2451\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 407.9911\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.4 min] Value: relu, Epochs: 69, Loss: 3372.6951\n",
      "[5/31 | 16.1% |  0.3 min] Value: leakyrelu, Epochs: 54, Loss: 6059.8022\n",
      "[6/31 | 19.4% |  0.4 min] Value: gelu, Epochs: 72, Loss: 6826.6758\n",
      "[7/31 | 22.6% |  0.4 min] Value: elu, Epochs: 73, Loss: 2518.4202\n",
      "[8/31 | 25.8% |  0.4 min] Value: silu, Epochs: 74, Loss: 6308.5498\n",
      "Best activation = elu, val_loss = 2518.4202\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  5.1 min] Value: 0.0001, Epochs: 1001, Loss: 935.1074\n",
      "[10/31 | 32.3% |  0.4 min] Value: 0.001, Epochs: 60, Loss: 2479.5625\n",
      "Best learning_rate = 0.0001, val_loss = 935.1074\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  6.5 min] Value: 32, Epochs: 550, Loss: 362.4538\n",
      "[12/31 | 38.7% |  5.8 min] Value: 512, Epochs: 1001, Loss: 2148.1785\n",
      "[13/31 | 41.9% |  5.8 min] Value: 1024, Epochs: 1001, Loss: 1230.8326\n",
      "Best batch_size = 32, val_loss = 362.4538\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  5.1 min] Value: 0.0, Epochs: 541, Loss: 384.8513\n",
      "[15/31 | 48.4% |  5.3 min] Value: 1e-05, Epochs: 589, Loss: 365.4468\n",
      "[16/31 | 51.6% |  5.3 min] Value: 0.0001, Epochs: 592, Loss: 344.4896\n",
      "[17/31 | 54.8% |  5.2 min] Value: 0.001, Epochs: 547, Loss: 377.0194\n",
      "[18/31 | 58.1% |  5.3 min] Value: 0.01, Epochs: 587, Loss: 358.3608\n",
      "Best weight_decay = 0.0001, val_loss = 344.4896\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  1.5 min] Value: 0.01, Epochs: 584, Loss: 344.1898\n",
      "[20/31 | 64.5% |  0.8 min] Value: 0.5, Epochs: 198, Loss: 2332.4524\n",
      "[21/31 | 67.7% |  0.9 min] Value: 1.0, Epochs: 236, Loss: 2264.2722\n",
      "Best tau = 0.01, val_loss = 344.1898\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.6 min] Value: 0.0, Epochs: 572, Loss: 378.2165\n",
      "[23/31 | 74.2% |  1.2 min] Value: 0.2, Epochs: 242, Loss: 1058.0748\n",
      "[24/31 | 77.4% |  1.0 min] Value: 0.4, Epochs: 160, Loss: 1412.6479\n",
      "[25/31 | 80.6% |  0.7 min] Value: 0.6, Epochs: 91, Loss: 1542.4814\n",
      "[26/31 | 83.9% |  0.6 min] Value: 0.8, Epochs: 67, Loss: 4510.5903\n",
      "Best instance_dropout = 0.0, val_loss = 378.2165\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.7 min] Value: 1, Epochs: 218, Loss: 2719.0312\n",
      "[28/31 | 90.3% |  3.9 min] Value: 2, Epochs: 546, Loss: 456.7707\n",
      "[29/31 | 93.5% |  4.0 min] Value: 3, Epochs: 573, Loss: 385.4108\n",
      "[30/31 | 96.8% |  3.9 min] Value: 4, Epochs: 556, Loss: 356.8721\n",
      "[31/31 | 100.0% |  4.1 min] Value: 5, Epochs: 628, Loss: 319.2651\n",
      "Best random_seed = 5, val_loss = 319.2651\n",
      "Stepwise optimization completed in 28.1 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 55, Loss: 0.0052\n",
      "[2/28 |  7.1% |  0.1 min] Value: (256, 128, 64), Epochs: 31, Loss: 0.0125\n",
      "[3/28 | 10.7% |  0.2 min] Value: (128,), Epochs: 126, Loss: 0.0135\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0052\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.8 min] Value: relu, Epochs: 106, Loss: 0.0052\n",
      "[5/28 | 17.9% |  0.5 min] Value: leakyrelu, Epochs: 57, Loss: 0.0055\n",
      "[6/28 | 21.4% |  0.5 min] Value: gelu, Epochs: 57, Loss: 0.0059\n",
      "[7/28 | 25.0% |  0.8 min] Value: elu, Epochs: 116, Loss: 0.0321\n",
      "[8/28 | 28.6% |  0.3 min] Value: silu, Epochs: 39, Loss: 0.0049\n",
      "Best activation = silu, val_loss = 0.0049\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  1.0 min] Value: 0.0001, Epochs: 206, Loss: 0.0058\n",
      "[10/28 | 35.7% |  0.4 min] Value: 0.001, Epochs: 55, Loss: 0.0052\n",
      "Best learning_rate = 0.001, val_loss = 0.0052\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.4 min] Value: 32, Epochs: 31, Loss: 0.0052\n",
      "[12/28 | 42.9% |  0.3 min] Value: 512, Epochs: 55, Loss: 0.0052\n",
      "[13/28 | 46.4% |  0.3 min] Value: 1024, Epochs: 55, Loss: 0.0052\n",
      "Best batch_size = 512, val_loss = 0.0052\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.4 min] Value: 0.0, Epochs: 77, Loss: 0.0048\n",
      "[15/28 | 53.6% |  0.4 min] Value: 1e-05, Epochs: 55, Loss: 0.0052\n",
      "[16/28 | 57.1% |  0.3 min] Value: 0.0001, Epochs: 55, Loss: 0.0052\n",
      "[17/28 | 60.7% |  0.4 min] Value: 0.001, Epochs: 58, Loss: 0.0051\n",
      "[18/28 | 64.3% |  0.4 min] Value: 0.01, Epochs: 74, Loss: 0.0043\n",
      "Best weight_decay = 0.01, val_loss = 0.0043\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.3 min] Value: 0.0, Epochs: 58, Loss: 0.0051\n",
      "[20/28 | 71.4% |  0.2 min] Value: 0.2, Epochs: 38, Loss: 0.0170\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 14, Loss: 0.0544\n",
      "[22/28 | 78.6% |  0.2 min] Value: 0.6, Epochs: 25, Loss: 0.0716\n",
      "[23/28 | 82.1% |  0.2 min] Value: 0.8, Epochs: 24, Loss: 0.1147\n",
      "Best instance_dropout = 0.0, val_loss = 0.0051\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.4 min] Value: 1, Epochs: 58, Loss: 0.0051\n",
      "[25/28 | 89.3% |  0.4 min] Value: 2, Epochs: 62, Loss: 0.0052\n",
      "[26/28 | 92.9% |  0.4 min] Value: 3, Epochs: 72, Loss: 0.0047\n",
      "[27/28 | 96.4% |  0.3 min] Value: 4, Epochs: 48, Loss: 0.0047\n",
      "[28/28 | 100.0% |  0.4 min] Value: 5, Epochs: 58, Loss: 0.0055\n",
      "Best random_seed = 4, val_loss = 0.0047\n",
      "Stepwise optimization completed in 3.7 min\n",
      "\n",
      "\n",
      "[Task 3/9] Starting task: 'TPSA'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:15<00:00, 43.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.7 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 54, Loss: 94.7771\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 28, Loss: 245.9736\n",
      "[3/31 |  9.7% |  0.2 min] Value: (128,), Epochs: 43, Loss: 347.3000\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 94.7771\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.9 min] Value: relu, Epochs: 57, Loss: 109.8288\n",
      "[5/31 | 16.1% |  0.7 min] Value: leakyrelu, Epochs: 40, Loss: 94.2263\n",
      "[6/31 | 19.4% |  0.5 min] Value: gelu, Epochs: 26, Loss: 101.8193\n",
      "[7/31 | 22.6% |  0.5 min] Value: elu, Epochs: 23, Loss: 216.2474\n",
      "[8/31 | 25.8% |  0.9 min] Value: silu, Epochs: 48, Loss: 160.6714\n",
      "Best activation = leakyrelu, val_loss = 94.2263\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.6 min] Value: 0.0001, Epochs: 35, Loss: 230.5230\n",
      "[10/31 | 32.3% |  1.5 min] Value: 0.001, Epochs: 68, Loss: 93.6509\n",
      "Best learning_rate = 0.001, val_loss = 93.6509\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  1.5 min] Value: 32, Epochs: 65, Loss: 88.9847\n",
      "[12/31 | 38.7% |  0.6 min] Value: 512, Epochs: 94, Loss: 133.2931\n",
      "[13/31 | 41.9% |  0.9 min] Value: 1024, Epochs: 115, Loss: 137.0252\n",
      "Best batch_size = 32, val_loss = 88.9847\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.3 min] Value: 0.0, Epochs: 42, Loss: 89.7961\n",
      "[15/31 | 48.4% |  1.4 min] Value: 1e-05, Epochs: 40, Loss: 94.9621\n",
      "[16/31 | 51.6% |  1.3 min] Value: 0.0001, Epochs: 38, Loss: 81.4016\n",
      "[17/31 | 54.8% |  1.5 min] Value: 0.001, Epochs: 48, Loss: 91.6164\n",
      "[18/31 | 58.1% |  1.4 min] Value: 0.01, Epochs: 43, Loss: 99.4487\n",
      "Best weight_decay = 0.0001, val_loss = 81.4016\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.8 min] Value: 0.01, Epochs: 25, Loss: 417.2214\n",
      "[20/31 | 64.5% |  0.8 min] Value: 0.5, Epochs: 29, Loss: 111.6553\n",
      "[21/31 | 67.7% |  1.2 min] Value: 1.0, Epochs: 45, Loss: 96.6311\n",
      "Best tau = 1.0, val_loss = 96.6311\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.9 min] Value: 0.0, Epochs: 28, Loss: 91.0882\n",
      "[23/31 | 74.2% |  0.9 min] Value: 0.2, Epochs: 24, Loss: 175.4948\n",
      "[24/31 | 77.4% |  1.1 min] Value: 0.4, Epochs: 33, Loss: 235.4409\n",
      "[25/31 | 80.6% |  1.0 min] Value: 0.6, Epochs: 30, Loss: 274.8243\n",
      "[26/31 | 83.9% |  0.8 min] Value: 0.8, Epochs: 25, Loss: 309.0078\n",
      "Best instance_dropout = 0.0, val_loss = 91.0882\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.9 min] Value: 1, Epochs: 40, Loss: 89.9833\n",
      "[28/31 | 90.3% |  0.9 min] Value: 2, Epochs: 37, Loss: 83.4843\n",
      "[29/31 | 93.5% |  1.2 min] Value: 3, Epochs: 54, Loss: 99.3455\n",
      "[30/31 | 96.8% |  1.0 min] Value: 4, Epochs: 39, Loss: 101.2515\n",
      "[31/31 | 100.0% |  0.9 min] Value: 5, Epochs: 46, Loss: 92.9282\n",
      "Best random_seed = 2, val_loss = 83.4843\n",
      "Stepwise optimization completed in 9.7 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.4 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 53, Loss: 256.3267\n",
      "[2/31 |  6.5% |  0.1 min] Value: (256, 128, 64), Epochs: 27, Loss: 356.6534\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 45, Loss: 372.0869\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 256.3267\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.8 min] Value: relu, Epochs: 70, Loss: 230.6910\n",
      "[5/31 | 16.1% |  0.9 min] Value: leakyrelu, Epochs: 62, Loss: 242.1532\n",
      "[6/31 | 19.4% |  0.8 min] Value: gelu, Epochs: 38, Loss: 279.4164\n",
      "[7/31 | 22.6% |  0.9 min] Value: elu, Epochs: 58, Loss: 283.5821\n",
      "[8/31 | 25.8% |  0.6 min] Value: silu, Epochs: 38, Loss: 295.0632\n",
      "Best activation = relu, val_loss = 230.6910\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.3 min] Value: 0.0001, Epochs: 38, Loss: 395.6843\n",
      "[10/31 | 32.3% |  0.5 min] Value: 0.001, Epochs: 71, Loss: 238.4698\n",
      "Best learning_rate = 0.001, val_loss = 238.4698\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.6 min] Value: 32, Epochs: 34, Loss: 267.8870\n",
      "[12/31 | 38.7% |  0.4 min] Value: 512, Epochs: 71, Loss: 238.4431\n",
      "[13/31 | 41.9% |  0.7 min] Value: 1024, Epochs: 68, Loss: 243.4537\n",
      "Best batch_size = 512, val_loss = 238.4431\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.9 min] Value: 0.0, Epochs: 66, Loss: 235.8190\n",
      "[15/31 | 48.4% |  0.9 min] Value: 1e-05, Epochs: 64, Loss: 240.9841\n",
      "[16/31 | 51.6% |  0.8 min] Value: 0.0001, Epochs: 71, Loss: 238.4158\n",
      "[17/31 | 54.8% |  0.8 min] Value: 0.001, Epochs: 71, Loss: 238.3322\n",
      "[18/31 | 58.1% |  0.8 min] Value: 0.01, Epochs: 71, Loss: 238.0628\n",
      "Best weight_decay = 0.0, val_loss = 235.8190\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.6 min] Value: 0.01, Epochs: 71, Loss: 236.2099\n",
      "[20/31 | 64.5% |  0.7 min] Value: 0.5, Epochs: 72, Loss: 237.1366\n",
      "[21/31 | 67.7% |  0.7 min] Value: 1.0, Epochs: 71, Loss: 238.4836\n",
      "Best tau = 0.01, val_loss = 236.2099\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 70, Loss: 236.1543\n",
      "[23/31 | 74.2% |  0.5 min] Value: 0.2, Epochs: 66, Loss: 235.7363\n",
      "[24/31 | 77.4% |  0.5 min] Value: 0.4, Epochs: 55, Loss: 285.5323\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 43, Loss: 288.3689\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 19, Loss: 1435.3256\n",
      "Best instance_dropout = 0.2, val_loss = 235.7363\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.2 min] Value: 1, Epochs: 17, Loss: 557.3022\n",
      "[28/31 | 90.3% |  0.4 min] Value: 2, Epochs: 58, Loss: 246.6113\n",
      "[29/31 | 93.5% |  0.6 min] Value: 3, Epochs: 58, Loss: 241.7010\n",
      "[30/31 | 96.8% |  0.6 min] Value: 4, Epochs: 55, Loss: 248.9332\n",
      "[31/31 | 100.0% |  0.6 min] Value: 5, Epochs: 67, Loss: 253.5345\n",
      "Best random_seed = 3, val_loss = 241.7010\n",
      "Stepwise optimization completed in 5.2 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  1.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 47, Loss: 132.8170\n",
      "[2/31 |  6.5% |  1.7 min] Value: (256, 128, 64), Epochs: 282, Loss: 186.6301\n",
      "[3/31 |  9.7% |  3.6 min] Value: (128,), Epochs: 1001, Loss: 223.7701\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 132.8170\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  2.3 min] Value: relu, Epochs: 113, Loss: 122.6962\n",
      "[5/31 | 16.1% |  2.3 min] Value: leakyrelu, Epochs: 106, Loss: 122.6222\n",
      "[6/31 | 19.4% |  1.1 min] Value: gelu, Epochs: 39, Loss: 296.9351\n",
      "[7/31 | 22.6% |  1.6 min] Value: elu, Epochs: 65, Loss: 151.7322\n",
      "[8/31 | 25.8% |  1.3 min] Value: silu, Epochs: 63, Loss: 167.9353\n",
      "Best activation = leakyrelu, val_loss = 122.6222\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.3 min] Value: 0.0001, Epochs: 111, Loss: 125.1281\n",
      "[10/31 | 32.3% |  0.6 min] Value: 0.001, Epochs: 41, Loss: 123.4724\n",
      "Best learning_rate = 0.001, val_loss = 123.4724\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.9 min] Value: 32, Epochs: 44, Loss: 111.4061\n",
      "[12/31 | 38.7% |  0.4 min] Value: 512, Epochs: 54, Loss: 230.5287\n",
      "[13/31 | 41.9% |  0.4 min] Value: 1024, Epochs: 53, Loss: 240.3201\n",
      "Best batch_size = 32, val_loss = 111.4061\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.5 min] Value: 0.0, Epochs: 29, Loss: 212.3279\n",
      "[15/31 | 48.4% |  0.7 min] Value: 1e-05, Epochs: 27, Loss: 164.0123\n",
      "[16/31 | 51.6% |  0.7 min] Value: 0.0001, Epochs: 35, Loss: 121.4282\n",
      "[17/31 | 54.8% |  0.9 min] Value: 0.001, Epochs: 61, Loss: 108.7565\n",
      "[18/31 | 58.1% |  1.1 min] Value: 0.01, Epochs: 52, Loss: 113.0386\n",
      "Best weight_decay = 0.001, val_loss = 108.7565\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.9 min] Value: 0.01, Epochs: 38, Loss: 114.4009\n",
      "[20/31 | 64.5% |  0.7 min] Value: 0.5, Epochs: 26, Loss: 284.4168\n",
      "[21/31 | 67.7% |  0.5 min] Value: 1.0, Epochs: 22, Loss: 268.1406\n",
      "Best tau = 0.01, val_loss = 114.4009\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.1 min] Value: 0.0, Epochs: 51, Loss: 99.3641\n",
      "[23/31 | 74.2% |  0.7 min] Value: 0.2, Epochs: 23, Loss: 278.4124\n",
      "[24/31 | 77.4% |  0.7 min] Value: 0.4, Epochs: 21, Loss: 250.7025\n",
      "[25/31 | 80.6% |  0.9 min] Value: 0.6, Epochs: 28, Loss: 293.7979\n",
      "[26/31 | 83.9% |  1.1 min] Value: 0.8, Epochs: 39, Loss: 512.2309\n",
      "Best instance_dropout = 0.0, val_loss = 99.3641\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.9 min] Value: 1, Epochs: 36, Loss: 98.6026\n",
      "[28/31 | 90.3% |  0.8 min] Value: 2, Epochs: 30, Loss: 106.1464\n",
      "[29/31 | 93.5% |  1.0 min] Value: 3, Epochs: 45, Loss: 107.1560\n",
      "[30/31 | 96.8% |  1.3 min] Value: 4, Epochs: 58, Loss: 102.0553\n",
      "[31/31 | 100.0% |  0.9 min] Value: 5, Epochs: 39, Loss: 128.1979\n",
      "Best random_seed = 1, val_loss = 98.6026\n",
      "Stepwise optimization completed in 12.5 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 37, Loss: 0.0086\n",
      "[2/28 |  7.1% |  0.0 min] Value: (256, 128, 64), Epochs: 18, Loss: 0.0195\n",
      "[3/28 | 10.7% |  0.2 min] Value: (128,), Epochs: 138, Loss: 0.0282\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0086\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.1 min] Value: relu, Epochs: 14, Loss: 0.0303\n",
      "[5/28 | 17.9% |  0.4 min] Value: leakyrelu, Epochs: 56, Loss: 0.0084\n",
      "[6/28 | 21.4% |  0.4 min] Value: gelu, Epochs: 72, Loss: 0.0077\n",
      "[7/28 | 25.0% |  0.5 min] Value: elu, Epochs: 78, Loss: 0.0276\n",
      "[8/28 | 28.6% |  0.3 min] Value: silu, Epochs: 33, Loss: 0.0093\n",
      "Best activation = gelu, val_loss = 0.0077\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.2 min] Value: 0.0001, Epochs: 43, Loss: 0.0182\n",
      "[10/28 | 35.7% |  0.3 min] Value: 0.001, Epochs: 72, Loss: 0.0077\n",
      "Best learning_rate = 0.001, val_loss = 0.0077\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.9 min] Value: 32, Epochs: 43, Loss: 0.0048\n",
      "[12/28 | 42.9% |  0.4 min] Value: 512, Epochs: 72, Loss: 0.0077\n",
      "[13/28 | 46.4% |  0.5 min] Value: 1024, Epochs: 72, Loss: 0.0077\n",
      "Best batch_size = 32, val_loss = 0.0048\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.8 min] Value: 0.0, Epochs: 34, Loss: 0.0058\n",
      "[15/28 | 53.6% |  0.8 min] Value: 1e-05, Epochs: 33, Loss: 0.0062\n",
      "[16/28 | 57.1% |  0.6 min] Value: 0.0001, Epochs: 29, Loss: 0.0072\n",
      "[17/28 | 60.7% |  0.5 min] Value: 0.001, Epochs: 22, Loss: 0.0074\n",
      "[18/28 | 64.3% |  0.6 min] Value: 0.01, Epochs: 27, Loss: 0.0074\n",
      "Best weight_decay = 0.0, val_loss = 0.0058\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.7 min] Value: 0.0, Epochs: 29, Loss: 0.0068\n",
      "[20/28 | 71.4% |  0.6 min] Value: 0.2, Epochs: 28, Loss: 0.0175\n",
      "[21/28 | 75.0% |  0.4 min] Value: 0.4, Epochs: 16, Loss: 0.0340\n",
      "[22/28 | 78.6% |  0.5 min] Value: 0.6, Epochs: 22, Loss: 0.0636\n",
      "[23/28 | 82.1% |  0.5 min] Value: 0.8, Epochs: 16, Loss: 0.1361\n",
      "Best instance_dropout = 0.0, val_loss = 0.0068\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.8 min] Value: 1, Epochs: 33, Loss: 0.0058\n",
      "[25/28 | 89.3% |  0.8 min] Value: 2, Epochs: 35, Loss: 0.0061\n",
      "[26/28 | 92.9% |  1.0 min] Value: 3, Epochs: 48, Loss: 0.0067\n",
      "[27/28 | 96.4% |  0.7 min] Value: 4, Epochs: 26, Loss: 0.0069\n",
      "[28/28 | 100.0% |  0.6 min] Value: 5, Epochs: 24, Loss: 0.0072\n",
      "Best random_seed = 1, val_loss = 0.0058\n",
      "Stepwise optimization completed in 4.2 min\n",
      "\n",
      "\n",
      "[Task 4/9] Starting task: 'NumHDonors'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:18<00:00, 36.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 25, Loss: 0.1037\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 32, Loss: 0.2516\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 17, Loss: 0.5714\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.1037\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.8 min] Value: relu, Epochs: 64, Loss: 0.0837\n",
      "[5/31 | 16.1% |  0.6 min] Value: leakyrelu, Epochs: 29, Loss: 0.1084\n",
      "[6/31 | 19.4% |  0.5 min] Value: gelu, Epochs: 25, Loss: 0.1075\n",
      "[7/31 | 22.6% |  0.5 min] Value: elu, Epochs: 20, Loss: 0.1774\n",
      "[8/31 | 25.8% |  0.5 min] Value: silu, Epochs: 30, Loss: 0.0985\n",
      "Best activation = relu, val_loss = 0.0837\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.6 min] Value: 0.0001, Epochs: 43, Loss: 0.1279\n",
      "[10/31 | 32.3% |  0.4 min] Value: 0.001, Epochs: 25, Loss: 0.1023\n",
      "Best learning_rate = 0.001, val_loss = 0.1023\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.5 min] Value: 32, Epochs: 31, Loss: 0.1061\n",
      "[12/31 | 38.7% |  0.4 min] Value: 512, Epochs: 79, Loss: 0.0849\n",
      "[13/31 | 41.9% |  0.4 min] Value: 1024, Epochs: 79, Loss: 0.0849\n",
      "Best batch_size = 512, val_loss = 0.0849\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.5 min] Value: 0.0, Epochs: 69, Loss: 0.0811\n",
      "[15/31 | 48.4% |  0.6 min] Value: 1e-05, Epochs: 80, Loss: 0.0854\n",
      "[16/31 | 51.6% |  0.6 min] Value: 0.0001, Epochs: 79, Loss: 0.0852\n",
      "[17/31 | 54.8% |  0.4 min] Value: 0.001, Epochs: 61, Loss: 0.0884\n",
      "[18/31 | 58.1% |  0.5 min] Value: 0.01, Epochs: 65, Loss: 0.0886\n",
      "Best weight_decay = 0.0, val_loss = 0.0811\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.1 min] Value: 0.01, Epochs: 20, Loss: 0.6257\n",
      "[20/31 | 64.5% |  0.4 min] Value: 0.5, Epochs: 79, Loss: 0.1003\n",
      "[21/31 | 67.7% |  0.3 min] Value: 1.0, Epochs: 80, Loss: 0.0853\n",
      "Best tau = 1.0, val_loss = 0.0853\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 80, Loss: 0.0854\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 33, Loss: 0.2280\n",
      "[24/31 | 77.4% |  0.3 min] Value: 0.4, Epochs: 43, Loss: 0.4377\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 49, Loss: 0.4045\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 49, Loss: 0.5278\n",
      "Best instance_dropout = 0.0, val_loss = 0.0854\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.3 min] Value: 1, Epochs: 43, Loss: 0.1645\n",
      "[28/31 | 90.3% |  0.6 min] Value: 2, Epochs: 80, Loss: 0.0851\n",
      "[29/31 | 93.5% |  0.6 min] Value: 3, Epochs: 84, Loss: 0.1107\n",
      "[30/31 | 96.8% |  0.4 min] Value: 4, Epochs: 60, Loss: 0.0912\n",
      "[31/31 | 100.0% |  0.5 min] Value: 5, Epochs: 67, Loss: 0.1057\n",
      "Best random_seed = 2, val_loss = 0.0851\n",
      "Stepwise optimization completed in 4.2 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.1 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 25, Loss: 0.5404\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 85, Loss: 0.3042\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 53, Loss: 0.4311\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.3042\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 43, Loss: 0.4151\n",
      "[5/31 | 16.1% |  0.1 min] Value: leakyrelu, Epochs: 26, Loss: 0.5534\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 25, Loss: 0.4975\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 59, Loss: 0.2716\n",
      "[8/31 | 25.8% |  0.1 min] Value: silu, Epochs: 41, Loss: 0.4443\n",
      "Best activation = elu, val_loss = 0.2716\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.0 min] Value: 0.0001, Epochs: 25, Loss: 0.7633\n",
      "[10/31 | 32.3% |  0.1 min] Value: 0.001, Epochs: 72, Loss: 0.2573\n",
      "Best learning_rate = 0.001, val_loss = 0.2573\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 34, Loss: 0.2248\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 55, Loss: 0.2868\n",
      "[13/31 | 41.9% |  0.1 min] Value: 1024, Epochs: 58, Loss: 0.2669\n",
      "Best batch_size = 32, val_loss = 0.2248\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.2 min] Value: 0.0, Epochs: 22, Loss: 0.3329\n",
      "[15/31 | 48.4% |  0.2 min] Value: 1e-05, Epochs: 25, Loss: 0.2758\n",
      "[16/31 | 51.6% |  0.2 min] Value: 0.0001, Epochs: 22, Loss: 0.2366\n",
      "[17/31 | 54.8% |  0.2 min] Value: 0.001, Epochs: 23, Loss: 0.3049\n",
      "[18/31 | 58.1% |  0.2 min] Value: 0.01, Epochs: 26, Loss: 0.2867\n",
      "Best weight_decay = 0.0001, val_loss = 0.2366\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.1 min] Value: 0.01, Epochs: 21, Loss: 0.4875\n",
      "[20/31 | 64.5% |  0.2 min] Value: 0.5, Epochs: 42, Loss: 0.2454\n",
      "[21/31 | 67.7% |  0.1 min] Value: 1.0, Epochs: 20, Loss: 0.2727\n",
      "Best tau = 0.5, val_loss = 0.2454\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.3 min] Value: 0.0, Epochs: 33, Loss: 0.1224\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 26, Loss: 0.2524\n",
      "[24/31 | 77.4% |  0.3 min] Value: 0.4, Epochs: 35, Loss: 0.3511\n",
      "[25/31 | 80.6% |  0.2 min] Value: 0.6, Epochs: 15, Loss: 0.4901\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 28, Loss: 0.4714\n",
      "Best instance_dropout = 0.0, val_loss = 0.1224\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.3 min] Value: 1, Epochs: 42, Loss: 0.1329\n",
      "[28/31 | 90.3% |  0.3 min] Value: 2, Epochs: 33, Loss: 0.1548\n",
      "[29/31 | 93.5% |  0.2 min] Value: 3, Epochs: 27, Loss: 0.1394\n",
      "[30/31 | 96.8% |  0.3 min] Value: 4, Epochs: 29, Loss: 0.1418\n",
      "[31/31 | 100.0% |  0.4 min] Value: 5, Epochs: 74, Loss: 0.1101\n",
      "Best random_seed = 5, val_loss = 0.1101\n",
      "Stepwise optimization completed in 1.6 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 22, Loss: 0.1225\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 55, Loss: 0.0895\n",
      "[3/31 |  9.7% |  0.2 min] Value: (128,), Epochs: 80, Loss: 0.1422\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0895\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.4 min] Value: relu, Epochs: 64, Loss: 0.0865\n",
      "[5/31 | 16.1% |  0.4 min] Value: leakyrelu, Epochs: 80, Loss: 0.0816\n",
      "[6/31 | 19.4% |  0.4 min] Value: gelu, Epochs: 56, Loss: 0.1208\n",
      "[7/31 | 22.6% |  0.2 min] Value: elu, Epochs: 26, Loss: 0.1627\n",
      "[8/31 | 25.8% |  0.3 min] Value: silu, Epochs: 41, Loss: 0.1964\n",
      "Best activation = leakyrelu, val_loss = 0.0816\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.5 min] Value: 0.0001, Epochs: 233, Loss: 0.0969\n",
      "[10/31 | 32.3% |  0.2 min] Value: 0.001, Epochs: 63, Loss: 0.0842\n",
      "Best learning_rate = 0.001, val_loss = 0.0842\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.3 min] Value: 32, Epochs: 59, Loss: 0.0876\n",
      "[12/31 | 38.7% |  0.2 min] Value: 512, Epochs: 171, Loss: 0.0933\n",
      "[13/31 | 41.9% |  0.8 min] Value: 1024, Epochs: 949, Loss: 0.0873\n",
      "Best batch_size = 1024, val_loss = 0.0873\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.0 min] Value: 0.0, Epochs: 394, Loss: 0.0924\n",
      "[15/31 | 48.4% |  0.9 min] Value: 1e-05, Epochs: 394, Loss: 0.0924\n",
      "[16/31 | 51.6% |  1.2 min] Value: 0.0001, Epochs: 766, Loss: 0.0882\n",
      "[17/31 | 54.8% |  1.3 min] Value: 0.001, Epochs: 1001, Loss: 0.0884\n",
      "[18/31 | 58.1% |  0.7 min] Value: 0.01, Epochs: 297, Loss: 0.0908\n",
      "Best weight_decay = 0.0001, val_loss = 0.0882\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.3 min] Value: 0.01, Epochs: 393, Loss: 0.0931\n",
      "[20/31 | 64.5% |  0.0 min] Value: 0.5, Epochs: 30, Loss: 0.3694\n",
      "[21/31 | 67.7% |  0.1 min] Value: 1.0, Epochs: 38, Loss: 0.4322\n",
      "Best tau = 0.01, val_loss = 0.0931\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.3 min] Value: 0.0, Epochs: 396, Loss: 0.0931\n",
      "[23/31 | 74.2% |  0.1 min] Value: 0.2, Epochs: 82, Loss: 0.2421\n",
      "[24/31 | 77.4% |  0.1 min] Value: 0.4, Epochs: 65, Loss: 0.3271\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 31, Loss: 0.4619\n",
      "[26/31 | 83.9% |  0.1 min] Value: 0.8, Epochs: 29, Loss: 0.5115\n",
      "Best instance_dropout = 0.0, val_loss = 0.0931\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.5 min] Value: 1, Epochs: 860, Loss: 0.0916\n",
      "[28/31 | 90.3% |  0.2 min] Value: 2, Epochs: 120, Loss: 0.1451\n",
      "[29/31 | 93.5% |  0.1 min] Value: 3, Epochs: 34, Loss: 0.4736\n",
      "[30/31 | 96.8% |  0.2 min] Value: 4, Epochs: 105, Loss: 0.1115\n",
      "[31/31 | 100.0% |  0.2 min] Value: 5, Epochs: 118, Loss: 0.1090\n",
      "Best random_seed = 1, val_loss = 0.0916\n",
      "Stepwise optimization completed in 4.3 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.4 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 33, Loss: 0.0060\n",
      "[2/28 |  7.1% |  0.4 min] Value: (256, 128, 64), Epochs: 72, Loss: 0.0103\n",
      "[3/28 | 10.7% |  0.2 min] Value: (128,), Epochs: 56, Loss: 0.0343\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0060\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  1.0 min] Value: relu, Epochs: 49, Loss: 0.0065\n",
      "[5/28 | 17.9% |  1.0 min] Value: leakyrelu, Epochs: 56, Loss: 0.0062\n",
      "[6/28 | 21.4% |  0.9 min] Value: gelu, Epochs: 43, Loss: 0.0054\n",
      "[7/28 | 25.0% |  1.0 min] Value: elu, Epochs: 48, Loss: 0.0227\n",
      "[8/28 | 28.6% |  0.8 min] Value: silu, Epochs: 39, Loss: 0.0068\n",
      "Best activation = gelu, val_loss = 0.0054\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.4 min] Value: 0.0001, Epochs: 22, Loss: 0.0187\n",
      "[10/28 | 35.7% |  0.4 min] Value: 0.001, Epochs: 27, Loss: 0.0050\n",
      "Best learning_rate = 0.001, val_loss = 0.0050\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.6 min] Value: 32, Epochs: 39, Loss: 0.0059\n",
      "[12/28 | 42.9% |  0.4 min] Value: 512, Epochs: 69, Loss: 0.0069\n",
      "[13/28 | 46.4% |  0.4 min] Value: 1024, Epochs: 69, Loss: 0.0069\n",
      "Best batch_size = 32, val_loss = 0.0059\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.5 min] Value: 0.0, Epochs: 23, Loss: 0.0053\n",
      "[15/28 | 53.6% |  0.6 min] Value: 1e-05, Epochs: 29, Loss: 0.0052\n",
      "[16/28 | 57.1% |  0.7 min] Value: 0.0001, Epochs: 36, Loss: 0.0060\n",
      "[17/28 | 60.7% |  0.8 min] Value: 0.001, Epochs: 47, Loss: 0.0070\n",
      "[18/28 | 64.3% |  0.7 min] Value: 0.01, Epochs: 44, Loss: 0.0063\n",
      "Best weight_decay = 1e-05, val_loss = 0.0052\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.4 min] Value: 0.0, Epochs: 27, Loss: 0.0121\n",
      "[20/28 | 71.4% |  0.5 min] Value: 0.2, Epochs: 22, Loss: 0.0240\n",
      "[21/28 | 75.0% |  0.2 min] Value: 0.4, Epochs: 12, Loss: 0.0408\n",
      "[22/28 | 78.6% |  0.2 min] Value: 0.6, Epochs: 12, Loss: 0.0763\n",
      "[23/28 | 82.1% |  0.4 min] Value: 0.8, Epochs: 18, Loss: 0.1455\n",
      "Best instance_dropout = 0.0, val_loss = 0.0121\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.7 min] Value: 1, Epochs: 38, Loss: 0.0064\n",
      "[25/28 | 89.3% |  0.5 min] Value: 2, Epochs: 28, Loss: 0.0082\n",
      "[26/28 | 92.9% |  0.7 min] Value: 3, Epochs: 30, Loss: 0.0062\n",
      "[27/28 | 96.4% |  0.7 min] Value: 4, Epochs: 35, Loss: 0.0059\n",
      "[28/28 | 100.0% |  0.7 min] Value: 5, Epochs: 37, Loss: 0.0081\n",
      "Best random_seed = 4, val_loss = 0.0059\n",
      "Stepwise optimization completed in 4.3 min\n",
      "\n",
      "\n",
      "[Task 5/9] Starting task: 'NumHAcceptors'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:17<00:00, 39.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.5 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 153, Loss: 0.2044\n",
      "[2/31 |  6.5% |  0.0 min] Value: (256, 128, 64), Epochs: 22, Loss: 1.3123\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 42, Loss: 1.9235\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.2044\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.0 min] Value: relu, Epochs: 181, Loss: 0.1492\n",
      "[5/31 | 16.1% |  0.9 min] Value: leakyrelu, Epochs: 145, Loss: 0.1993\n",
      "[6/31 | 19.4% |  0.7 min] Value: gelu, Epochs: 107, Loss: 0.1775\n",
      "[7/31 | 22.6% |  0.8 min] Value: elu, Epochs: 89, Loss: 0.2894\n",
      "[8/31 | 25.8% |  1.1 min] Value: silu, Epochs: 203, Loss: 0.1919\n",
      "Best activation = relu, val_loss = 0.1492\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.9 min] Value: 0.0001, Epochs: 435, Loss: 0.3112\n",
      "[10/31 | 32.3% |  0.8 min] Value: 0.001, Epochs: 154, Loss: 0.2157\n",
      "Best learning_rate = 0.001, val_loss = 0.2157\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  1.1 min] Value: 32, Epochs: 70, Loss: 0.1323\n",
      "[12/31 | 38.7% |  0.8 min] Value: 512, Epochs: 159, Loss: 0.2150\n",
      "[13/31 | 41.9% |  1.0 min] Value: 1024, Epochs: 216, Loss: 0.1954\n",
      "Best batch_size = 32, val_loss = 0.1323\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.0 min] Value: 0.0, Epochs: 53, Loss: 0.1922\n",
      "[15/31 | 48.4% |  1.0 min] Value: 1e-05, Epochs: 54, Loss: 0.1938\n",
      "[16/31 | 51.6% |  1.2 min] Value: 0.0001, Epochs: 71, Loss: 0.1352\n",
      "[17/31 | 54.8% |  1.3 min] Value: 0.001, Epochs: 90, Loss: 0.1370\n",
      "[18/31 | 58.1% |  1.1 min] Value: 0.01, Epochs: 63, Loss: 0.1490\n",
      "Best weight_decay = 0.0001, val_loss = 0.1352\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.3 min] Value: 0.01, Epochs: 20, Loss: 1.4455\n",
      "[20/31 | 64.5% |  0.8 min] Value: 0.5, Epochs: 76, Loss: 0.2065\n",
      "[21/31 | 67.7% |  0.8 min] Value: 1.0, Epochs: 74, Loss: 0.1309\n",
      "Best tau = 1.0, val_loss = 0.1309\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.8 min] Value: 0.0, Epochs: 66, Loss: 0.1403\n",
      "[23/31 | 74.2% |  0.5 min] Value: 0.2, Epochs: 26, Loss: 0.4976\n",
      "[24/31 | 77.4% |  0.3 min] Value: 0.4, Epochs: 18, Loss: 1.3161\n",
      "[25/31 | 80.6% |  0.5 min] Value: 0.6, Epochs: 33, Loss: 1.0307\n",
      "[26/31 | 83.9% |  0.4 min] Value: 0.8, Epochs: 23, Loss: 1.3869\n",
      "Best instance_dropout = 0.0, val_loss = 0.1403\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.1 min] Value: 1, Epochs: 66, Loss: 0.1534\n",
      "[28/31 | 90.3% |  1.4 min] Value: 2, Epochs: 88, Loss: 0.1335\n",
      "[29/31 | 93.5% |  1.1 min] Value: 3, Epochs: 59, Loss: 0.1798\n",
      "[30/31 | 96.8% |  1.2 min] Value: 4, Epochs: 72, Loss: 0.1939\n",
      "[31/31 | 100.0% |  1.1 min] Value: 5, Epochs: 70, Loss: 0.1385\n",
      "Best random_seed = 2, val_loss = 0.1335\n",
      "Stepwise optimization completed in 9.0 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 28, Loss: 0.9672\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 47, Loss: 0.3994\n",
      "[3/31 |  9.7% |  0.2 min] Value: (128,), Epochs: 55, Loss: 0.3410\n",
      "Best hidden_layer_sizes = (128,), val_loss = 0.3410\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.8 min] Value: relu, Epochs: 134, Loss: 0.2710\n",
      "[5/31 | 16.1% |  0.8 min] Value: leakyrelu, Epochs: 126, Loss: 0.2621\n",
      "[6/31 | 19.4% |  0.7 min] Value: gelu, Epochs: 79, Loss: 0.2764\n",
      "[7/31 | 22.6% |  0.8 min] Value: elu, Epochs: 106, Loss: 0.3254\n",
      "[8/31 | 25.8% |  0.6 min] Value: silu, Epochs: 66, Loss: 0.3292\n",
      "Best activation = leakyrelu, val_loss = 0.2621\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.8 min] Value: 0.0001, Epochs: 298, Loss: 0.3532\n",
      "[10/31 | 32.3% |  0.7 min] Value: 0.001, Epochs: 117, Loss: 0.2322\n",
      "Best learning_rate = 0.001, val_loss = 0.2322\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 75, Loss: 0.2841\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 45, Loss: 0.9232\n",
      "[13/31 | 41.9% |  0.1 min] Value: 1024, Epochs: 45, Loss: 0.9232\n",
      "Best batch_size = 32, val_loss = 0.2841\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.6 min] Value: 0.0, Epochs: 61, Loss: 0.2917\n",
      "[15/31 | 48.4% |  0.9 min] Value: 1e-05, Epochs: 154, Loss: 0.2329\n",
      "[16/31 | 51.6% |  0.8 min] Value: 0.0001, Epochs: 136, Loss: 0.2327\n",
      "[17/31 | 54.8% |  0.7 min] Value: 0.001, Epochs: 76, Loss: 0.2634\n",
      "[18/31 | 58.1% |  0.6 min] Value: 0.01, Epochs: 59, Loss: 0.3062\n",
      "Best weight_decay = 0.0001, val_loss = 0.2327\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.3 min] Value: 0.01, Epochs: 44, Loss: 0.7924\n",
      "[20/31 | 64.5% |  0.3 min] Value: 0.5, Epochs: 79, Loss: 0.2858\n",
      "[21/31 | 67.7% |  0.5 min] Value: 1.0, Epochs: 123, Loss: 0.2222\n",
      "Best tau = 1.0, val_loss = 0.2222\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.4 min] Value: 0.0, Epochs: 74, Loss: 0.2344\n",
      "[23/31 | 74.2% |  0.3 min] Value: 0.2, Epochs: 28, Loss: 0.6539\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 21, Loss: 0.8103\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 36, Loss: 1.1312\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 31, Loss: 1.1517\n",
      "Best instance_dropout = 0.0, val_loss = 0.2344\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.7 min] Value: 1, Epochs: 112, Loss: 0.3338\n",
      "[28/31 | 90.3% |  0.7 min] Value: 2, Epochs: 104, Loss: 0.2274\n",
      "[29/31 | 93.5% |  0.7 min] Value: 3, Epochs: 120, Loss: 0.2294\n",
      "[30/31 | 96.8% |  0.6 min] Value: 4, Epochs: 81, Loss: 0.3751\n",
      "[31/31 | 100.0% |  0.7 min] Value: 5, Epochs: 81, Loss: 0.2168\n",
      "Best random_seed = 5, val_loss = 0.2168\n",
      "Stepwise optimization completed in 4.6 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.4 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 149, Loss: 0.1824\n",
      "[2/31 |  6.5% |  0.0 min] Value: (256, 128, 64), Epochs: 21, Loss: 1.4324\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 53, Loss: 1.5074\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.1824\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.7 min] Value: relu, Epochs: 146, Loss: 0.1754\n",
      "[5/31 | 16.1% |  0.6 min] Value: leakyrelu, Epochs: 154, Loss: 0.1766\n",
      "[6/31 | 19.4% |  1.9 min] Value: gelu, Epochs: 581, Loss: 0.1816\n",
      "[7/31 | 22.6% |  1.2 min] Value: elu, Epochs: 334, Loss: 0.3349\n",
      "[8/31 | 25.8% |  2.3 min] Value: silu, Epochs: 800, Loss: 0.1648\n",
      "Best activation = silu, val_loss = 0.1648\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.1 min] Value: 0.0001, Epochs: 27, Loss: 2.2973\n",
      "[10/31 | 32.3% |  2.3 min] Value: 0.001, Epochs: 869, Loss: 0.1856\n",
      "Best learning_rate = 0.001, val_loss = 0.1856\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.7 min] Value: 32, Epochs: 42, Loss: 0.1831\n",
      "[12/31 | 38.7% |  0.7 min] Value: 512, Epochs: 192, Loss: 0.2072\n",
      "[13/31 | 41.9% |  1.5 min] Value: 1024, Epochs: 545, Loss: 0.1891\n",
      "Best batch_size = 32, val_loss = 0.1831\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.9 min] Value: 0.0, Epochs: 58, Loss: 0.2024\n",
      "[15/31 | 48.4% |  1.0 min] Value: 1e-05, Epochs: 63, Loss: 0.1810\n",
      "[16/31 | 51.6% |  0.9 min] Value: 0.0001, Epochs: 62, Loss: 0.1988\n",
      "[17/31 | 54.8% |  0.9 min] Value: 0.001, Epochs: 62, Loss: 0.1872\n",
      "[18/31 | 58.1% |  0.6 min] Value: 0.01, Epochs: 39, Loss: 0.2052\n",
      "Best weight_decay = 1e-05, val_loss = 0.1810\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.5 min] Value: 0.01, Epochs: 57, Loss: 0.1712\n",
      "[20/31 | 64.5% |  0.3 min] Value: 0.5, Epochs: 35, Loss: 1.0064\n",
      "[21/31 | 67.7% |  0.2 min] Value: 1.0, Epochs: 18, Loss: 1.3121\n",
      "Best tau = 0.01, val_loss = 0.1712\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.0 min] Value: 0.0, Epochs: 58, Loss: 0.2121\n",
      "[23/31 | 74.2% |  0.5 min] Value: 0.2, Epochs: 40, Loss: 0.4851\n",
      "[24/31 | 77.4% |  0.7 min] Value: 0.4, Epochs: 28, Loss: 0.6775\n",
      "[25/31 | 80.6% |  0.4 min] Value: 0.6, Epochs: 26, Loss: 1.0128\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 15, Loss: 1.2744\n",
      "Best instance_dropout = 0.0, val_loss = 0.2121\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.1 min] Value: 1, Epochs: 48, Loss: 0.1837\n",
      "[28/31 | 90.3% |  1.3 min] Value: 2, Epochs: 52, Loss: 0.1783\n",
      "[29/31 | 93.5% |  0.7 min] Value: 3, Epochs: 39, Loss: 0.2113\n",
      "[30/31 | 96.8% |  1.0 min] Value: 4, Epochs: 58, Loss: 0.2237\n",
      "[31/31 | 100.0% |  0.8 min] Value: 5, Epochs: 45, Loss: 0.1982\n",
      "Best random_seed = 2, val_loss = 0.1783\n",
      "Stepwise optimization completed in 10.4 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 19, Loss: 0.0081\n",
      "[2/28 |  7.1% |  0.2 min] Value: (256, 128, 64), Epochs: 25, Loss: 0.0176\n",
      "[3/28 | 10.7% |  0.2 min] Value: (128,), Epochs: 48, Loss: 0.0272\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0081\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.6 min] Value: relu, Epochs: 25, Loss: 0.0082\n",
      "[5/28 | 17.9% |  0.4 min] Value: leakyrelu, Epochs: 21, Loss: 0.0088\n",
      "[6/28 | 21.4% |  1.0 min] Value: gelu, Epochs: 56, Loss: 0.0061\n",
      "[7/28 | 25.0% |  1.0 min] Value: elu, Epochs: 55, Loss: 0.0157\n",
      "[8/28 | 28.6% |  0.5 min] Value: silu, Epochs: 26, Loss: 0.0065\n",
      "Best activation = gelu, val_loss = 0.0061\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.4 min] Value: 0.0001, Epochs: 29, Loss: 0.0110\n",
      "[10/28 | 35.7% |  0.5 min] Value: 0.001, Epochs: 34, Loss: 0.0060\n",
      "Best learning_rate = 0.001, val_loss = 0.0060\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.3 min] Value: 32, Epochs: 24, Loss: 0.0066\n",
      "[12/28 | 42.9% |  0.3 min] Value: 512, Epochs: 62, Loss: 0.0090\n",
      "[13/28 | 46.4% |  0.3 min] Value: 1024, Epochs: 62, Loss: 0.0090\n",
      "Best batch_size = 32, val_loss = 0.0066\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.4 min] Value: 0.0, Epochs: 20, Loss: 0.0087\n",
      "[15/28 | 53.6% |  0.7 min] Value: 1e-05, Epochs: 34, Loss: 0.0076\n",
      "[16/28 | 57.1% |  0.4 min] Value: 0.0001, Epochs: 25, Loss: 0.0057\n",
      "[17/28 | 60.7% |  0.3 min] Value: 0.001, Epochs: 18, Loss: 0.0078\n",
      "[18/28 | 64.3% |  0.8 min] Value: 0.01, Epochs: 43, Loss: 0.0053\n",
      "Best weight_decay = 0.01, val_loss = 0.0053\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.4 min] Value: 0.0, Epochs: 24, Loss: 0.0067\n",
      "[20/28 | 71.4% |  0.3 min] Value: 0.2, Epochs: 14, Loss: 0.0222\n",
      "[21/28 | 75.0% |  0.6 min] Value: 0.4, Epochs: 32, Loss: 0.0417\n",
      "[22/28 | 78.6% |  0.4 min] Value: 0.6, Epochs: 14, Loss: 0.0905\n",
      "[23/28 | 82.1% |  0.3 min] Value: 0.8, Epochs: 19, Loss: 0.1549\n",
      "Best instance_dropout = 0.0, val_loss = 0.0067\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.6 min] Value: 1, Epochs: 35, Loss: 0.0061\n",
      "[25/28 | 89.3% |  0.5 min] Value: 2, Epochs: 25, Loss: 0.0079\n",
      "[26/28 | 92.9% |  0.5 min] Value: 3, Epochs: 33, Loss: 0.0100\n",
      "[27/28 | 96.4% |  0.5 min] Value: 4, Epochs: 26, Loss: 0.0068\n",
      "[28/28 | 100.0% |  0.4 min] Value: 5, Epochs: 23, Loss: 0.0061\n",
      "Best random_seed = 5, val_loss = 0.0061\n",
      "Stepwise optimization completed in 4.2 min\n",
      "\n",
      "\n",
      "[Task 6/9] Starting task: 'MolMR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:19<00:00, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.7 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 49, Loss: 16.9680\n",
      "[2/31 |  6.5% |  0.6 min] Value: (256, 128, 64), Epochs: 98, Loss: 31.4207\n",
      "[3/31 |  9.7% |  0.6 min] Value: (128,), Epochs: 114, Loss: 314.4533\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 16.9680\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.2 min] Value: relu, Epochs: 69, Loss: 13.4559\n",
      "[5/31 | 16.1% |  1.5 min] Value: leakyrelu, Epochs: 98, Loss: 12.6059\n",
      "[6/31 | 19.4% |  1.1 min] Value: gelu, Epochs: 72, Loss: 11.5136\n",
      "[7/31 | 22.6% |  0.7 min] Value: elu, Epochs: 41, Loss: 27.8447\n",
      "[8/31 | 25.8% |  1.1 min] Value: silu, Epochs: 76, Loss: 16.6317\n",
      "Best activation = gelu, val_loss = 11.5136\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  2.1 min] Value: 0.0001, Epochs: 204, Loss: 24.1737\n",
      "[10/31 | 32.3% |  1.1 min] Value: 0.001, Epochs: 71, Loss: 12.2675\n",
      "Best learning_rate = 0.001, val_loss = 12.2675\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.9 min] Value: 32, Epochs: 69, Loss: 12.6802\n",
      "[12/31 | 38.7% |  1.1 min] Value: 512, Epochs: 249, Loss: 16.8735\n",
      "[13/31 | 41.9% |  1.0 min] Value: 1024, Epochs: 260, Loss: 14.4450\n",
      "Best batch_size = 32, val_loss = 12.6802\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.3 min] Value: 0.0, Epochs: 83, Loss: 12.0571\n",
      "[15/31 | 48.4% |  1.0 min] Value: 1e-05, Epochs: 67, Loss: 17.2670\n",
      "[16/31 | 51.6% |  1.4 min] Value: 0.0001, Epochs: 109, Loss: 11.8913\n",
      "[17/31 | 54.8% |  1.4 min] Value: 0.001, Epochs: 81, Loss: 16.4377\n",
      "[18/31 | 58.1% |  0.9 min] Value: 0.01, Epochs: 45, Loss: 20.5054\n",
      "Best weight_decay = 0.0001, val_loss = 11.8913\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.3 min] Value: 0.01, Epochs: 18, Loss: 248.9173\n",
      "[20/31 | 64.5% |  1.0 min] Value: 0.5, Epochs: 83, Loss: 13.0559\n",
      "[21/31 | 67.7% |  0.9 min] Value: 1.0, Epochs: 94, Loss: 14.1563\n",
      "Best tau = 0.5, val_loss = 13.0559\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.0 min] Value: 0.0, Epochs: 109, Loss: 11.7149\n",
      "[23/31 | 74.2% |  0.4 min] Value: 0.2, Epochs: 25, Loss: 145.7644\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 13, Loss: 212.1971\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 16, Loss: 244.2222\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 12, Loss: 293.1291\n",
      "Best instance_dropout = 0.0, val_loss = 11.7149\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.2 min] Value: 1, Epochs: 84, Loss: 23.6380\n",
      "[28/31 | 90.3% |  1.0 min] Value: 2, Epochs: 63, Loss: 16.1498\n",
      "[29/31 | 93.5% |  1.2 min] Value: 3, Epochs: 85, Loss: 12.7967\n",
      "[30/31 | 96.8% |  1.1 min] Value: 4, Epochs: 64, Loss: 15.2946\n",
      "[31/31 | 100.0% |  1.2 min] Value: 5, Epochs: 82, Loss: 15.9450\n",
      "Best random_seed = 3, val_loss = 12.7967\n",
      "Stepwise optimization completed in 10.0 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 17, Loss: 282.6425\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 44, Loss: 263.5239\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 42, Loss: 313.2961\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 263.5239\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.2 min] Value: relu, Epochs: 40, Loss: 279.0535\n",
      "[5/31 | 16.1% |  0.2 min] Value: leakyrelu, Epochs: 44, Loss: 268.7034\n",
      "[6/31 | 19.4% |  0.2 min] Value: gelu, Epochs: 26, Loss: 266.8302\n",
      "[7/31 | 22.6% |  0.2 min] Value: elu, Epochs: 25, Loss: 262.5898\n",
      "[8/31 | 25.8% |  0.2 min] Value: silu, Epochs: 23, Loss: 262.4109\n",
      "Best activation = silu, val_loss = 262.4109\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.2 min] Value: 0.0001, Epochs: 106, Loss: 265.0367\n",
      "[10/31 | 32.3% |  0.1 min] Value: 0.001, Epochs: 30, Loss: 278.9026\n",
      "Best learning_rate = 0.0001, val_loss = 265.0367\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.4 min] Value: 32, Epochs: 138, Loss: 253.9207\n",
      "[12/31 | 38.7% |  0.3 min] Value: 512, Epochs: 207, Loss: 388.5830\n",
      "[13/31 | 41.9% |  0.3 min] Value: 1024, Epochs: 207, Loss: 388.5830\n",
      "Best batch_size = 32, val_loss = 253.9207\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.9 min] Value: 0.0, Epochs: 123, Loss: 260.4467\n",
      "[15/31 | 48.4% |  0.9 min] Value: 1e-05, Epochs: 135, Loss: 259.3582\n",
      "[16/31 | 51.6% |  0.9 min] Value: 0.0001, Epochs: 109, Loss: 266.5498\n",
      "[17/31 | 54.8% |  0.8 min] Value: 0.001, Epochs: 105, Loss: 265.2943\n",
      "[18/31 | 58.1% |  0.9 min] Value: 0.01, Epochs: 139, Loss: 250.7749\n",
      "Best weight_decay = 0.01, val_loss = 250.7749\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.5 min] Value: 0.01, Epochs: 125, Loss: 264.0366\n",
      "[20/31 | 64.5% |  0.5 min] Value: 0.5, Epochs: 117, Loss: 264.9171\n",
      "[21/31 | 67.7% |  0.5 min] Value: 1.0, Epochs: 111, Loss: 276.1856\n",
      "Best tau = 0.01, val_loss = 264.0366\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.6 min] Value: 0.0, Epochs: 113, Loss: 268.8991\n",
      "[23/31 | 74.2% |  0.7 min] Value: 0.2, Epochs: 153, Loss: 238.1952\n",
      "[24/31 | 77.4% |  0.5 min] Value: 0.4, Epochs: 67, Loss: 289.6157\n",
      "[25/31 | 80.6% |  0.4 min] Value: 0.6, Epochs: 39, Loss: 373.3260\n",
      "[26/31 | 83.9% |  0.4 min] Value: 0.8, Epochs: 39, Loss: 570.4482\n",
      "Best instance_dropout = 0.2, val_loss = 238.1952\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.8 min] Value: 1, Epochs: 141, Loss: 265.6576\n",
      "[28/31 | 90.3% |  0.7 min] Value: 2, Epochs: 104, Loss: 267.0609\n",
      "[29/31 | 93.5% |  0.6 min] Value: 3, Epochs: 80, Loss: 252.0176\n",
      "[30/31 | 96.8% |  0.5 min] Value: 4, Epochs: 56, Loss: 276.7077\n",
      "[31/31 | 100.0% |  0.8 min] Value: 5, Epochs: 157, Loss: 237.3278\n",
      "Best random_seed = 5, val_loss = 237.3278\n",
      "Stepwise optimization completed in 4.0 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.9 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 77, Loss: 22.4439\n",
      "[2/31 |  6.5% |  0.8 min] Value: (256, 128, 64), Epochs: 219, Loss: 13.4036\n",
      "[3/31 |  9.7% |  1.1 min] Value: (128,), Epochs: 643, Loss: 18.6741\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 13.4036\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.2 min] Value: relu, Epochs: 179, Loss: 13.3593\n",
      "[5/31 | 16.1% |  1.3 min] Value: leakyrelu, Epochs: 193, Loss: 12.3074\n",
      "[6/31 | 19.4% |  1.3 min] Value: gelu, Epochs: 179, Loss: 13.3302\n",
      "[7/31 | 22.6% |  1.1 min] Value: elu, Epochs: 157, Loss: 15.5353\n",
      "[8/31 | 25.8% |  1.2 min] Value: silu, Epochs: 183, Loss: 14.1430\n",
      "Best activation = leakyrelu, val_loss = 12.3074\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.9 min] Value: 0.0001, Epochs: 466, Loss: 25.7853\n",
      "[10/31 | 32.3% |  0.4 min] Value: 0.001, Epochs: 150, Loss: 12.5334\n",
      "Best learning_rate = 0.001, val_loss = 12.5334\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 162, Loss: 13.7001\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 48, Loss: 141.1311\n",
      "[13/31 | 41.9% |  0.1 min] Value: 1024, Epochs: 50, Loss: 376.9067\n",
      "Best batch_size = 32, val_loss = 13.7001\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.3 min] Value: 0.0, Epochs: 155, Loss: 12.4082\n",
      "[15/31 | 48.4% |  1.5 min] Value: 1e-05, Epochs: 174, Loss: 12.5931\n",
      "[16/31 | 51.6% |  1.5 min] Value: 0.0001, Epochs: 172, Loss: 14.1514\n",
      "[17/31 | 54.8% |  1.5 min] Value: 0.001, Epochs: 190, Loss: 11.9450\n",
      "[18/31 | 58.1% |  1.4 min] Value: 0.01, Epochs: 168, Loss: 12.6829\n",
      "Best weight_decay = 0.001, val_loss = 11.9450\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.4 min] Value: 0.01, Epochs: 134, Loss: 16.6900\n",
      "[20/31 | 64.5% |  0.2 min] Value: 0.5, Epochs: 29, Loss: 295.6400\n",
      "[21/31 | 67.7% |  0.2 min] Value: 1.0, Epochs: 29, Loss: 320.8567\n",
      "Best tau = 0.01, val_loss = 16.6900\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 167, Loss: 11.4437\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 37, Loss: 103.2728\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 17, Loss: 168.3740\n",
      "[25/31 | 80.6% |  0.2 min] Value: 0.6, Epochs: 17, Loss: 261.9740\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 18, Loss: 262.7377\n",
      "Best instance_dropout = 0.0, val_loss = 11.4437\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.4 min] Value: 1, Epochs: 158, Loss: 13.6161\n",
      "[28/31 | 90.3% |  1.8 min] Value: 2, Epochs: 305, Loss: 10.2356\n",
      "[29/31 | 93.5% |  1.6 min] Value: 3, Epochs: 186, Loss: 13.8497\n",
      "[30/31 | 96.8% |  1.6 min] Value: 4, Epochs: 189, Loss: 10.2323\n",
      "[31/31 | 100.0% |  1.4 min] Value: 5, Epochs: 155, Loss: 13.2992\n",
      "Best random_seed = 4, val_loss = 10.2323\n",
      "Stepwise optimization completed in 7.8 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.4 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 38, Loss: 0.0043\n",
      "[2/28 |  7.1% |  0.3 min] Value: (256, 128, 64), Epochs: 37, Loss: 0.0082\n",
      "[3/28 | 10.7% |  0.3 min] Value: (128,), Epochs: 57, Loss: 0.0095\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0043\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.6 min] Value: relu, Epochs: 39, Loss: 0.0058\n",
      "[5/28 | 17.9% |  0.5 min] Value: leakyrelu, Epochs: 30, Loss: 0.0082\n",
      "[6/28 | 21.4% |  0.7 min] Value: gelu, Epochs: 43, Loss: 0.0047\n",
      "[7/28 | 25.0% |  0.9 min] Value: elu, Epochs: 60, Loss: 0.0083\n",
      "[8/28 | 28.6% |  0.5 min] Value: silu, Epochs: 28, Loss: 0.0057\n",
      "Best activation = gelu, val_loss = 0.0047\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  1.0 min] Value: 0.0001, Epochs: 94, Loss: 0.0065\n",
      "[10/28 | 35.7% |  0.4 min] Value: 0.001, Epochs: 27, Loss: 0.0060\n",
      "Best learning_rate = 0.001, val_loss = 0.0060\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.2 min] Value: 32, Epochs: 20, Loss: 0.0051\n",
      "[12/28 | 42.9% |  0.3 min] Value: 512, Epochs: 78, Loss: 0.0050\n",
      "[13/28 | 46.4% |  0.3 min] Value: 1024, Epochs: 78, Loss: 0.0050\n",
      "Best batch_size = 1024, val_loss = 0.0050\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.6 min] Value: 0.0, Epochs: 84, Loss: 0.0048\n",
      "[15/28 | 53.6% |  0.6 min] Value: 1e-05, Epochs: 96, Loss: 0.0048\n",
      "[16/28 | 57.1% |  0.6 min] Value: 0.0001, Epochs: 84, Loss: 0.0048\n",
      "[17/28 | 60.7% |  0.6 min] Value: 0.001, Epochs: 84, Loss: 0.0049\n",
      "[18/28 | 64.3% |  0.5 min] Value: 0.01, Epochs: 78, Loss: 0.0050\n",
      "Best weight_decay = 1e-05, val_loss = 0.0048\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.4 min] Value: 0.0, Epochs: 84, Loss: 0.0048\n",
      "[20/28 | 71.4% |  0.2 min] Value: 0.2, Epochs: 31, Loss: 0.0171\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 16, Loss: 0.0505\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 16, Loss: 0.0571\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 18, Loss: 0.1163\n",
      "Best instance_dropout = 0.0, val_loss = 0.0048\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.6 min] Value: 1, Epochs: 90, Loss: 0.0056\n",
      "[25/28 | 89.3% |  0.5 min] Value: 2, Epochs: 87, Loss: 0.0052\n",
      "[26/28 | 92.9% |  0.5 min] Value: 3, Epochs: 79, Loss: 0.0052\n",
      "[27/28 | 96.4% |  0.5 min] Value: 4, Epochs: 85, Loss: 0.0059\n",
      "[28/28 | 100.0% |  0.6 min] Value: 5, Epochs: 84, Loss: 0.0048\n",
      "Best random_seed = 5, val_loss = 0.0048\n",
      "Stepwise optimization completed in 4.1 min\n",
      "\n",
      "\n",
      "[Task 7/9] Starting task: 'NumRotatableBonds'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:14<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 24, Loss: 0.2002\n",
      "[2/31 |  6.5% |  0.1 min] Value: (256, 128, 64), Epochs: 19, Loss: 0.1132\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 26, Loss: 0.1460\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.1132\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 15, Loss: 0.1711\n",
      "[5/31 | 16.1% |  0.1 min] Value: leakyrelu, Epochs: 16, Loss: 0.1532\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 15, Loss: 0.1361\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 21, Loss: 0.1556\n",
      "[8/31 | 25.8% |  0.1 min] Value: silu, Epochs: 16, Loss: 0.1295\n",
      "Best activation = silu, val_loss = 0.1295\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.1 min] Value: 0.0001, Epochs: 43, Loss: 0.1078\n",
      "[10/31 | 32.3% |  0.1 min] Value: 0.001, Epochs: 16, Loss: 0.1389\n",
      "Best learning_rate = 0.0001, val_loss = 0.1078\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 45, Loss: 0.1022\n",
      "[12/31 | 38.7% |  0.2 min] Value: 512, Epochs: 139, Loss: 0.1073\n",
      "[13/31 | 41.9% |  0.2 min] Value: 1024, Epochs: 139, Loss: 0.1073\n",
      "Best batch_size = 32, val_loss = 0.1022\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.4 min] Value: 0.0, Epochs: 78, Loss: 0.0971\n",
      "[15/31 | 48.4% |  0.3 min] Value: 1e-05, Epochs: 41, Loss: 0.1022\n",
      "[16/31 | 51.6% |  0.3 min] Value: 0.0001, Epochs: 42, Loss: 0.1021\n",
      "[17/31 | 54.8% |  0.3 min] Value: 0.001, Epochs: 42, Loss: 0.0971\n",
      "[18/31 | 58.1% |  0.3 min] Value: 0.01, Epochs: 39, Loss: 0.1100\n",
      "Best weight_decay = 0.001, val_loss = 0.0971\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.2 min] Value: 0.01, Epochs: 52, Loss: 0.3270\n",
      "[20/31 | 64.5% |  0.2 min] Value: 0.5, Epochs: 45, Loss: 0.1066\n",
      "[21/31 | 67.7% |  0.3 min] Value: 1.0, Epochs: 60, Loss: 0.0933\n",
      "Best tau = 1.0, val_loss = 0.0933\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 52, Loss: 0.1011\n",
      "[23/31 | 74.2% |  0.6 min] Value: 0.2, Epochs: 56, Loss: 0.0873\n",
      "[24/31 | 77.4% |  0.7 min] Value: 0.4, Epochs: 75, Loss: 0.0856\n",
      "[25/31 | 80.6% |  0.7 min] Value: 0.6, Epochs: 80, Loss: 0.1191\n",
      "[26/31 | 83.9% |  0.8 min] Value: 0.8, Epochs: 109, Loss: 0.1428\n",
      "Best instance_dropout = 0.4, val_loss = 0.0856\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.5 min] Value: 1, Epochs: 62, Loss: 0.1092\n",
      "[28/31 | 90.3% |  0.5 min] Value: 2, Epochs: 65, Loss: 0.0813\n",
      "[29/31 | 93.5% |  0.5 min] Value: 3, Epochs: 71, Loss: 0.0879\n",
      "[30/31 | 96.8% |  0.5 min] Value: 4, Epochs: 59, Loss: 0.1186\n",
      "[31/31 | 100.0% |  0.6 min] Value: 5, Epochs: 89, Loss: 0.0934\n",
      "Best random_seed = 2, val_loss = 0.0813\n",
      "Stepwise optimization completed in 2.6 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.6 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 46, Loss: 0.1310\n",
      "[2/31 |  6.5% |  0.5 min] Value: (256, 128, 64), Epochs: 89, Loss: 0.1559\n",
      "[3/31 |  9.7% |  0.6 min] Value: (128,), Epochs: 120, Loss: 0.2382\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.1310\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.4 min] Value: relu, Epochs: 20, Loss: 0.1715\n",
      "[5/31 | 16.1% |  0.5 min] Value: leakyrelu, Epochs: 26, Loss: 0.1260\n",
      "[6/31 | 19.4% |  0.5 min] Value: gelu, Epochs: 30, Loss: 0.1152\n",
      "[7/31 | 22.6% |  0.6 min] Value: elu, Epochs: 27, Loss: 0.1725\n",
      "[8/31 | 25.8% |  0.5 min] Value: silu, Epochs: 27, Loss: 0.1079\n",
      "Best activation = silu, val_loss = 0.1079\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.4 min] Value: 0.0001, Epochs: 36, Loss: 0.1102\n",
      "[10/31 | 32.3% |  0.2 min] Value: 0.001, Epochs: 14, Loss: 1.0410\n",
      "Best learning_rate = 0.0001, val_loss = 0.1102\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.4 min] Value: 32, Epochs: 34, Loss: 0.1288\n",
      "[12/31 | 38.7% |  0.3 min] Value: 512, Epochs: 58, Loss: 0.1228\n",
      "[13/31 | 41.9% |  0.3 min] Value: 1024, Epochs: 54, Loss: 0.1212\n",
      "Best batch_size = 1024, val_loss = 0.1212\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.4 min] Value: 0.0, Epochs: 63, Loss: 0.1116\n",
      "[15/31 | 48.4% |  0.3 min] Value: 1e-05, Epochs: 54, Loss: 0.1230\n",
      "[16/31 | 51.6% |  0.3 min] Value: 0.0001, Epochs: 60, Loss: 0.0978\n",
      "[17/31 | 54.8% |  0.3 min] Value: 0.001, Epochs: 63, Loss: 0.0923\n",
      "[18/31 | 58.1% |  0.3 min] Value: 0.01, Epochs: 60, Loss: 0.1069\n",
      "Best weight_decay = 0.001, val_loss = 0.0923\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.3 min] Value: 0.01, Epochs: 51, Loss: 0.1028\n",
      "[20/31 | 64.5% |  0.4 min] Value: 0.5, Epochs: 72, Loss: 0.1015\n",
      "[21/31 | 67.7% |  0.5 min] Value: 1.0, Epochs: 83, Loss: 0.0980\n",
      "Best tau = 1.0, val_loss = 0.0980\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.4 min] Value: 0.0, Epochs: 45, Loss: 0.1274\n",
      "[23/31 | 74.2% |  0.5 min] Value: 0.2, Epochs: 82, Loss: 0.0988\n",
      "[24/31 | 77.4% |  0.4 min] Value: 0.4, Epochs: 42, Loss: 0.1561\n",
      "[25/31 | 80.6% |  0.4 min] Value: 0.6, Epochs: 56, Loss: 0.1948\n",
      "[26/31 | 83.9% |  0.5 min] Value: 0.8, Epochs: 55, Loss: 0.2559\n",
      "Best instance_dropout = 0.2, val_loss = 0.0988\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.6 min] Value: 1, Epochs: 76, Loss: 0.0879\n",
      "[28/31 | 90.3% |  0.4 min] Value: 2, Epochs: 43, Loss: 0.1177\n",
      "[29/31 | 93.5% |  0.5 min] Value: 3, Epochs: 72, Loss: 0.1103\n",
      "[30/31 | 96.8% |  0.7 min] Value: 4, Epochs: 97, Loss: 0.0887\n",
      "[31/31 | 100.0% |  0.6 min] Value: 5, Epochs: 76, Loss: 0.0919\n",
      "Best random_seed = 1, val_loss = 0.0879\n",
      "Stepwise optimization completed in 4.0 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 25, Loss: 0.1047\n",
      "[2/31 |  6.5% |  0.4 min] Value: (256, 128, 64), Epochs: 83, Loss: 0.0866\n",
      "[3/31 |  9.7% |  0.5 min] Value: (128,), Epochs: 169, Loss: 0.0938\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0866\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.4 min] Value: relu, Epochs: 74, Loss: 0.0827\n",
      "[5/31 | 16.1% |  0.4 min] Value: leakyrelu, Epochs: 87, Loss: 0.0776\n",
      "[6/31 | 19.4% |  0.3 min] Value: gelu, Epochs: 32, Loss: 0.1016\n",
      "[7/31 | 22.6% |  0.2 min] Value: elu, Epochs: 27, Loss: 0.1267\n",
      "[8/31 | 25.8% |  0.2 min] Value: silu, Epochs: 26, Loss: 0.1216\n",
      "Best activation = leakyrelu, val_loss = 0.0776\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.8 min] Value: 0.0001, Epochs: 297, Loss: 0.0844\n",
      "[10/31 | 32.3% |  0.3 min] Value: 0.001, Epochs: 66, Loss: 0.0828\n",
      "Best learning_rate = 0.001, val_loss = 0.0828\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.4 min] Value: 32, Epochs: 66, Loss: 0.0831\n",
      "[12/31 | 38.7% |  0.6 min] Value: 512, Epochs: 336, Loss: 0.0872\n",
      "[13/31 | 41.9% |  0.6 min] Value: 1024, Epochs: 346, Loss: 0.0807\n",
      "Best batch_size = 1024, val_loss = 0.0807\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.1 min] Value: 0.0, Epochs: 342, Loss: 0.0832\n",
      "[15/31 | 48.4% |  1.2 min] Value: 1e-05, Epochs: 422, Loss: 0.0793\n",
      "[16/31 | 51.6% |  1.2 min] Value: 0.0001, Epochs: 413, Loss: 0.0829\n",
      "[17/31 | 54.8% |  1.0 min] Value: 0.001, Epochs: 317, Loss: 0.0834\n",
      "[18/31 | 58.1% |  1.2 min] Value: 0.01, Epochs: 396, Loss: 0.0813\n",
      "Best weight_decay = 1e-05, val_loss = 0.0793\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.5 min] Value: 0.01, Epochs: 367, Loss: 0.0831\n",
      "[20/31 | 64.5% |  0.1 min] Value: 0.5, Epochs: 54, Loss: 0.2018\n",
      "[21/31 | 67.7% |  0.0 min] Value: 1.0, Epochs: 15, Loss: 0.6454\n",
      "Best tau = 0.01, val_loss = 0.0831\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 395, Loss: 0.0786\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 71, Loss: 0.1817\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 41, Loss: 0.2544\n",
      "[25/31 | 80.6% |  0.2 min] Value: 0.6, Epochs: 52, Loss: 0.3025\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 62, Loss: 0.3431\n",
      "Best instance_dropout = 0.0, val_loss = 0.0786\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.8 min] Value: 1, Epochs: 326, Loss: 0.0933\n",
      "[28/31 | 90.3% |  0.6 min] Value: 2, Epochs: 223, Loss: 0.0785\n",
      "[29/31 | 93.5% |  1.2 min] Value: 3, Epochs: 814, Loss: 0.0809\n",
      "[30/31 | 96.8% |  0.9 min] Value: 4, Epochs: 416, Loss: 0.0815\n",
      "[31/31 | 100.0% |  0.8 min] Value: 5, Epochs: 320, Loss: 0.0791\n",
      "Best random_seed = 2, val_loss = 0.0785\n",
      "Stepwise optimization completed in 5.7 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 56, Loss: 0.0134\n",
      "[2/28 |  7.1% |  0.4 min] Value: (256, 128, 64), Epochs: 195, Loss: 0.0113\n",
      "[3/28 | 10.7% |  0.9 min] Value: (128,), Epochs: 912, Loss: 0.0213\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0113\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.2 min] Value: relu, Epochs: 76, Loss: 0.0115\n",
      "[5/28 | 17.9% |  0.2 min] Value: leakyrelu, Epochs: 83, Loss: 0.0110\n",
      "[6/28 | 21.4% |  0.4 min] Value: gelu, Epochs: 195, Loss: 0.0113\n",
      "[7/28 | 25.0% |  0.6 min] Value: elu, Epochs: 543, Loss: 0.0289\n",
      "[8/28 | 28.6% |  0.3 min] Value: silu, Epochs: 122, Loss: 0.0131\n",
      "Best activation = leakyrelu, val_loss = 0.0110\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.4 min] Value: 0.0001, Epochs: 331, Loss: 0.0167\n",
      "[10/28 | 35.7% |  0.2 min] Value: 0.001, Epochs: 83, Loss: 0.0110\n",
      "Best learning_rate = 0.001, val_loss = 0.0110\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.1 min] Value: 32, Epochs: 31, Loss: 0.0119\n",
      "[12/28 | 42.9% |  0.1 min] Value: 512, Epochs: 83, Loss: 0.0110\n",
      "[13/28 | 46.4% |  0.1 min] Value: 1024, Epochs: 83, Loss: 0.0110\n",
      "Best batch_size = 1024, val_loss = 0.0110\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.2 min] Value: 0.0, Epochs: 83, Loss: 0.0110\n",
      "[15/28 | 53.6% |  0.2 min] Value: 1e-05, Epochs: 83, Loss: 0.0110\n",
      "[16/28 | 57.1% |  0.2 min] Value: 0.0001, Epochs: 83, Loss: 0.0110\n",
      "[17/28 | 60.7% |  0.2 min] Value: 0.001, Epochs: 83, Loss: 0.0110\n",
      "[18/28 | 64.3% |  0.2 min] Value: 0.01, Epochs: 83, Loss: 0.0110\n",
      "Best weight_decay = 0.001, val_loss = 0.0110\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 83, Loss: 0.0110\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 86, Loss: 0.0093\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 40, Loss: 0.0176\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 33, Loss: 0.0321\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 18, Loss: 0.1247\n",
      "Best instance_dropout = 0.2, val_loss = 0.0093\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 57, Loss: 0.0093\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 39, Loss: 0.0164\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 40, Loss: 0.0113\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 84, Loss: 0.0088\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 88, Loss: 0.0096\n",
      "Best random_seed = 4, val_loss = 0.0088\n",
      "Stepwise optimization completed in 2.7 min\n",
      "\n",
      "\n",
      "[Task 8/9] Starting task: 'RingCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:14<00:00, 46.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 35, Loss: 0.4385\n",
      "[2/31 |  6.5% |  0.3 min] Value: (256, 128, 64), Epochs: 90, Loss: 0.3846\n",
      "[3/31 |  9.7% |  0.3 min] Value: (128,), Epochs: 90, Loss: 0.8410\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.3846\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.5 min] Value: relu, Epochs: 96, Loss: 0.3799\n",
      "[5/31 | 16.1% |  0.5 min] Value: leakyrelu, Epochs: 74, Loss: 0.3589\n",
      "[6/31 | 19.4% |  0.5 min] Value: gelu, Epochs: 67, Loss: 0.4021\n",
      "[7/31 | 22.6% |  0.4 min] Value: elu, Epochs: 59, Loss: 0.4323\n",
      "[8/31 | 25.8% |  0.5 min] Value: silu, Epochs: 75, Loss: 0.4227\n",
      "Best activation = leakyrelu, val_loss = 0.3589\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.3 min] Value: 0.0001, Epochs: 96, Loss: 0.3765\n",
      "[10/31 | 32.3% |  0.1 min] Value: 0.001, Epochs: 34, Loss: 0.4510\n",
      "Best learning_rate = 0.0001, val_loss = 0.3765\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 89, Loss: 0.3789\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 93, Loss: 0.6001\n",
      "[13/31 | 41.9% |  0.1 min] Value: 1024, Epochs: 94, Loss: 0.5999\n",
      "Best batch_size = 32, val_loss = 0.3789\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.7 min] Value: 0.0, Epochs: 100, Loss: 0.3639\n",
      "[15/31 | 48.4% |  0.7 min] Value: 1e-05, Epochs: 97, Loss: 0.3798\n",
      "[16/31 | 51.6% |  0.7 min] Value: 0.0001, Epochs: 103, Loss: 0.3686\n",
      "[17/31 | 54.8% |  0.5 min] Value: 0.001, Epochs: 66, Loss: 0.3952\n",
      "[18/31 | 58.1% |  0.6 min] Value: 0.01, Epochs: 85, Loss: 0.3635\n",
      "Best weight_decay = 0.01, val_loss = 0.3635\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.2 min] Value: 0.01, Epochs: 43, Loss: 0.7415\n",
      "[20/31 | 64.5% |  0.3 min] Value: 0.5, Epochs: 72, Loss: 0.3770\n",
      "[21/31 | 67.7% |  0.4 min] Value: 1.0, Epochs: 98, Loss: 0.3827\n",
      "Best tau = 0.5, val_loss = 0.3770\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.7 min] Value: 0.0, Epochs: 192, Loss: 0.1139\n",
      "[23/31 | 74.2% |  0.6 min] Value: 0.2, Epochs: 96, Loss: 0.2855\n",
      "[24/31 | 77.4% |  0.6 min] Value: 0.4, Epochs: 91, Loss: 0.4002\n",
      "[25/31 | 80.6% |  0.5 min] Value: 0.6, Epochs: 74, Loss: 0.5533\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 25, Loss: 0.7536\n",
      "Best instance_dropout = 0.0, val_loss = 0.1139\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.7 min] Value: 1, Epochs: 105, Loss: 0.2492\n",
      "[28/31 | 90.3% |  0.6 min] Value: 2, Epochs: 95, Loss: 0.1752\n",
      "[29/31 | 93.5% |  0.5 min] Value: 3, Epochs: 67, Loss: 0.2459\n",
      "[30/31 | 96.8% |  0.7 min] Value: 4, Epochs: 149, Loss: 0.2169\n",
      "[31/31 | 100.0% |  0.6 min] Value: 5, Epochs: 84, Loss: 0.2075\n",
      "Best random_seed = 2, val_loss = 0.1752\n",
      "Stepwise optimization completed in 3.8 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.1 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 39, Loss: 0.4422\n",
      "[2/31 |  6.5% |  0.1 min] Value: (256, 128, 64), Epochs: 73, Loss: 0.6598\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 115, Loss: 0.4897\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.4422\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 29, Loss: 0.6176\n",
      "[5/31 | 16.1% |  0.2 min] Value: leakyrelu, Epochs: 42, Loss: 0.5328\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 36, Loss: 0.3752\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 12, Loss: 0.7079\n",
      "[8/31 | 25.8% |  0.2 min] Value: silu, Epochs: 39, Loss: 0.4363\n",
      "Best activation = gelu, val_loss = 0.3752\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.1 min] Value: 0.0001, Epochs: 36, Loss: 0.3877\n",
      "[10/31 | 32.3% |  0.2 min] Value: 0.001, Epochs: 55, Loss: 0.2468\n",
      "Best learning_rate = 0.001, val_loss = 0.2468\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.4 min] Value: 32, Epochs: 28, Loss: 0.2472\n",
      "[12/31 | 38.7% |  0.3 min] Value: 512, Epochs: 40, Loss: 0.2567\n",
      "[13/31 | 41.9% |  0.2 min] Value: 1024, Epochs: 40, Loss: 0.2452\n",
      "Best batch_size = 1024, val_loss = 0.2452\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.3 min] Value: 0.0, Epochs: 48, Loss: 0.2453\n",
      "[15/31 | 48.4% |  0.3 min] Value: 1e-05, Epochs: 48, Loss: 0.2016\n",
      "[16/31 | 51.6% |  0.4 min] Value: 0.0001, Epochs: 55, Loss: 0.2303\n",
      "[17/31 | 54.8% |  0.3 min] Value: 0.001, Epochs: 41, Loss: 0.2293\n",
      "[18/31 | 58.1% |  0.4 min] Value: 0.01, Epochs: 56, Loss: 0.2278\n",
      "Best weight_decay = 1e-05, val_loss = 0.2016\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.2 min] Value: 0.01, Epochs: 34, Loss: 0.6806\n",
      "[20/31 | 64.5% |  0.2 min] Value: 0.5, Epochs: 57, Loss: 0.2557\n",
      "[21/31 | 67.7% |  0.2 min] Value: 1.0, Epochs: 36, Loss: 0.2183\n",
      "Best tau = 1.0, val_loss = 0.2183\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.2 min] Value: 0.0, Epochs: 65, Loss: 0.0778\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 44, Loss: 0.2105\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 50, Loss: 0.3500\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 17, Loss: 1.2640\n",
      "[26/31 | 83.9% |  0.1 min] Value: 0.8, Epochs: 14, Loss: 0.9847\n",
      "Best instance_dropout = 0.0, val_loss = 0.0778\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.3 min] Value: 1, Epochs: 65, Loss: 0.0778\n",
      "[28/31 | 90.3% |  0.3 min] Value: 2, Epochs: 58, Loss: 0.0861\n",
      "[29/31 | 93.5% |  0.3 min] Value: 3, Epochs: 84, Loss: 0.0697\n",
      "[30/31 | 96.8% |  0.2 min] Value: 4, Epochs: 54, Loss: 0.0841\n",
      "[31/31 | 100.0% |  0.4 min] Value: 5, Epochs: 102, Loss: 0.0644\n",
      "Best random_seed = 5, val_loss = 0.0644\n",
      "Stepwise optimization completed in 2.1 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 80, Loss: 0.0419\n",
      "[2/31 |  6.5% |  0.4 min] Value: (256, 128, 64), Epochs: 454, Loss: 0.0513\n",
      "[3/31 |  9.7% |  0.1 min] Value: (128,), Epochs: 47, Loss: 0.4475\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0419\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.5 min] Value: relu, Epochs: 80, Loss: 0.0391\n",
      "[5/31 | 16.1% |  0.5 min] Value: leakyrelu, Epochs: 83, Loss: 0.0405\n",
      "[6/31 | 19.4% |  0.4 min] Value: gelu, Epochs: 73, Loss: 0.0441\n",
      "[7/31 | 22.6% |  1.6 min] Value: elu, Epochs: 330, Loss: 0.1504\n",
      "[8/31 | 25.8% |  1.6 min] Value: silu, Epochs: 430, Loss: 0.0275\n",
      "Best activation = silu, val_loss = 0.0275\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.1 min] Value: 0.0001, Epochs: 26, Loss: 0.4801\n",
      "[10/31 | 32.3% |  0.9 min] Value: 0.001, Epochs: 247, Loss: 0.0309\n",
      "Best learning_rate = 0.001, val_loss = 0.0309\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  1.6 min] Value: 32, Epochs: 84, Loss: 0.0277\n",
      "[12/31 | 38.7% |  2.0 min] Value: 512, Epochs: 386, Loss: 0.0294\n",
      "[13/31 | 41.9% |  2.1 min] Value: 1024, Epochs: 411, Loss: 0.0314\n",
      "Best batch_size = 32, val_loss = 0.0277\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.4 min] Value: 0.0, Epochs: 83, Loss: 0.0269\n",
      "[15/31 | 48.4% |  0.8 min] Value: 1e-05, Epochs: 52, Loss: 0.0287\n",
      "[16/31 | 51.6% |  0.9 min] Value: 0.0001, Epochs: 53, Loss: 0.0317\n",
      "[17/31 | 54.8% |  1.3 min] Value: 0.001, Epochs: 72, Loss: 0.0269\n",
      "[18/31 | 58.1% |  1.0 min] Value: 0.01, Epochs: 61, Loss: 0.0306\n",
      "Best weight_decay = 0.001, val_loss = 0.0269\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.5 min] Value: 0.01, Epochs: 47, Loss: 0.0314\n",
      "[20/31 | 64.5% |  0.3 min] Value: 0.5, Epochs: 23, Loss: 0.6399\n",
      "[21/31 | 67.7% |  0.2 min] Value: 1.0, Epochs: 15, Loss: 0.5303\n",
      "Best tau = 0.01, val_loss = 0.0314\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.7 min] Value: 0.0, Epochs: 71, Loss: 0.0309\n",
      "[23/31 | 74.2% |  0.3 min] Value: 0.2, Epochs: 17, Loss: 0.2414\n",
      "[24/31 | 77.4% |  0.4 min] Value: 0.4, Epochs: 22, Loss: 0.4156\n",
      "[25/31 | 80.6% |  0.4 min] Value: 0.6, Epochs: 23, Loss: 0.7760\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 19, Loss: 0.7042\n",
      "Best instance_dropout = 0.0, val_loss = 0.0309\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.7 min] Value: 1, Epochs: 43, Loss: 0.0385\n",
      "[28/31 | 90.3% |  1.1 min] Value: 2, Epochs: 88, Loss: 0.0251\n",
      "[29/31 | 93.5% |  1.1 min] Value: 3, Epochs: 90, Loss: 0.0272\n",
      "[30/31 | 96.8% |  0.9 min] Value: 4, Epochs: 62, Loss: 0.0288\n",
      "[31/31 | 100.0% |  1.1 min] Value: 5, Epochs: 78, Loss: 0.0301\n",
      "Best random_seed = 2, val_loss = 0.0251\n",
      "Stepwise optimization completed in 8.7 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 13, Loss: 0.1738\n",
      "[2/28 |  7.1% |  0.0 min] Value: (256, 128, 64), Epochs: 15, Loss: 0.0226\n",
      "[3/28 | 10.7% |  0.0 min] Value: (128,), Epochs: 44, Loss: 0.0273\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0226\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.0 min] Value: relu, Epochs: 16, Loss: 0.0218\n",
      "[5/28 | 17.9% |  0.0 min] Value: leakyrelu, Epochs: 16, Loss: 0.0196\n",
      "[6/28 | 21.4% |  0.0 min] Value: gelu, Epochs: 12, Loss: 0.0260\n",
      "[7/28 | 25.0% |  0.0 min] Value: elu, Epochs: 32, Loss: 0.0411\n",
      "[8/28 | 28.6% |  0.0 min] Value: silu, Epochs: 13, Loss: 0.0284\n",
      "Best activation = leakyrelu, val_loss = 0.0196\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.0 min] Value: 0.0001, Epochs: 45, Loss: 0.0252\n",
      "[10/28 | 35.7% |  0.0 min] Value: 0.001, Epochs: 16, Loss: 0.0207\n",
      "Best learning_rate = 0.001, val_loss = 0.0207\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.0 min] Value: 32, Epochs: 14, Loss: 0.0372\n",
      "[12/28 | 42.9% |  0.0 min] Value: 512, Epochs: 16, Loss: 0.0207\n",
      "[13/28 | 46.4% |  0.0 min] Value: 1024, Epochs: 16, Loss: 0.0225\n",
      "Best batch_size = 512, val_loss = 0.0207\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.0 min] Value: 0.0, Epochs: 16, Loss: 0.0211\n",
      "[15/28 | 53.6% |  0.0 min] Value: 1e-05, Epochs: 16, Loss: 0.0222\n",
      "[16/28 | 57.1% |  0.0 min] Value: 0.0001, Epochs: 16, Loss: 0.0200\n",
      "[17/28 | 60.7% |  0.0 min] Value: 0.001, Epochs: 15, Loss: 0.0208\n",
      "[18/28 | 64.3% |  0.0 min] Value: 0.01, Epochs: 16, Loss: 0.0210\n",
      "Best weight_decay = 0.0001, val_loss = 0.0200\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.2 min] Value: 0.0, Epochs: 142, Loss: 0.0101\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 16, Loss: 0.0207\n",
      "[21/28 | 75.0% |  0.0 min] Value: 0.4, Epochs: 14, Loss: 0.0363\n",
      "[22/28 | 78.6% |  0.0 min] Value: 0.6, Epochs: 14, Loss: 0.0686\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 55, Loss: 0.0832\n",
      "Best instance_dropout = 0.0, val_loss = 0.0101\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.2 min] Value: 1, Epochs: 80, Loss: 0.0098\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 27, Loss: 0.0099\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 59, Loss: 0.0130\n",
      "[27/28 | 96.4% |  0.2 min] Value: 4, Epochs: 142, Loss: 0.0101\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 46, Loss: 0.0135\n",
      "Best random_seed = 1, val_loss = 0.0098\n",
      "Stepwise optimization completed in 0.6 min\n",
      "\n",
      "\n",
      "[Task 9/9] Starting task: 'FractionCSP3'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fragments: 100%|███████████████████████████████████████████████████████████| 672/672 [00:14<00:00, 46.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Model 1/4] Training model: 'AdditiveAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  1.3 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 96, Loss: 0.0349\n",
      "[2/31 |  6.5% |  0.8 min] Value: (256, 128, 64), Epochs: 111, Loss: 0.1449\n",
      "[3/31 |  9.7% |  1.0 min] Value: (128,), Epochs: 194, Loss: 0.3112\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0349\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.3 min] Value: relu, Epochs: 85, Loss: 0.0267\n",
      "[5/31 | 16.1% |  2.0 min] Value: leakyrelu, Epochs: 126, Loss: 0.0185\n",
      "[6/31 | 19.4% |  2.2 min] Value: gelu, Epochs: 132, Loss: 0.0408\n",
      "[7/31 | 22.6% |  2.2 min] Value: elu, Epochs: 138, Loss: 0.0413\n",
      "[8/31 | 25.8% |  2.4 min] Value: silu, Epochs: 163, Loss: 0.0246\n",
      "Best activation = leakyrelu, val_loss = 0.0185\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.8 min] Value: 0.0001, Epochs: 164, Loss: 0.0328\n",
      "[10/31 | 32.3% |  1.2 min] Value: 0.001, Epochs: 68, Loss: 0.0104\n",
      "Best learning_rate = 0.001, val_loss = 0.0104\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.7 min] Value: 32, Epochs: 82, Loss: 0.0080\n",
      "[12/31 | 38.7% |  0.5 min] Value: 512, Epochs: 163, Loss: 0.0101\n",
      "[13/31 | 41.9% |  0.5 min] Value: 1024, Epochs: 162, Loss: 0.0099\n",
      "Best batch_size = 32, val_loss = 0.0080\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.6 min] Value: 0.0, Epochs: 50, Loss: 0.0108\n",
      "[15/31 | 48.4% |  1.1 min] Value: 1e-05, Epochs: 109, Loss: 0.0048\n",
      "[16/31 | 51.6% |  0.6 min] Value: 0.0001, Epochs: 53, Loss: 0.0076\n",
      "[17/31 | 54.8% |  0.6 min] Value: 0.001, Epochs: 45, Loss: 0.0072\n",
      "[18/31 | 58.1% |  0.3 min] Value: 0.01, Epochs: 21, Loss: 0.3581\n",
      "Best weight_decay = 1e-05, val_loss = 0.0048\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.6 min] Value: 0.01, Epochs: 33, Loss: 0.2829\n",
      "[20/31 | 64.5% |  0.6 min] Value: 0.5, Epochs: 54, Loss: 0.0066\n",
      "[21/31 | 67.7% |  0.4 min] Value: 1.0, Epochs: 31, Loss: 0.0070\n",
      "Best tau = 0.5, val_loss = 0.0066\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.5 min] Value: 0.0, Epochs: 45, Loss: 0.0123\n",
      "[23/31 | 74.2% |  0.3 min] Value: 0.2, Epochs: 26, Loss: 0.2255\n",
      "[24/31 | 77.4% |  0.2 min] Value: 0.4, Epochs: 20, Loss: 0.2957\n",
      "[25/31 | 80.6% |  0.2 min] Value: 0.6, Epochs: 20, Loss: 0.3551\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 15, Loss: 0.4149\n",
      "Best instance_dropout = 0.0, val_loss = 0.0123\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  1.0 min] Value: 1, Epochs: 75, Loss: 0.0091\n",
      "[28/31 | 90.3% |  0.5 min] Value: 2, Epochs: 34, Loss: 0.0190\n",
      "[29/31 | 93.5% |  1.1 min] Value: 3, Epochs: 87, Loss: 0.0035\n",
      "[30/31 | 96.8% |  0.4 min] Value: 4, Epochs: 24, Loss: 0.3187\n",
      "[31/31 | 100.0% |  0.9 min] Value: 5, Epochs: 61, Loss: 0.0061\n",
      "Best random_seed = 3, val_loss = 0.0035\n",
      "Stepwise optimization completed in 9.4 min\n",
      "\n",
      "  [Model 2/4] Training model: 'SelfAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.4 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 92, Loss: 0.0113\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 116, Loss: 0.0493\n",
      "[3/31 |  9.7% |  0.4 min] Value: (128,), Epochs: 371, Loss: 0.0708\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0113\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  1.4 min] Value: relu, Epochs: 268, Loss: 0.0204\n",
      "[5/31 | 16.1% |  2.3 min] Value: leakyrelu, Epochs: 361, Loss: 0.0171\n",
      "[6/31 | 19.4% |  0.6 min] Value: gelu, Epochs: 92, Loss: 0.0113\n",
      "[7/31 | 22.6% |  0.4 min] Value: elu, Epochs: 63, Loss: 0.1590\n",
      "[8/31 | 25.8% |  2.8 min] Value: silu, Epochs: 594, Loss: 0.0111\n",
      "Best activation = silu, val_loss = 0.0111\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  1.8 min] Value: 0.0001, Epochs: 459, Loss: 0.0204\n",
      "[10/31 | 32.3% |  2.3 min] Value: 0.001, Epochs: 599, Loss: 0.0108\n",
      "Best learning_rate = 0.001, val_loss = 0.0108\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.8 min] Value: 32, Epochs: 40, Loss: 0.0085\n",
      "[12/31 | 38.7% |  2.9 min] Value: 512, Epochs: 597, Loss: 0.0124\n",
      "[13/31 | 41.9% |  2.9 min] Value: 1024, Epochs: 596, Loss: 0.0064\n",
      "Best batch_size = 1024, val_loss = 0.0064\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  4.1 min] Value: 0.0, Epochs: 595, Loss: 0.0099\n",
      "[15/31 | 48.4% |  4.1 min] Value: 1e-05, Epochs: 594, Loss: 0.0097\n",
      "[16/31 | 51.6% |  0.7 min] Value: 0.0001, Epochs: 94, Loss: 0.0107\n",
      "[17/31 | 54.8% |  4.0 min] Value: 0.001, Epochs: 594, Loss: 0.0097\n",
      "[18/31 | 58.1% |  4.0 min] Value: 0.01, Epochs: 609, Loss: 0.0105\n",
      "Best weight_decay = 1e-05, val_loss = 0.0097\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.2 min] Value: 0.01, Epochs: 27, Loss: 0.3240\n",
      "[20/31 | 64.5% |  2.1 min] Value: 0.5, Epochs: 370, Loss: 0.0187\n",
      "[21/31 | 67.7% |  2.7 min] Value: 1.0, Epochs: 594, Loss: 0.0100\n",
      "Best tau = 1.0, val_loss = 0.0100\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  1.3 min] Value: 0.0, Epochs: 594, Loss: 0.0117\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 48, Loss: 0.1330\n",
      "[24/31 | 77.4% |  0.1 min] Value: 0.4, Epochs: 25, Loss: 0.2203\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 24, Loss: 0.4256\n",
      "[26/31 | 83.9% |  0.2 min] Value: 0.8, Epochs: 41, Loss: 0.4037\n",
      "Best instance_dropout = 0.0, val_loss = 0.0117\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.3 min] Value: 1, Epochs: 61, Loss: 0.0129\n",
      "[28/31 | 90.3% |  1.6 min] Value: 2, Epochs: 584, Loss: 0.0068\n",
      "[29/31 | 93.5% |  0.3 min] Value: 3, Epochs: 69, Loss: 0.0123\n",
      "[30/31 | 96.8% |  1.1 min] Value: 4, Epochs: 302, Loss: 0.0109\n",
      "[31/31 | 100.0% |  1.1 min] Value: 5, Epochs: 312, Loss: 0.0106\n",
      "Best random_seed = 2, val_loss = 0.0068\n",
      "Stepwise optimization completed in 18.1 min\n",
      "\n",
      "  [Model 3/4] Training model: 'HopfieldAttentionNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.5 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 65, Loss: 0.0035\n",
      "[2/31 |  6.5% |  0.2 min] Value: (256, 128, 64), Epochs: 40, Loss: 0.0291\n",
      "[3/31 |  9.7% |  0.3 min] Value: (128,), Epochs: 148, Loss: 0.0418\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.0035\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.5 min] Value: relu, Epochs: 47, Loss: 0.0105\n",
      "[5/31 | 16.1% |  0.3 min] Value: leakyrelu, Epochs: 26, Loss: 0.0090\n",
      "[6/31 | 19.4% |  0.5 min] Value: gelu, Epochs: 56, Loss: 0.0037\n",
      "[7/31 | 22.6% |  0.5 min] Value: elu, Epochs: 47, Loss: 0.0109\n",
      "[8/31 | 25.8% |  0.5 min] Value: silu, Epochs: 64, Loss: 0.0032\n",
      "Best activation = silu, val_loss = 0.0032\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.6 min] Value: 0.0001, Epochs: 109, Loss: 0.0066\n",
      "[10/31 | 32.3% |  0.4 min] Value: 0.001, Epochs: 64, Loss: 0.0035\n",
      "Best learning_rate = 0.001, val_loss = 0.0035\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.4 min] Value: 32, Epochs: 51, Loss: 0.0034\n",
      "[12/31 | 38.7% |  0.6 min] Value: 512, Epochs: 270, Loss: 0.0030\n",
      "[13/31 | 41.9% |  0.5 min] Value: 1024, Epochs: 194, Loss: 0.0032\n",
      "Best batch_size = 512, val_loss = 0.0030\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  1.0 min] Value: 0.0, Epochs: 266, Loss: 0.0032\n",
      "[15/31 | 48.4% |  1.0 min] Value: 1e-05, Epochs: 294, Loss: 0.0061\n",
      "[16/31 | 51.6% |  1.0 min] Value: 0.0001, Epochs: 290, Loss: 0.0059\n",
      "[17/31 | 54.8% |  1.1 min] Value: 0.001, Epochs: 302, Loss: 0.0034\n",
      "[18/31 | 58.1% |  1.0 min] Value: 0.01, Epochs: 294, Loss: 0.0143\n",
      "Best weight_decay = 0.0, val_loss = 0.0032\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.6 min] Value: 0.01, Epochs: 303, Loss: 0.0103\n",
      "[20/31 | 64.5% |  0.1 min] Value: 0.5, Epochs: 37, Loss: 0.3704\n",
      "[21/31 | 67.7% |  0.1 min] Value: 1.0, Epochs: 26, Loss: 0.6309\n",
      "Best tau = 0.01, val_loss = 0.0103\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.6 min] Value: 0.0, Epochs: 336, Loss: 0.0116\n",
      "[23/31 | 74.2% |  0.2 min] Value: 0.2, Epochs: 53, Loss: 0.1075\n",
      "[24/31 | 77.4% |  0.1 min] Value: 0.4, Epochs: 46, Loss: 0.2841\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 39, Loss: 0.3037\n",
      "[26/31 | 83.9% |  0.1 min] Value: 0.8, Epochs: 20, Loss: 0.3864\n",
      "Best instance_dropout = 0.0, val_loss = 0.0116\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.8 min] Value: 1, Epochs: 247, Loss: 0.0042\n",
      "[28/31 | 90.3% |  0.9 min] Value: 2, Epochs: 326, Loss: 0.0127\n",
      "[29/31 | 93.5% |  0.6 min] Value: 3, Epochs: 173, Loss: 0.0057\n",
      "[30/31 | 96.8% |  0.4 min] Value: 4, Epochs: 123, Loss: 0.0067\n",
      "[31/31 | 100.0% |  0.7 min] Value: 5, Epochs: 225, Loss: 0.0067\n",
      "Best random_seed = 1, val_loss = 0.0042\n",
      "Stepwise optimization completed in 5.4 min\n",
      "\n",
      "  [Model 4/4] Training model: 'DynamicPoolingNetworkRegressor'\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.2 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 63, Loss: 0.0060\n",
      "[2/28 |  7.1% |  0.1 min] Value: (256, 128, 64), Epochs: 65, Loss: 0.0051\n",
      "[3/28 | 10.7% |  0.1 min] Value: (128,), Epochs: 138, Loss: 0.0128\n",
      "Best hidden_layer_sizes = (256, 128, 64), val_loss = 0.0051\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.2 min] Value: relu, Epochs: 66, Loss: 0.0050\n",
      "[5/28 | 17.9% |  0.2 min] Value: leakyrelu, Epochs: 65, Loss: 0.0051\n",
      "[6/28 | 21.4% |  0.2 min] Value: gelu, Epochs: 112, Loss: 0.0089\n",
      "[7/28 | 25.0% |  0.2 min] Value: elu, Epochs: 118, Loss: 0.0549\n",
      "[8/28 | 28.6% |  0.2 min] Value: silu, Epochs: 92, Loss: 0.0130\n",
      "Best activation = relu, val_loss = 0.0050\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.2 min] Value: 0.0001, Epochs: 344, Loss: 0.0059\n",
      "[10/28 | 35.7% |  0.1 min] Value: 0.001, Epochs: 66, Loss: 0.0050\n",
      "Best learning_rate = 0.001, val_loss = 0.0050\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.1 min] Value: 32, Epochs: 25, Loss: 0.0059\n",
      "[12/28 | 42.9% |  0.1 min] Value: 512, Epochs: 66, Loss: 0.0050\n",
      "[13/28 | 46.4% |  0.1 min] Value: 1024, Epochs: 66, Loss: 0.0050\n",
      "Best batch_size = 1024, val_loss = 0.0050\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.2 min] Value: 0.0, Epochs: 66, Loss: 0.0050\n",
      "[15/28 | 53.6% |  0.2 min] Value: 1e-05, Epochs: 66, Loss: 0.0050\n",
      "[16/28 | 57.1% |  0.2 min] Value: 0.0001, Epochs: 66, Loss: 0.0050\n",
      "[17/28 | 60.7% |  0.2 min] Value: 0.001, Epochs: 66, Loss: 0.0050\n",
      "[18/28 | 64.3% |  0.2 min] Value: 0.01, Epochs: 66, Loss: 0.0050\n",
      "Best weight_decay = 0.01, val_loss = 0.0050\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 66, Loss: 0.0050\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 47, Loss: 0.0161\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 25, Loss: 0.0342\n",
      "[22/28 | 78.6% |  0.0 min] Value: 0.6, Epochs: 15, Loss: 0.0631\n",
      "[23/28 | 82.1% |  0.0 min] Value: 0.8, Epochs: 14, Loss: 0.1389\n",
      "Best instance_dropout = 0.0, val_loss = 0.0050\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 66, Loss: 0.0050\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 48, Loss: 0.0085\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 50, Loss: 0.0048\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 102, Loss: 0.0046\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 44, Loss: 0.0087\n",
      "Best random_seed = 4, val_loss = 0.0046\n",
      "Stepwise optimization completed in 1.0 min\n",
      "\n",
      "\n",
      "All tasks and models completed.\n"
     ]
    }
   ],
   "source": [
    "bag_size = 5\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "tasks = [\"LogP\", \"MolWt\", \"TPSA\", \"NumHDonors\", \"NumHAcceptors\", \n",
    "         \"MolMR\", \"NumRotatableBonds\", \"RingCount\", \"FractionCSP3\"]\n",
    "\n",
    "for task_idx, task in enumerate(tasks, 1):\n",
    "    print(f\"\\n[Task {task_idx}/{len(tasks)}] Starting task: '{task}'\")\n",
    "\n",
    "    # load data\n",
    "    REPO_ID = \"KagakuData/notebooks\"\n",
    "    csv_path = hf_hub_download(REPO_ID, filename=\"chembl/CHEMBL279.csv\", repo_type=\"dataset\")\n",
    "    data = pd.read_csv(csv_path, header=None)\n",
    "    smiles = list(data[0])\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "\n",
    "    # compute bag desc\n",
    "    frag_gen = FragmentGenerator(num_cpu=40, verbose=True)\n",
    "    frags = frag_gen.run(mols)\n",
    "    #\n",
    "    bag_size = 5\n",
    "    rng = np.random.RandomState(42)\n",
    "    frags = [mol for mol in frags if len(mol) > bag_size]\n",
    "    frags = [rng.choice(mol, size=bag_size, replace=False).tolist() for mol in frags]\n",
    "    #\n",
    "    get_property = PROPERTY_FUNCTIONS[task]\n",
    "    contribs = [[get_property(f) for f in mol] for mol in frags]\n",
    "    props = [sum(m) for m in contribs]\n",
    "    #\n",
    "    desc = compute_fragment_descriptors(frags)\n",
    "    #\n",
    "    x_train, x_test, y_train, y_test, key_train, key_test, frg_train, frg_test = train_test_split(\n",
    "        desc, props, contribs, frags, random_state=42)\n",
    "    \n",
    "    # scale features\n",
    "    scaler = BagMinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train_scaled, x_test_scaled = scaler.transform(x_train), scaler.transform(x_test)\n",
    "    \n",
    "    # build models\n",
    "    for model_idx, (name, model) in enumerate(regressor_list, 1):\n",
    "        print(f\"  [Model {model_idx}/{len(regressor_list)}] Training model: '{name}'\")\n",
    "\n",
    "        # train model\n",
    "        model.hopt(x_train_scaled, y_train, param_grid=DEFAULT_PARAM_GRID, verbose=True)\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        \n",
    "        # predict\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "        w_pred = model.get_instance_weights(x_test_scaled)\n",
    "        w_pred = [w.flatten() for w in w_pred]\n",
    "        #\n",
    "        res_df.loc[name, f\"PRED_{task}\"] = r2_score(y_test, y_pred)\n",
    "        res_df.loc[name, f\"KID_{task}\"] = kid_ranking_accuracy(key_test, w_pred)\n",
    "\n",
    "print(\"\\nAll tasks and models completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df0ed6f6-21c1-4087-96fd-51efdc662085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRED_LogP</th>\n",
       "      <th>KID_LogP</th>\n",
       "      <th>PRED_MolWt</th>\n",
       "      <th>KID_MolWt</th>\n",
       "      <th>PRED_TPSA</th>\n",
       "      <th>KID_TPSA</th>\n",
       "      <th>PRED_NumHDonors</th>\n",
       "      <th>KID_NumHDonors</th>\n",
       "      <th>PRED_NumHAcceptors</th>\n",
       "      <th>KID_NumHAcceptors</th>\n",
       "      <th>PRED_MolMR</th>\n",
       "      <th>KID_MolMR</th>\n",
       "      <th>PRED_NumRotatableBonds</th>\n",
       "      <th>KID_NumRotatableBonds</th>\n",
       "      <th>PRED_RingCount</th>\n",
       "      <th>KID_RingCount</th>\n",
       "      <th>PRED_FractionCSP3</th>\n",
       "      <th>KID_FractionCSP3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdditiveAttentionNetworkRegressor</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelfAttentionNetworkRegressor</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HopfieldAttentionNetworkRegressor</th>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DynamicPoolingNetworkRegressor</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   PRED_LogP  KID_LogP  PRED_MolWt  KID_MolWt  \\\n",
       "AdditiveAttentionNetworkRegressor       0.65      0.11        0.92       0.24   \n",
       "SelfAttentionNetworkRegressor           0.74      0.17        0.38       0.59   \n",
       "HopfieldAttentionNetworkRegressor       0.10     -0.10        0.41       0.80   \n",
       "DynamicPoolingNetworkRegressor          0.67      0.71        0.83       0.88   \n",
       "\n",
       "                                   PRED_TPSA  KID_TPSA  PRED_NumHDonors  \\\n",
       "AdditiveAttentionNetworkRegressor       0.85      0.36             0.87   \n",
       "SelfAttentionNetworkRegressor           0.49      0.70             0.78   \n",
       "HopfieldAttentionNetworkRegressor       0.35      0.60             0.03   \n",
       "DynamicPoolingNetworkRegressor          0.81      0.90             0.88   \n",
       "\n",
       "                                   KID_NumHDonors  PRED_NumHAcceptors  \\\n",
       "AdditiveAttentionNetworkRegressor            0.38                0.92   \n",
       "SelfAttentionNetworkRegressor                0.24                0.88   \n",
       "HopfieldAttentionNetworkRegressor           -0.33                0.58   \n",
       "DynamicPoolingNetworkRegressor               0.62                0.71   \n",
       "\n",
       "                                   KID_NumHAcceptors  PRED_MolMR  KID_MolMR  \\\n",
       "AdditiveAttentionNetworkRegressor              -0.05        0.96       0.66   \n",
       "SelfAttentionNetworkRegressor                   0.00        0.31       0.82   \n",
       "HopfieldAttentionNetworkRegressor               0.66        0.40       0.84   \n",
       "DynamicPoolingNetworkRegressor                  0.88        0.84       0.86   \n",
       "\n",
       "                                   PRED_NumRotatableBonds  \\\n",
       "AdditiveAttentionNetworkRegressor                    0.65   \n",
       "SelfAttentionNetworkRegressor                        0.70   \n",
       "HopfieldAttentionNetworkRegressor                    0.66   \n",
       "DynamicPoolingNetworkRegressor                       0.68   \n",
       "\n",
       "                                   KID_NumRotatableBonds  PRED_RingCount  \\\n",
       "AdditiveAttentionNetworkRegressor                   0.12            0.94   \n",
       "SelfAttentionNetworkRegressor                       0.14            0.95   \n",
       "HopfieldAttentionNetworkRegressor                   0.09            0.42   \n",
       "DynamicPoolingNetworkRegressor                      0.15            0.68   \n",
       "\n",
       "                                   KID_RingCount  PRED_FractionCSP3  \\\n",
       "AdditiveAttentionNetworkRegressor           0.08               0.99   \n",
       "SelfAttentionNetworkRegressor               0.30               0.99   \n",
       "HopfieldAttentionNetworkRegressor           0.79               0.46   \n",
       "DynamicPoolingNetworkRegressor              0.85               0.89   \n",
       "\n",
       "                                   KID_FractionCSP3  \n",
       "AdditiveAttentionNetworkRegressor              0.11  \n",
       "SelfAttentionNetworkRegressor                  0.54  \n",
       "HopfieldAttentionNetworkRegressor              0.59  \n",
       "DynamicPoolingNetworkRegressor                 0.71  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98beab-6d0d-4e77-931b-ff51e7c10abd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsarmil",
   "language": "python",
   "name": "qsarmil"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
