{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a064a01-df10-4435-9689-eea1fd1f4d49",
   "metadata": {},
   "source": [
    "### 1. Key Instance Detection\n",
    "\n",
    "Some MIL algorithms can identify key instances (if they have get_instance_weights method). In this section, AttentionNetworkRegressor is used to estimate the conformer weights. Here, different 3D descriptors are used to estimate the weight distribution depending on the representation type.\n",
    "\n",
    "**Conclusion:** With current representations available the weight distribution is not definitive (almost uniform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826a68c-2e11-4897-a4be-5d236c7fa05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsarmil.descriptor.rdkit import (RDKitGEOM, \n",
    "                                      RDKitAUTOCORR, \n",
    "                                      RDKitRDF, \n",
    "                                      RDKitMORSE, \n",
    "                                      RDKitWHIM, \n",
    "                                      RDKitGETAWAY)\n",
    "\n",
    "from molfeat.calc import (Pharmacophore3D, \n",
    "                          USRDescriptors, \n",
    "                          ElectroShapeDescriptors)\n",
    "\n",
    "from qsarmil.descriptor.wrapper import DescriptorWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13bd69-4c30-4a6d-b04f-b7e60fdbb6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_list = [\n",
    "             (\"RDKitGEOM\", DescriptorWrapper(RDKitGEOM())),\n",
    "             (\"RDKitAUTOCORR\", DescriptorWrapper(RDKitAUTOCORR())),\n",
    "             (\"RDKitRDF\", DescriptorWrapper(RDKitRDF())),\n",
    "             (\"RDKitMORSE\", DescriptorWrapper(RDKitMORSE())),\n",
    "             (\"RDKitWHIM\", DescriptorWrapper(RDKitWHIM())),\n",
    "             # (\"RDKitGETAWAY\", DescriptorWrapper(RDKitGETAWAY())), # can be long\n",
    "             # (\"MolFeatPmapper\", DescriptorWrapper(Pharmacophore3D(factory='pmapper'))), # can be long\n",
    "             (\"MolFeatUSRD\", DescriptorWrapper(USRDescriptors())),\n",
    "             (\"MolFeatElectroShape\", DescriptorWrapper(ElectroShapeDescriptors())),\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150f610f-09c0-497d-9efd-40a2af63cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_hparams = {'hidden_layer_sizes':(256, 128, 64),\n",
    "                   'num_epoch':300,\n",
    "                   'batch_size':128,\n",
    "                   'learning_rate':0.001,\n",
    "                   'weight_decay':0.001,\n",
    "                   'instance_weight_dropout':0.01,\n",
    "                   'init_cuda':False,\n",
    "                   'verbose':False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42034654-2e25-493d-b070-69e2eecd3532",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list = [pd.DataFrame() for _ in confs_test]\n",
    "for desc_name, desc_calc in desc_list:\n",
    "    \n",
    "    # calc descriptors\n",
    "    x_train = desc_calc.transform(confs_train)\n",
    "    x_test = desc_calc.transform(confs_test)\n",
    "\n",
    "    # scale descriptors\n",
    "    scaler = BagMinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train_scaled = scaler.transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "    # train model\n",
    "    model = AttentionNetworkRegressor(**network_hparams)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "\n",
    "    # get instance weights\n",
    "    w_pred = model.get_instance_weights(x_test_scaled)\n",
    "    for w, df in zip(w_pred, w_list):\n",
    "        df[desc_name] = w\n",
    "        df.index = [f\"Conformer_{i + 1}\" for i in range(len(w))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d6ad44-3fe8-4d0e-8da0-1f38afa04f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list[0].round(2) # molecule 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c45ba-1dc1-457f-8ff9-5f1d34e5c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_list[1].round(2) # molecule 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8389b-1cd4-4944-8745-40338aa00f25",
   "metadata": {},
   "source": [
    "### 2. Intra-bag vs. Inter-bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b20ff-f0b4-4ad8-a5d4-8013fdd9faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_bag_variances(bags):\n",
    "    \"\"\"\n",
    "    Computes intra-bag and inter-bag variance from a list of bags.\n",
    "\n",
    "    Parameters:\n",
    "    - bags: list of np.ndarray, each of shape (n_instances, descriptor_dim)\n",
    "\n",
    "    Returns:\n",
    "    - intra_bag_variances: list of float (one per bag)\n",
    "    - mean_intra_bag_variance: float\n",
    "    - inter_bag_variance: float\n",
    "    \"\"\"\n",
    "    bag_means = []\n",
    "    intra_bag_variances = []\n",
    "\n",
    "    for bag in bags:\n",
    "        if bag.shape[0] == 0:\n",
    "            raise ValueError(\"A bag is empty.\")\n",
    "        bag_mean = bag.mean(axis=0)\n",
    "        bag_means.append(bag_mean)\n",
    "        variance = np.mean(np.linalg.norm(bag - bag_mean, axis=1) ** 2)\n",
    "        intra_bag_variances.append(variance)\n",
    "\n",
    "    # Convert list of means to array\n",
    "    bag_means = np.stack(bag_means, axis=0)\n",
    "    global_mean = bag_means.mean(axis=0)\n",
    "\n",
    "    # Inter-bag variance: variance of bag means from global mean\n",
    "    inter_bag_variance = np.mean(np.linalg.norm(bag_means - global_mean, axis=1) ** 2)\n",
    "\n",
    "    return intra_bag_variances, np.mean(intra_bag_variances), inter_bag_variance\n",
    "\n",
    "def normalized_entropy(weights, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes normalized entropy of a vector of attention weights.\n",
    "\n",
    "    Parameters:\n",
    "    - weights: array-like of shape (n,) â€” non-negative, need not be normalized\n",
    "    - epsilon: small value to avoid log(0)\n",
    "\n",
    "    Returns:\n",
    "    - norm_entropy: float in [0, 1], where 0 = sharp, 1 = flat\n",
    "    \"\"\"\n",
    "    weights = np.asarray(weights, dtype=np.float64)\n",
    "    weights = weights / (weights.sum() + epsilon)  # normalize\n",
    "\n",
    "    entropy = -np.sum(weights * np.log(weights + epsilon))\n",
    "    max_entropy = np.log(len(weights) + epsilon)\n",
    "\n",
    "    return entropy / max_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d17af-6103-4579-99f4-6489224497ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df = pd.DataFrame()\n",
    "for desc_name, desc_calc in desc_list:\n",
    "\n",
    "    # calc descriptors\n",
    "    x_train = desc_calc.transform(confs_train)\n",
    "    x_test = desc_calc.transform(confs_test)\n",
    "    \n",
    "    # scale bags\n",
    "    bags = x_train + x_test\n",
    "    scaler = BagMinMaxScaler()\n",
    "    scaler.fit(bags)\n",
    "    bags_scaled = scaler.transform(bags)\n",
    "    \n",
    "    # calc var\n",
    "    intra_vars, mean_intra, mean_inter = compute_bag_variances(bags_scaled)\n",
    "    \n",
    "    # save results\n",
    "    var_df.loc[desc_name, \"intra\"] = mean_intra.item()\n",
    "    var_df.loc[desc_name, \"inter\"] = mean_inter.item()\n",
    "    var_df.loc[desc_name, \"ratio\"] = (mean_intra / mean_inter).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1541d-be3f-4c0c-8b35-70c24fe43d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edb9e2c-7c9f-441d-b9ba-5ba81fd74227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ent_dict = defaultdict(list)\n",
    "for bag in w_list:\n",
    "    for dsc in bag.columns:\n",
    "        ent_dict[dsc].append(normalized_entropy(bag[dsc]))\n",
    "#\n",
    "ent_df = pd.DataFrame()\n",
    "for k, v in ent_dict.items():\n",
    "    ent_df.loc[k, \"ent\"] = np.mean(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84833c66-08c2-4c65-b0af-6097e4aa52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([var_df, ent_df], axis=1).sort_values(by=\"ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436abd7-a14d-4a86-ae7a-831b5be89f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1597b4-453c-4da5-be1a-ddc8eda53d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec1d83-6f83-4e8a-bfd7-292bf954e248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
