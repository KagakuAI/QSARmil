{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load dataset\n",
    "\n",
    "The example datasets contain molecule structure (SMILES) and measured bioactivity (pKi or IC50) – the higher the better. Each SMILES is converted to a Mol object in RDKit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "from sklearn.metrics import r2_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_to_clf(y):\n",
    "    return np.where(np.array(y) > 6, 1, 0)\n",
    "\n",
    "def accuracy_metric(y_true, y_pred, task=None):\n",
    "    if task == \"classification\":\n",
    "        return accuracy_score(y_true, y_pred)\n",
    "    elif task == \"regression\":\n",
    "        return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"regression\"\n",
    "# TASK = \"classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/CHEMBL1824/train.csv', header=None)\n",
    "data_test = pd.read_csv('data/CHEMBL1824/test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "smi_train, prop_train = data_train[0].to_list(), data_train[1].to_list()\n",
    "smi_test, prop_test = data_test[0].to_list(), data_test[1].to_list()\n",
    "\n",
    "if TASK == \"classification\":\n",
    "    prop_train, prop_test = reg_to_clf(prop_train), reg_to_clf(prop_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_train, y_train = [], []\n",
    "for smi, prop in zip(smi_train, prop_train):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol:\n",
    "        mols_train.append(mol)\n",
    "        y_train.append(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_test, y_test = [], []\n",
    "for smi, prop in zip(smi_test, prop_test):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    if mol:\n",
    "        mols_test.append(mol)\n",
    "        y_test.append(prop)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Reduce the dataset size for faster pipeline (for playing around)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols_train, y_train = mols_train[:80], y_train[:80]\n",
    "mols_test, y_test = mols_test[:20], y_test[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Conformer generation\n",
    "\n",
    "For each molecule, an ensemble of conformers is generated. Then, molecules for which conformer generation failed are filtered out from both, the training and test set. Generated conformers can be accessed by mol.GetConformers(confID=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsarmil.conformer import RDKitConformerGenerator\n",
    "\n",
    "from qsarmil.utils.logging import FailedConformer, FailedDescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_gen = RDKitConformerGenerator(num_conf=10, num_cpu=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating conformers: 100%|████████████████████████████████████████████████████████████| 80/80 [00:05<00:00, 15.92it/s]\n"
     ]
    }
   ],
   "source": [
    "confs_train = conf_gen.run(mols_train)\n",
    "\n",
    "tmp = [(c, y) for c, y in zip(confs_train, y_train) if not isinstance(c, FailedConformer)]\n",
    "confs_train, y_train = zip(*tmp) \n",
    "confs_train, y_train = list(confs_train), list(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating conformers: 100%|████████████████████████████████████████████████████████████| 20/20 [00:02<00:00,  8.37it/s]\n"
     ]
    }
   ],
   "source": [
    "confs_test = conf_gen.run(mols_test)\n",
    "\n",
    "tmp = [(c, y) for c, y in zip(confs_test, y_test) if not isinstance(c, FailedConformer)]\n",
    "confs_test, y_test = zip(*tmp) \n",
    "confs_test, y_test = list(confs_test), list(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptor calculation\n",
    "\n",
    "Then, for each molecule with associated conformers 3D descriptors are calculated. Here, a descriptor wrapper is used, which is designed to apply descriptor calculators from external packages. The resulting descriptors are a list of 2D arrays (bags). Also, the resulting descriptors are scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qsarmil.descriptor.rdkit import (RDKitGEOM, \n",
    "                                      RDKitAUTOCORR, \n",
    "                                      RDKitRDF, \n",
    "                                      RDKitMORSE, \n",
    "                                      RDKitWHIM, \n",
    "                                      RDKitGETAWAY)\n",
    "\n",
    "from molfeat.calc import Pharmacophore3D, USRDescriptors, ElectroShapeDescriptors\n",
    "\n",
    "from qsarmil.descriptor.wrapper import DescriptorWrapper\n",
    "\n",
    "from milearn.preprocessing import BagMinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_calc = DescriptorWrapper(RDKitRDF())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = desc_calc.transform(confs_train)\n",
    "x_test = desc_calc.transform(confs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = BagMinMaxScaler()\n",
    "\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_scaled = scaler.transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST dataset creation\n",
    "from milearn.data.mnist import load_mnist, create_bags_or, create_bags_and, create_bags_xor, create_bags_reg\n",
    "\n",
    "# Preprocessing\n",
    "from milearn.preprocessing import BagMinMaxScaler\n",
    "\n",
    "# Network hparams\n",
    "from milearn.network.module.hopt import DEFAULT_PARAM_GRID\n",
    "\n",
    "# MIL wrappers\n",
    "from milearn.network.regressor import BagWrapperMLPNetworkRegressor, InstanceWrapperMLPNetworkRegressor\n",
    "from milearn.network.classifier import BagWrapperMLPNetworkClassifier, InstanceWrapperMLPNetworkClassifier\n",
    "\n",
    "# MIL networks\n",
    "from milearn.network.regressor import (InstanceNetworkRegressor,\n",
    "                                       BagNetworkRegressor,\n",
    "                                       AdditiveAttentionNetworkRegressor,\n",
    "                                       SelfAttentionNetworkRegressor,\n",
    "                                       HopfieldAttentionNetworkRegressor,\n",
    "                                       DynamicPoolingNetworkRegressor)\n",
    "\n",
    "from milearn.network.classifier import (InstanceNetworkClassifier,\n",
    "                                        BagNetworkClassifier,\n",
    "                                        AdditiveAttentionNetworkClassifier,\n",
    "                                        SelfAttentionNetworkClassifier,\n",
    "                                        HopfieldAttentionNetworkClassifier,\n",
    "                                        DynamicPoolingNetworkClassifier)\n",
    "\n",
    "# Utils\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor_list = [\n",
    "\n",
    "        # wrapper mil networks\n",
    "        (\"MeanBagWrapperMLPNetworkRegressor\", BagWrapperMLPNetworkRegressor(pool=\"mean\")),\n",
    "        (\"MeanInstanceWrapperMLPNetworkRegressor\", InstanceWrapperMLPNetworkRegressor(pool=\"mean\")),\n",
    "    \n",
    "        # classic mil networks\n",
    "        (\"MeanBagNetworkRegressor\", BagNetworkRegressor(pool=\"mean\")),\n",
    "        (\"MeanInstanceNetworkRegressor\", InstanceNetworkRegressor(pool=\"mean\")),\n",
    "\n",
    "        # attention mil networks\n",
    "        (\"AdditiveAttentionNetworkRegressor\", AdditiveAttentionNetworkRegressor()),\n",
    "        (\"SelfAttentionNetworkRegressor\", SelfAttentionNetworkRegressor()),\n",
    "        (\"HopfieldAttentionNetworkRegressor\", HopfieldAttentionNetworkRegressor()),\n",
    "\n",
    "        # other mil networks\n",
    "        (\"DynamicPoolingNetworkRegressor\", DynamicPoolingNetworkRegressor()),\n",
    "    ]\n",
    "\n",
    "classifier_list = [\n",
    "\n",
    "        # wrapper mil networks\n",
    "        (\"MeanBagWrapperMLPNetworkClassifier\", BagWrapperMLPNetworkClassifier(pool=\"mean\")),\n",
    "        (\"MeanInstanceWrapperMLPNetworkClassifier\", InstanceWrapperMLPNetworkClassifier(pool=\"mean\")),\n",
    "    \n",
    "        # classic mil networks\n",
    "        (\"MeanBagNetworkClassifier\", BagNetworkClassifier(pool=\"mean\")),\n",
    "        (\"MeanInstanceNetworkClassifier\", InstanceNetworkClassifier(pool=\"mean\")),\n",
    "\n",
    "        # attention mil networks\n",
    "        (\"AdditiveAttentionNetworkClassifier\", AdditiveAttentionNetworkClassifier()),\n",
    "        (\"SelfAttentionNetworkClassifier\", SelfAttentionNetworkClassifier()),\n",
    "        (\"HopfieldAttentionNetworkClassifier\", HopfieldAttentionNetworkClassifier()),\n",
    "\n",
    "        # other mil networks\n",
    "        (\"DynamicPoolingNetworkClassifier\", DynamicPoolingNetworkClassifier()),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeanBagWrapperMLPNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 30, Loss: 1.9428\n",
      "[2/28 |  7.1% |  0.0 min] Value: (256, 128, 64), Epochs: 51, Loss: 2.1204\n",
      "[3/28 | 10.7% |  0.0 min] Value: (128,), Epochs: 47, Loss: 7.4852\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 1.9428\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.1 min] Value: relu, Epochs: 64, Loss: 1.6078\n",
      "[5/28 | 17.9% |  0.1 min] Value: leakyrelu, Epochs: 71, Loss: 1.9903\n",
      "[6/28 | 21.4% |  0.1 min] Value: gelu, Epochs: 52, Loss: 1.3541\n",
      "[7/28 | 25.0% |  0.1 min] Value: elu, Epochs: 29, Loss: 2.1464\n",
      "[8/28 | 28.6% |  0.1 min] Value: silu, Epochs: 34, Loss: 0.8457\n",
      "Best activation = silu, val_loss = 0.8457\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.1 min] Value: 0.0001, Epochs: 55, Loss: 6.0836\n",
      "[10/28 | 35.7% |  0.1 min] Value: 0.001, Epochs: 43, Loss: 0.7298\n",
      "Best learning_rate = 0.001, val_loss = 0.7298\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.1 min] Value: 32, Epochs: 34, Loss: 1.1421\n",
      "[12/28 | 42.9% |  0.0 min] Value: 512, Epochs: 28, Loss: 1.5941\n",
      "[13/28 | 46.4% |  0.0 min] Value: 1024, Epochs: 41, Loss: 0.7237\n",
      "Best batch_size = 1024, val_loss = 0.7237\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.1 min] Value: 0.0, Epochs: 33, Loss: 0.9119\n",
      "[15/28 | 53.6% |  0.1 min] Value: 1e-05, Epochs: 34, Loss: 1.0372\n",
      "[16/28 | 57.1% |  0.1 min] Value: 0.0001, Epochs: 32, Loss: 1.0829\n",
      "[17/28 | 60.7% |  0.1 min] Value: 0.001, Epochs: 39, Loss: 0.8786\n",
      "[18/28 | 64.3% |  0.1 min] Value: 0.01, Epochs: 34, Loss: 0.8666\n",
      "Best weight_decay = 0.01, val_loss = 0.8666\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 32, Loss: 0.9260\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 35, Loss: 0.9450\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 42, Loss: 0.7401\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 43, Loss: 1.1745\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 39, Loss: 1.0226\n",
      "Best instance_dropout = 0.4, val_loss = 0.7401\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 56, Loss: 0.8101\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 32, Loss: 1.0427\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 27, Loss: 1.3215\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 36, Loss: 0.8824\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 27, Loss: 0.9800\n",
      "Best random_seed = 1, val_loss = 0.8101\n",
      "Stepwise optimization completed in 0.6 min\n",
      "\n",
      "MeanInstanceWrapperMLPNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  1.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 180, Loss: 0.1504\n",
      "[2/28 |  7.1% |  0.5 min] Value: (256, 128, 64), Epochs: 164, Loss: 0.4196\n",
      "[3/28 | 10.7% |  0.7 min] Value: (128,), Epochs: 368, Loss: 0.4542\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.1504\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.7 min] Value: relu, Epochs: 113, Loss: 0.2597\n",
      "[5/28 | 17.9% |  0.5 min] Value: leakyrelu, Epochs: 71, Loss: 0.5037\n",
      "[6/28 | 21.4% |  0.6 min] Value: gelu, Epochs: 80, Loss: 0.3102\n",
      "[7/28 | 25.0% |  0.4 min] Value: elu, Epochs: 48, Loss: 0.7848\n",
      "[8/28 | 28.6% |  0.7 min] Value: silu, Epochs: 110, Loss: 0.4375\n",
      "Best activation = relu, val_loss = 0.2597\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  1.0 min] Value: 0.0001, Epochs: 246, Loss: 0.2861\n",
      "[10/28 | 35.7% |  0.4 min] Value: 0.001, Epochs: 90, Loss: 0.5307\n",
      "Best learning_rate = 0.0001, val_loss = 0.2861\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  1.9 min] Value: 32, Epochs: 174, Loss: 0.2104\n",
      "[12/28 | 42.9% |  0.9 min] Value: 512, Epochs: 417, Loss: 0.3340\n",
      "[13/28 | 46.4% |  0.1 min] Value: 1024, Epochs: 51, Loss: 7.8308\n",
      "Best batch_size = 32, val_loss = 0.2104\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  3.1 min] Value: 0.0, Epochs: 132, Loss: 0.2674\n",
      "[15/28 | 53.6% |  2.8 min] Value: 1e-05, Epochs: 103, Loss: 0.2478\n",
      "[16/28 | 57.1% |  2.5 min] Value: 0.0001, Epochs: 88, Loss: 0.4681\n",
      "[17/28 | 60.7% |  4.0 min] Value: 0.001, Epochs: 193, Loss: 0.2193\n",
      "[18/28 | 64.3% |  3.5 min] Value: 0.01, Epochs: 145, Loss: 0.2129\n",
      "Best weight_decay = 0.01, val_loss = 0.2129\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  4.1 min] Value: 0.0, Epochs: 148, Loss: 0.2058\n",
      "[20/28 | 71.4% |  4.4 min] Value: 0.2, Epochs: 176, Loss: 0.1580\n",
      "[21/28 | 75.0% |  4.2 min] Value: 0.4, Epochs: 159, Loss: 0.1930\n",
      "[22/28 | 78.6% |  3.8 min] Value: 0.6, Epochs: 140, Loss: 0.1986\n",
      "[23/28 | 82.1% |  4.1 min] Value: 0.8, Epochs: 156, Loss: 0.2064\n",
      "Best instance_dropout = 0.2, val_loss = 0.1580\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  4.7 min] Value: 1, Epochs: 177, Loss: 0.1802\n",
      "[25/28 | 89.3% |  4.9 min] Value: 2, Epochs: 196, Loss: 0.1668\n",
      "[26/28 | 92.9% |  4.3 min] Value: 3, Epochs: 160, Loss: 0.2058\n",
      "[27/28 | 96.4% |  4.7 min] Value: 4, Epochs: 176, Loss: 0.2127\n",
      "[28/28 | 100.0% |  4.2 min] Value: 5, Epochs: 149, Loss: 0.2470\n",
      "Best random_seed = 2, val_loss = 0.1668\n",
      "Stepwise optimization completed in 17.9 min\n",
      "\n",
      "MeanBagNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 19, Loss: 0.6963\n",
      "[2/28 |  7.1% |  0.1 min] Value: (256, 128, 64), Epochs: 129, Loss: 1.0670\n",
      "[3/28 | 10.7% |  0.0 min] Value: (128,), Epochs: 37, Loss: 6.8123\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.6963\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.1 min] Value: relu, Epochs: 43, Loss: 1.7393\n",
      "[5/28 | 17.9% |  0.1 min] Value: leakyrelu, Epochs: 47, Loss: 2.4949\n",
      "[6/28 | 21.4% |  0.1 min] Value: gelu, Epochs: 19, Loss: 0.6963\n",
      "[7/28 | 25.0% |  0.1 min] Value: elu, Epochs: 37, Loss: 1.5760\n",
      "[8/28 | 28.6% |  0.1 min] Value: silu, Epochs: 28, Loss: 1.5057\n",
      "Best activation = gelu, val_loss = 0.6963\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.1 min] Value: 0.0001, Epochs: 93, Loss: 1.1857\n",
      "[10/28 | 35.7% |  0.0 min] Value: 0.001, Epochs: 19, Loss: 0.6963\n",
      "Best learning_rate = 0.001, val_loss = 0.6963\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.0 min] Value: 32, Epochs: 17, Loss: 0.8715\n",
      "[12/28 | 42.9% |  0.0 min] Value: 512, Epochs: 19, Loss: 0.6963\n",
      "[13/28 | 46.4% |  0.0 min] Value: 1024, Epochs: 19, Loss: 0.6963\n",
      "Best batch_size = 512, val_loss = 0.6963\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.1 min] Value: 0.0, Epochs: 22, Loss: 0.7752\n",
      "[15/28 | 53.6% |  0.1 min] Value: 1e-05, Epochs: 19, Loss: 0.6963\n",
      "[16/28 | 57.1% |  0.1 min] Value: 0.0001, Epochs: 19, Loss: 0.6963\n",
      "[17/28 | 60.7% |  0.1 min] Value: 0.001, Epochs: 19, Loss: 0.6963\n",
      "[18/28 | 64.3% |  0.1 min] Value: 0.01, Epochs: 26, Loss: 1.2861\n",
      "Best weight_decay = 0.001, val_loss = 0.6963\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 19, Loss: 0.6963\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 19, Loss: 0.7247\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 19, Loss: 0.6875\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 24, Loss: 1.0501\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 24, Loss: 0.9988\n",
      "Best instance_dropout = 0.4, val_loss = 0.6875\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 23, Loss: 0.7871\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 26, Loss: 1.3862\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 32, Loss: 1.3942\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 27, Loss: 0.7242\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 25, Loss: 0.9531\n",
      "Best random_seed = 4, val_loss = 0.7242\n",
      "Stepwise optimization completed in 0.5 min\n",
      "\n",
      "MeanInstanceNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 19, Loss: 0.6963\n",
      "[2/28 |  7.1% |  0.1 min] Value: (256, 128, 64), Epochs: 129, Loss: 1.0670\n",
      "[3/28 | 10.7% |  0.0 min] Value: (128,), Epochs: 37, Loss: 6.8123\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.6963\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.1 min] Value: relu, Epochs: 43, Loss: 1.7107\n",
      "[5/28 | 17.9% |  0.1 min] Value: leakyrelu, Epochs: 47, Loss: 2.4947\n",
      "[6/28 | 21.4% |  0.1 min] Value: gelu, Epochs: 26, Loss: 0.8827\n",
      "[7/28 | 25.0% |  0.1 min] Value: elu, Epochs: 37, Loss: 1.5760\n",
      "[8/28 | 28.6% |  0.1 min] Value: silu, Epochs: 28, Loss: 1.5057\n",
      "Best activation = gelu, val_loss = 0.8827\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.1 min] Value: 0.0001, Epochs: 93, Loss: 1.1857\n",
      "[10/28 | 35.7% |  0.0 min] Value: 0.001, Epochs: 19, Loss: 0.6963\n",
      "Best learning_rate = 0.001, val_loss = 0.6963\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.1 min] Value: 32, Epochs: 24, Loss: 0.7489\n",
      "[12/28 | 42.9% |  0.0 min] Value: 512, Epochs: 23, Loss: 1.6589\n",
      "[13/28 | 46.4% |  0.0 min] Value: 1024, Epochs: 19, Loss: 0.6963\n",
      "Best batch_size = 1024, val_loss = 0.6963\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.1 min] Value: 0.0, Epochs: 31, Loss: 1.3705\n",
      "[15/28 | 53.6% |  0.1 min] Value: 1e-05, Epochs: 19, Loss: 0.6963\n",
      "[16/28 | 57.1% |  0.1 min] Value: 0.0001, Epochs: 19, Loss: 0.6963\n",
      "[17/28 | 60.7% |  0.1 min] Value: 0.001, Epochs: 23, Loss: 1.4788\n",
      "[18/28 | 64.3% |  0.1 min] Value: 0.01, Epochs: 19, Loss: 0.6962\n",
      "Best weight_decay = 0.01, val_loss = 0.6962\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 19, Loss: 0.6962\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 20, Loss: 1.6748\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 25, Loss: 1.4501\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 19, Loss: 1.1973\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 19, Loss: 0.8503\n",
      "Best instance_dropout = 0.0, val_loss = 0.6962\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 33, Loss: 0.8101\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 33, Loss: 1.0848\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 31, Loss: 1.1512\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 27, Loss: 1.2005\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 21, Loss: 0.8217\n",
      "Best random_seed = 1, val_loss = 0.8101\n",
      "Stepwise optimization completed in 0.6 min\n",
      "\n",
      "AdditiveAttentionNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 19, Loss: 0.6931\n",
      "[2/31 |  6.5% |  0.1 min] Value: (256, 128, 64), Epochs: 125, Loss: 1.0952\n",
      "[3/31 |  9.7% |  0.0 min] Value: (128,), Epochs: 37, Loss: 6.7543\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.6931\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 66, Loss: 2.8551\n",
      "[5/31 | 16.1% |  0.1 min] Value: leakyrelu, Epochs: 38, Loss: 1.7851\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 19, Loss: 0.6931\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 37, Loss: 1.2107\n",
      "[8/31 | 25.8% |  0.1 min] Value: silu, Epochs: 29, Loss: 1.5921\n",
      "Best activation = gelu, val_loss = 0.6931\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.1 min] Value: 0.0001, Epochs: 93, Loss: 1.1877\n",
      "[10/31 | 32.3% |  0.0 min] Value: 0.001, Epochs: 19, Loss: 0.6931\n",
      "Best learning_rate = 0.001, val_loss = 0.6931\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.1 min] Value: 32, Epochs: 18, Loss: 0.9204\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 32, Loss: 1.1316\n",
      "[13/31 | 41.9% |  0.0 min] Value: 1024, Epochs: 19, Loss: 0.6931\n",
      "Best batch_size = 1024, val_loss = 0.6931\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.1 min] Value: 0.0, Epochs: 19, Loss: 0.6931\n",
      "[15/31 | 48.4% |  0.1 min] Value: 1e-05, Epochs: 19, Loss: 0.6931\n",
      "[16/31 | 51.6% |  0.1 min] Value: 0.0001, Epochs: 19, Loss: 0.6931\n",
      "[17/31 | 54.8% |  0.1 min] Value: 0.001, Epochs: 19, Loss: 0.6931\n",
      "[18/31 | 58.1% |  0.1 min] Value: 0.01, Epochs: 19, Loss: 0.6930\n",
      "Best weight_decay = 0.01, val_loss = 0.6930\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.0 min] Value: 0.01, Epochs: 20, Loss: 1.5629\n",
      "[20/31 | 64.5% |  0.0 min] Value: 0.5, Epochs: 22, Loss: 0.8011\n",
      "[21/31 | 67.7% |  0.0 min] Value: 1.0, Epochs: 19, Loss: 0.6930\n",
      "Best tau = 1.0, val_loss = 0.6930\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.1 min] Value: 0.0, Epochs: 19, Loss: 0.6930\n",
      "[23/31 | 74.2% |  0.1 min] Value: 0.2, Epochs: 23, Loss: 1.5611\n",
      "[24/31 | 77.4% |  0.1 min] Value: 0.4, Epochs: 24, Loss: 1.2862\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 24, Loss: 1.0477\n",
      "[26/31 | 83.9% |  0.1 min] Value: 0.8, Epochs: 32, Loss: 1.3826\n",
      "Best instance_dropout = 0.0, val_loss = 0.6930\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.1 min] Value: 1, Epochs: 26, Loss: 1.3024\n",
      "[28/31 | 90.3% |  0.1 min] Value: 2, Epochs: 33, Loss: 1.0964\n",
      "[29/31 | 93.5% |  0.1 min] Value: 3, Epochs: 24, Loss: 1.5221\n",
      "[30/31 | 96.8% |  0.1 min] Value: 4, Epochs: 28, Loss: 0.9800\n",
      "[31/31 | 100.0% |  0.1 min] Value: 5, Epochs: 25, Loss: 0.7165\n",
      "Best random_seed = 5, val_loss = 0.7165\n",
      "Stepwise optimization completed in 0.6 min\n",
      "\n",
      "SelfAttentionNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.1 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 27, Loss: 1.3565\n",
      "[2/31 |  6.5% |  0.0 min] Value: (256, 128, 64), Epochs: 49, Loss: 1.3904\n",
      "[3/31 |  9.7% |  0.0 min] Value: (128,), Epochs: 44, Loss: 2.1168\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 1.3565\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 55, Loss: 2.5449\n",
      "[5/31 | 16.1% |  0.1 min] Value: leakyrelu, Epochs: 56, Loss: 2.1853\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 27, Loss: 1.3565\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 40, Loss: 1.5903\n",
      "[8/31 | 25.8% |  0.1 min] Value: silu, Epochs: 32, Loss: 1.2232\n",
      "Best activation = silu, val_loss = 1.2232\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.2 min] Value: 0.0001, Epochs: 133, Loss: 1.0963\n",
      "[10/31 | 32.3% |  0.0 min] Value: 0.001, Epochs: 32, Loss: 1.2232\n",
      "Best learning_rate = 0.0001, val_loss = 1.0963\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.2 min] Value: 32, Epochs: 71, Loss: 1.0371\n",
      "[12/31 | 38.7% |  0.2 min] Value: 512, Epochs: 133, Loss: 1.0963\n",
      "[13/31 | 41.9% |  0.2 min] Value: 1024, Epochs: 145, Loss: 0.9543\n",
      "Best batch_size = 1024, val_loss = 0.9543\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.3 min] Value: 0.0, Epochs: 135, Loss: 1.0932\n",
      "[15/31 | 48.4% |  0.4 min] Value: 1e-05, Epochs: 133, Loss: 1.0963\n",
      "[16/31 | 51.6% |  0.4 min] Value: 0.0001, Epochs: 134, Loss: 1.1034\n",
      "[17/31 | 54.8% |  0.4 min] Value: 0.001, Epochs: 133, Loss: 1.0963\n",
      "[18/31 | 58.1% |  0.4 min] Value: 0.01, Epochs: 133, Loss: 1.0960\n",
      "Best weight_decay = 0.0, val_loss = 1.0932\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.4 min] Value: 0.01, Epochs: 123, Loss: 1.1353\n",
      "[20/31 | 64.5% |  0.3 min] Value: 0.5, Epochs: 152, Loss: 0.9376\n",
      "[21/31 | 67.7% |  0.2 min] Value: 1.0, Epochs: 133, Loss: 1.0963\n",
      "Best tau = 0.5, val_loss = 0.9376\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.3 min] Value: 0.0, Epochs: 122, Loss: 1.1163\n",
      "[23/31 | 74.2% |  0.3 min] Value: 0.2, Epochs: 112, Loss: 1.1097\n",
      "[24/31 | 77.4% |  0.3 min] Value: 0.4, Epochs: 131, Loss: 0.9418\n",
      "[25/31 | 80.6% |  0.3 min] Value: 0.6, Epochs: 104, Loss: 1.1442\n",
      "[26/31 | 83.9% |  0.3 min] Value: 0.8, Epochs: 128, Loss: 1.1706\n",
      "Best instance_dropout = 0.4, val_loss = 0.9418\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.3 min] Value: 1, Epochs: 108, Loss: 1.3236\n",
      "[28/31 | 90.3% |  0.3 min] Value: 2, Epochs: 154, Loss: 0.9596\n",
      "[29/31 | 93.5% |  0.1 min] Value: 3, Epochs: 53, Loss: 1.9131\n",
      "[30/31 | 96.8% |  0.2 min] Value: 4, Epochs: 95, Loss: 1.2168\n",
      "[31/31 | 100.0% |  0.3 min] Value: 5, Epochs: 120, Loss: 1.1014\n",
      "Best random_seed = 2, val_loss = 0.9596\n",
      "Stepwise optimization completed in 2.0 min\n",
      "\n",
      "HopfieldAttentionNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/31 |  3.2% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 21, Loss: 0.6427\n",
      "[2/31 |  6.5% |  0.0 min] Value: (256, 128, 64), Epochs: 109, Loss: 1.0111\n",
      "[3/31 |  9.7% |  0.0 min] Value: (128,), Epochs: 37, Loss: 6.6910\n",
      "Best hidden_layer_sizes = (2048, 1024, 512, 256, 128, 64), val_loss = 0.6427\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/31 | 12.9% |  0.1 min] Value: relu, Epochs: 38, Loss: 1.9830\n",
      "[5/31 | 16.1% |  0.1 min] Value: leakyrelu, Epochs: 37, Loss: 1.8411\n",
      "[6/31 | 19.4% |  0.1 min] Value: gelu, Epochs: 19, Loss: 0.8782\n",
      "[7/31 | 22.6% |  0.1 min] Value: elu, Epochs: 34, Loss: 0.7068\n",
      "[8/31 | 25.8% |  0.1 min] Value: silu, Epochs: 25, Loss: 1.5248\n",
      "Best activation = elu, val_loss = 0.7068\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/31 | 29.0% |  0.0 min] Value: 0.0001, Epochs: 27, Loss: 1.2578\n",
      "[10/31 | 32.3% |  0.1 min] Value: 0.001, Epochs: 34, Loss: 0.7970\n",
      "Best learning_rate = 0.001, val_loss = 0.7970\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/31 | 35.5% |  0.1 min] Value: 32, Epochs: 22, Loss: 0.8148\n",
      "[12/31 | 38.7% |  0.1 min] Value: 512, Epochs: 34, Loss: 0.7218\n",
      "[13/31 | 41.9% |  0.1 min] Value: 1024, Epochs: 33, Loss: 1.0937\n",
      "Best batch_size = 512, val_loss = 0.7218\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/31 | 45.2% |  0.1 min] Value: 0.0, Epochs: 32, Loss: 1.6757\n",
      "[15/31 | 48.4% |  0.1 min] Value: 1e-05, Epochs: 34, Loss: 0.7240\n",
      "[16/31 | 51.6% |  0.1 min] Value: 0.0001, Epochs: 33, Loss: 1.0997\n",
      "[17/31 | 54.8% |  0.1 min] Value: 0.001, Epochs: 34, Loss: 0.9191\n",
      "[18/31 | 58.1% |  0.1 min] Value: 0.01, Epochs: 38, Loss: 0.7841\n",
      "Best weight_decay = 1e-05, val_loss = 0.7240\n",
      "Optimizing hyperparameter: tau (3 options)\n",
      "[19/31 | 61.3% |  0.1 min] Value: 0.01, Epochs: 37, Loss: 1.5920\n",
      "[20/31 | 64.5% |  0.1 min] Value: 0.5, Epochs: 33, Loss: 0.7254\n",
      "[21/31 | 67.7% |  0.1 min] Value: 1.0, Epochs: 32, Loss: 1.6725\n",
      "Best tau = 0.5, val_loss = 0.7254\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[22/31 | 71.0% |  0.1 min] Value: 0.0, Epochs: 32, Loss: 1.0337\n",
      "[23/31 | 74.2% |  0.1 min] Value: 0.2, Epochs: 35, Loss: 0.7622\n",
      "[24/31 | 77.4% |  0.1 min] Value: 0.4, Epochs: 33, Loss: 1.1731\n",
      "[25/31 | 80.6% |  0.1 min] Value: 0.6, Epochs: 38, Loss: 0.7146\n",
      "[26/31 | 83.9% |  0.1 min] Value: 0.8, Epochs: 33, Loss: 0.8020\n",
      "Best instance_dropout = 0.6, val_loss = 0.7146\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[27/31 | 87.1% |  0.1 min] Value: 1, Epochs: 31, Loss: 0.7109\n",
      "[28/31 | 90.3% |  0.1 min] Value: 2, Epochs: 33, Loss: 0.6897\n",
      "[29/31 | 93.5% |  0.1 min] Value: 3, Epochs: 41, Loss: 1.3104\n",
      "[30/31 | 96.8% |  0.1 min] Value: 4, Epochs: 37, Loss: 1.3343\n",
      "[31/31 | 100.0% |  0.1 min] Value: 5, Epochs: 18, Loss: 1.8569\n",
      "Best random_seed = 2, val_loss = 0.6897\n",
      "Stepwise optimization completed in 0.6 min\n",
      "\n",
      "DynamicPoolingNetworkRegressor\n",
      "Optimizing hyperparameter: hidden_layer_sizes (3 options)\n",
      "[1/28 |  3.6% |  0.0 min] Value: (2048, 1024, 512, 256, 128, 64), Epochs: 19, Loss: 0.0599\n",
      "[2/28 |  7.1% |  0.0 min] Value: (256, 128, 64), Epochs: 19, Loss: 0.0700\n",
      "[3/28 | 10.7% |  0.0 min] Value: (128,), Epochs: 17, Loss: 0.0596\n",
      "Best hidden_layer_sizes = (128,), val_loss = 0.0596\n",
      "Optimizing hyperparameter: activation (5 options)\n",
      "[4/28 | 14.3% |  0.0 min] Value: relu, Epochs: 18, Loss: 0.0650\n",
      "[5/28 | 17.9% |  0.0 min] Value: leakyrelu, Epochs: 18, Loss: 0.0556\n",
      "[6/28 | 21.4% |  0.0 min] Value: gelu, Epochs: 17, Loss: 0.0596\n",
      "[7/28 | 25.0% |  0.0 min] Value: elu, Epochs: 33, Loss: 0.0521\n",
      "[8/28 | 28.6% |  0.0 min] Value: silu, Epochs: 16, Loss: 0.0566\n",
      "Best activation = elu, val_loss = 0.0521\n",
      "Optimizing hyperparameter: learning_rate (2 options)\n",
      "[9/28 | 32.1% |  0.0 min] Value: 0.0001, Epochs: 100, Loss: 0.0575\n",
      "[10/28 | 35.7% |  0.0 min] Value: 0.001, Epochs: 33, Loss: 0.0521\n",
      "Best learning_rate = 0.001, val_loss = 0.0521\n",
      "Optimizing hyperparameter: batch_size (3 options)\n",
      "[11/28 | 39.3% |  0.0 min] Value: 32, Epochs: 22, Loss: 0.0572\n",
      "[12/28 | 42.9% |  0.0 min] Value: 512, Epochs: 33, Loss: 0.0521\n",
      "[13/28 | 46.4% |  0.0 min] Value: 1024, Epochs: 33, Loss: 0.0521\n",
      "Best batch_size = 512, val_loss = 0.0521\n",
      "Optimizing hyperparameter: weight_decay (5 options)\n",
      "[14/28 | 50.0% |  0.1 min] Value: 0.0, Epochs: 33, Loss: 0.0521\n",
      "[15/28 | 53.6% |  0.1 min] Value: 1e-05, Epochs: 33, Loss: 0.0521\n",
      "[16/28 | 57.1% |  0.1 min] Value: 0.0001, Epochs: 33, Loss: 0.0521\n",
      "[17/28 | 60.7% |  0.1 min] Value: 0.001, Epochs: 33, Loss: 0.0521\n",
      "[18/28 | 64.3% |  0.1 min] Value: 0.01, Epochs: 33, Loss: 0.0521\n",
      "Best weight_decay = 0.0, val_loss = 0.0521\n",
      "Optimizing hyperparameter: instance_dropout (5 options)\n",
      "[19/28 | 67.9% |  0.1 min] Value: 0.0, Epochs: 33, Loss: 0.0521\n",
      "[20/28 | 71.4% |  0.1 min] Value: 0.2, Epochs: 37, Loss: 0.0459\n",
      "[21/28 | 75.0% |  0.1 min] Value: 0.4, Epochs: 42, Loss: 0.0408\n",
      "[22/28 | 78.6% |  0.1 min] Value: 0.6, Epochs: 55, Loss: 0.0426\n",
      "[23/28 | 82.1% |  0.1 min] Value: 0.8, Epochs: 35, Loss: 0.0687\n",
      "Best instance_dropout = 0.4, val_loss = 0.0408\n",
      "Optimizing hyperparameter: random_seed (5 options)\n",
      "[24/28 | 85.7% |  0.1 min] Value: 1, Epochs: 59, Loss: 0.0400\n",
      "[25/28 | 89.3% |  0.1 min] Value: 2, Epochs: 59, Loss: 0.0401\n",
      "[26/28 | 92.9% |  0.1 min] Value: 3, Epochs: 31, Loss: 0.0448\n",
      "[27/28 | 96.4% |  0.1 min] Value: 4, Epochs: 34, Loss: 0.0438\n",
      "[28/28 | 100.0% |  0.1 min] Value: 5, Epochs: 47, Loss: 0.0407\n",
      "Best random_seed = 1, val_loss = 0.0400\n",
      "Stepwise optimization completed in 0.4 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if TASK == \"regression\":\n",
    "    method_list = regressor_list\n",
    "elif TASK == \"classification\":\n",
    "    method_list = classifier_list\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "for method_name, model in method_list:\n",
    "    print(method_name)\n",
    "\n",
    "    model.hopt(x_train_scaled, y_train, param_grid=DEFAULT_PARAM_GRID, verbose=True)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "\n",
    "    if TASK == \"regression\":\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "    elif TASK == \"classification\":\n",
    "        y_prob = model.predict(x_test_scaled)\n",
    "        y_pred = np.where(y_prob > 0.5, 1, 0)\n",
    "    \n",
    "    res_df.loc[method_name, \"ACC\"] = accuracy_metric(y_test, y_pred, task=TASK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MeanInstanceWrapperMLPNetworkRegressor</th>\n",
       "      <td>0.373213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanBagNetworkRegressor</th>\n",
       "      <td>0.331022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HopfieldAttentionNetworkRegressor</th>\n",
       "      <td>0.167728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SelfAttentionNetworkRegressor</th>\n",
       "      <td>0.166942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdditiveAttentionNetworkRegressor</th>\n",
       "      <td>0.027758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanInstanceNetworkRegressor</th>\n",
       "      <td>0.014949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanBagWrapperMLPNetworkRegressor</th>\n",
       "      <td>-0.014890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DynamicPoolingNetworkRegressor</th>\n",
       "      <td>-0.090924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ACC\n",
       "MeanInstanceWrapperMLPNetworkRegressor  0.373213\n",
       "MeanBagNetworkRegressor                 0.331022\n",
       "HopfieldAttentionNetworkRegressor       0.167728\n",
       "SelfAttentionNetworkRegressor           0.166942\n",
       "AdditiveAttentionNetworkRegressor       0.027758\n",
       "MeanInstanceNetworkRegressor            0.014949\n",
       "MeanBagWrapperMLPNetworkRegressor      -0.014890\n",
       "DynamicPoolingNetworkRegressor         -0.090924"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values(by=\"ACC\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qsarlazy",
   "language": "python",
   "name": "qsarlazy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
